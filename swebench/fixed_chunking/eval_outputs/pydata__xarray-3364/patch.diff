```patch
--- a/xarray/core/concat.py
+++ b/xarray/core/concat.py
@@ -50,6 +50,10 @@
             already loaded.
           * 'all': All data variables will be concatenated.
           * list of str: The listed data variables will be concatenated, in
+            addition to the 'minimal' data variables.
+
+        The default behaviour is 'minimal', but note that coordinates may also be
+        selected using the `coords` argument.
     coords : {'minimal', 'different', 'all' or list of str}, optional
         These coordinate variables will be concatenated together:
           * 'minimal': Only coordinates in which the dimension already appears
@@ -64,10 +68,20 @@
             addition to the 'minimal' coordinates.
         The default behaviour is 'different'. 'minimal' is behaviour prior to
         v0.15.0.
+    compat : {'identical', 'equals', 'broadcast_equals', 'no_conflicts', 'override'}, optional
+        String indicating how to compare variables of the same name for
+        potential conflicts when merging. This is applied to variables that
+        are not concatenated along the dimension `dim`.
+          - 'broadcast_equals': All values must be equal when variables are
+            broadcast against each other to ensure common dimensions.
+          - 'equals': All values and dimensions must be the same.
+          - 'identical': All values, dimensions and attributes must be the
+            same.
+          - 'no_conflicts': Only dimensions must be the same. Variables with
+            the same name are skipped unless they are coordinates (see `coords`).
+          - 'override': Skip comparing and pick variable from first dataset.
     positions : None or list of integer arrays, optional
         List of integer arrays which specifies the integer positions to which
         to assign each dataset along the concatenated dimension. If not
-        supplied, datasets are concatenated in the provided order.
     fill_value : scalar, optional
         Value to use for newly missing values
     join : {'outer', 'inner', 'left', 'right', 'exact'}, optional
@@ -79,8 +93,12 @@
         - 'left': use indexes from the first object with each dimension
         - 'right': use indexes from the last object with each dimension
         - 'exact': instead of aligning, raise `ValueError` when indexes to be
-          aligned are not equal.
+          aligned are not equal. Requires all objects to have the same indexes
+          (excluding `dim`).
 
+        This argument also controls how variables not present in all datasets are
+        handled:
+          - 'outer': Includes the union of variables from all datasets. Variables missing in some datasets will be filled with `fill_value`. (Default)
+          - 'inner': Includes only variables present in all datasets.
+          - 'exact': Requires all datasets to have the same variables.
     Returns
     -------
     combined : xarray.Dataset or xarray.DataArray
@@ -240,16 +258,13 @@
 
     # concatenate variables
     for k in concat_over:
-        # Concatenate variables along the new dimension
-        # N.B. ensure_common_dims cannot handle the case where the dimension is
-        # present in some variables but not others. This is handled by the logic
-        # above.
-        try:
-            vars = ensure_common_dims([ds.variables[k] for ds in datasets])
-        except KeyError:
-            raise ValueError("%r is not present in all datasets." % k)
+        # Ensure variables have matching dimensions and coordinate values,
+        # except along the concatenated dimension. This is done by the align
+        # call before _dataset_concat is called.
+        # If a variable is missing in some datasets (join='outer'), align pads
+        # the variable with NaN/fill_value, so it should always be present here.
+        vars = ensure_common_dims([ds.variables[k] for ds in datasets])
         combined = concat_vars(vars, dim, positions)
         assert isinstance(combined, Variable)
         result_vars[k] = combined
         if k in result_coord_names:
```
