```patch
--- a/sklearn/linear_model/ridge.py
+++ b/sklearn/linear_model/ridge.py
@@ -1257,12 +1257,17 @@
         The "balanced" mode uses the values of y to automatically adjust
         weights inversely proportional to class frequencies in the input data
         as ``n_samples / (n_classes * np.bincount(y))``
+
+    store_cv_values : boolean, default=False
+        Flag indicating if the cross-validation values corresponding to
+        each alpha should be stored in the `cv_values_` attribute (see
+        below). This flag is only compatible with `cv=None` (i.e. using
+        Generalized Cross-Validation).

     Attributes
     ----------
     cv_values_ : array, shape = [n_samples, n_alphas] or \
     shape = [n_samples, n_responses, n_alphas], optional
-        Cross-validation values for each alpha (if store_cv_values=True and \
 cv=None). After fit() has been called, this attribute will contain the \
 values computed Leave-One-Out cross-validation -- a matrix where each row \
 corresponds to a sample, and each column corresponds to a value of ``alpha``.
@@ -1289,11 +1294,11 @@
     """
     def __init__(self, alphas=(0.1, 1.0, 10.0),
                  fit_intercept=True, normalize=False, scoring=None,
-                 cv=None, class_weight=None):
+                 cv=None, class_weight=None, store_cv_values=False):
         super(RidgeClassifierCV, self).__init__(
             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,
             scoring=scoring, cv=cv, gcv_mode=None,
-            store_cv_values=False)
+            store_cv_values=store_cv_values)
         self.class_weight = class_weight

     def fit(self, X, y, sample_weight=None):
```
