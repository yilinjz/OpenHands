{"instance_id": "astropy__astropy-12907", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -123,7 +123,7 @@\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n\n     return np.hstack([cleft, cright])\n\n```\n"}
{"instance_id": "astropy__astropy-14182", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -56,8 +56,8 @@\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+    def __init__(self, **kwargs):\n+        super().__init__(delimiter_pad=None, bookend=False, **kwargs)\n \n     def write(self, lines):\n         lines = super().write(lines)\n\n```\n"}
{"instance_id": "astropy__astropy-14365", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -61,7 +61,7 @@\n     ValueError: Unrecognized QDP line...\n     \"\"\"\n     _decimal_re = r\"[+-]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?\"\n-    _command_re = r\"READ [TS]ERR(\\s+[0-9]+)+\"\n+    _command_re = r\"(?i)READ [TS]ERR(\\s+[0-9]+)+\"\n \n     sep = delimiter\n     if delimiter is None:\n\n```\n"}
{"instance_id": "astropy__astropy-14995", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -29,15 +29,23 @@\n          28             ``handle_mask`` must create (and copy) the returned mask.\n          29         \"\"\"\n          30         # If only one mask is present we need not bother about any type checks\n-         31         if (\n-         32             self.mask is None and operand is not None and operand.mask is None\n-         33         ) or handle_mask is None:\n-         34             return None\n-         35         elif self.mask is None and operand is not None:\n-         36             # Make a copy so there is no reference in the result.\n-         37             return deepcopy(operand.mask)\n-         38         elif operand is None:\n-         39             return deepcopy(self.mask)\n-         40         else:\n-         41             # Now lets calculate the resulting mask (operation enforces copy)\n-         42             return handle_mask(self.mask, operand.mask, **kwds)\n+         31         if handle_mask is None:\n+         32             return None\n+         33 \n+         34         self_has_mask = self.mask is not None\n+         35         operand_is_none = operand is None\n+         36         # operand should be None if operating with a constant, or an NDData-like object\n+         37         operand_has_mask = not operand_is_none and getattr(operand, \"mask\", None) is not None\n+         38 \n+         39         if not self_has_mask and not operand_has_mask:\n+         40             # Case: Neither has a mask\n+         41             return None\n+         42         elif not self_has_mask and operand_has_mask:\n+         43             # Case: Only operand has a mask\n+         44             # Make a copy so there is no reference in the result.\n+         45             return deepcopy(operand.mask)\n+         46         elif self_has_mask and (operand_is_none or not operand_has_mask):\n+         47             # Case: Only self has a mask (operand is None or operand has no mask)\n+         48             return deepcopy(self.mask)\n+         49         else:  # Both self_has_mask and operand_has_mask are True\n+         50             # Case: Both have masks, apply handle_mask\n+         51             # Now lets calculate the resulting mask (operation enforces copy)\n+         52             return handle_mask(self.mask, operand.mask, **kwds)\n\n```\n"}
{"instance_id": "astropy__astropy-6938", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -65,5 +65,6 @@\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            # The .replace() method on chararrays returns a copy; to modify\n+            # in-place requires assigning back the result of np.char.replace\n+            output_field[:] = np.char.replace(output_field, encode_ascii('E'), encode_ascii('D'))\n```\n"}
{"instance_id": "astropy__astropy-7746", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -11,14 +11,18 @@\n                 raise ValueError(\n                     \"Coordinate arrays are not broadcastable to each other\")\n\n-            xy = np.hstack([x.reshape((x.size, 1)) for x in axes])\n-\n-            if ra_dec_order and sky == 'input':\n-                xy = self._denormalize_sky(xy)\n-            output = func(xy, origin)\n+            # If the input arrays are empty, return empty arrays\n+            # matching the expected output shape. Note that self.naxis is\n+            # the number of output axes, which may not be the same as the\n+            # number of input axes.\n+            if axes[0].size == 0:\n+                output = np.empty((0, self.naxis), dtype=np.float64)\n+            else:\n+                xy = np.hstack([x.reshape((x.size, 1)) for x in axes])\n+                if ra_dec_order and sky == 'input':\n+                    xy = self._denormalize_sky(xy)\n+                output = func(xy, origin)\n+\n             if ra_dec_order and sky == 'output':\n                 output = self._normalize_sky(output)\n-                return (output[:, 0].reshape(axes[0].shape),\n-                        output[:, 1].reshape(axes[0].shape))\n+                if self.naxis == 2:  # Special case for ra/dec order output\n+                    return (output[:, 0].reshape(axes[0].shape),\n+                            output[:, 1].reshape(axes[0].shape))\n             return [output[:, i].reshape(axes[0].shape)\n                     for i in range(output.shape[1])]\n\n@@ -29,10 +33,14 @@\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n                     \"of shape (N, {0})\".format(self.naxis))\n-            if ra_dec_order and sky == 'input':\n-                xy = self._denormalize_sky(xy)\n-            result = func(xy, origin)\n+            # If the input array is empty, return an empty array\n+            # matching the expected output shape\n+            if xy.shape[0] == 0:\n+                result = np.empty((0, self.naxis), dtype=np.float64)\n+            else:\n+                if ra_dec_order and sky == 'input':\n+                    xy = self._denormalize_sky(xy)\n+                result = func(xy, origin)\n             if ra_dec_order and sky == 'output':\n                 result = self._normalize_sky(result)\n             return result\n\n```\n"}
{"instance_id": "django__django-10914", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -10,7 +10,7 @@\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n # you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+FILE_UPLOAD_PERMISSIONS = 0o644\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;\n\n```\n"}
{"instance_id": "django__django-10924", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -49,8 +49,12 @@\n             return str(value)\n \n     def formfield(self, **kwargs):\n+        # Resolve path if it's callable.\n+        path = self.path\n+        if callable(path):\n+            path = path()\n         return super().formfield(**{\n-            'path': self.path,\n+            'path': path,\n             'match': self.match,\n             'recursive': self.recursive,\n             'form_class': forms.FilePathField,\n\n```\n"}
{"instance_id": "django__django-11001", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -217,7 +217,10 @@\n             # is refactored into expressions, then we can check each part as we\n             # generate it.\n             without_ordering = self.ordering_parts.search(sql).group(1)\n+            # Normalize multiline SQL strings by replacing newlines with spaces\n+            # before searching for the ORDER BY clause (#26581).\n+            sql_oneline = ' '.join(sql.splitlines())\n+            without_ordering = self.ordering_parts.search(sql_oneline).group(1)\n             params_hash = make_hashable(params)\n             if (without_ordering, params_hash) in seen:\n                 continue\n\n```\n"}
{"instance_id": "django__django-11019", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "django__django-11039", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -76,7 +76,7 @@\n                 self.stdout.write(self.style.SQL_KEYWORD(\"--\"))\n\n             # Deconstruct the operations\n-            self.output_transaction = target_migration.atomic\n+            self.output_transaction = target_migration.atomic and connection.features.can_rollback_ddl\n\n             if self.output_transaction:\n                 self.stdout.write(\n\n```\n"}
{"instance_id": "django__django-11049", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -7,8 +7,8 @@\n     \"\"\"\n     empty_strings_allowed = False\n     default_error_messages = {\n-        'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                      \"[DD] [HH:[MM:]]ss[.uuuuuu] format.\")\n+        'invalid': _(\"'%(value)s' value has an invalid format. It must be in [DD] \"\n+                      \"[[HH:]MM:]ss[.uuuuuu] format.\")\n     }\n     description = _(\"Duration\")\n \n@@ -51,10 +51,11 @@\n         return '' if val is None else duration_string(val)\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n+        defaults = {\n             'form_class': forms.DurationField,\n-            **kwargs,\n-        })\n+            'help_text': _('Enter duration in format [DD] [[HH:]MM:]ss[.uuuuuu]'),\n+        }\n+        defaults.update(kwargs)\n+        return super().formfield(**defaults)\n\n\n class EmailField(CharField):\n\n```\n"}
{"instance_id": "django__django-11099", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -6,7 +6,7 @@\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -16,7 +16,7 @@\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n\n```\n"}
{"instance_id": "django__django-11133", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -131,8 +131,10 @@\n                 return bytes(value)\n             if isinstance(value, str):\n                 return bytes(value.encode(self.charset))\n+            if isinstance(value, memoryview):\n+                return bytes(value)\n             # Handle non-string types.\n             return str(value).encode(self.charset)\n\n         # These methods partially implement the file-like object interface.\n\n```\n"}
{"instance_id": "django__django-11179", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -15,6 +15,8 @@\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                # Set the PK to None on the instance.\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n\n```\n"}
{"instance_id": "django__django-11283", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -1,5 +1,6 @@\n from django.db import migrations\n from django.db.models import Q\n+from django.db.utils import IntegrityError\n \n \n def update_proxy_model_permissions(apps, schema_editor, reverse=False):\n@@ -9,6 +10,8 @@\n     \"\"\"\n     Permission = apps.get_model('auth', 'Permission')\n     ContentType = apps.get_model('contenttypes', 'ContentType')\n+    # Ensure we're using the correct database connection for ContentType lookups.\n+    db_alias = schema_editor.connection.alias\n     for Model in apps.get_models():\n         opts = Model._meta\n         if not opts.proxy:\n@@ -21,15 +24,35 @@\n         permissions_query = Q(codename__in=proxy_default_permissions_codenames)\n         for codename, name in opts.permissions:\n             permissions_query = permissions_query | Q(codename=codename, name=name)\n-        concrete_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=True)\n-        proxy_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n+\n+        # We use get_for_model directly because the ContentTypes may not exist\n+        # in the ContentType cache.\n+        try:\n+            concrete_content_type = ContentType.objects.db_manager(db_alias).get_for_model(\n+                Model, for_concrete_model=True)\n+            proxy_content_type = ContentType.objects.db_manager(db_alias).get_for_model(\n+                Model, for_concrete_model=False)\n+        except ContentType.DoesNotExist:\n+            # Content types might not exist if the model wasn't installed before\n+            # this migration. Skip this model.\n+            continue\n+\n         old_content_type = proxy_content_type if reverse else concrete_content_type\n         new_content_type = concrete_content_type if reverse else proxy_content_type\n-        Permission.objects.filter(\n+\n+        # Permissions that should have the new_content_type\n+        new_perms = Permission.objects.using(db_alias).filter(\n+            permissions_query,\n+            content_type=new_content_type,\n+        )\n+        new_perms_codenames = set(new_perms.values_list('codename', flat=True))\n+\n+        # Find permissions that have the old_content_type\n+        old_perms = Permission.objects.using(db_alias).filter(\n             permissions_query,\n             content_type=old_content_type,\n-        ).update(content_type=new_content_type)\n+        )\n+        # Update permissions that don't already exist with the new_content_type\n+        perms_to_update = old_perms.exclude(codename__in=new_perms_codenames)\n+        perms_to_update.update(content_type=new_content_type)\n+\n+        # Delete permissions that already exist with the new_content_type\n+        perms_to_delete = old_perms.filter(codename__in=new_perms_codenames)\n+        perms_to_delete.delete()\n \n \n def revert_proxy_model_permissions(apps, schema_editor):\n\n```\n"}
{"instance_id": "django__django-11422", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -106,6 +106,11 @@\n class BaseReloader:\n     def __init__(self):\n         self.extra_files = set()\n+        # Watch the script that started the reloader process.\n+        main_script = Path(sys.argv[0]).resolve()\n+        # sys.argv[0] is initially '../manage.py' or similar, so resolve()\n+        # is necessary to ensure stability on start-up.\n+        if main_script.is_file():\n+            self.extra_files.add(main_script)\n         self.directory_globs = defaultdict(set)\n         self._stop_condition = threading.Event()\n \n\n```\n"}
{"instance_id": "django__django-11564", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/templatetags/static.py\n+++ b/django/templatetags/static.py\n@@ -1,10 +1,21 @@\n+from urllib.parse import quote, urljoin\n+\n+from django.apps import apps\n+from django.conf import settings\n+from django import template\n+from django.utils.html import conditional_escape\n+try:\n+    from django.contrib.staticfiles.storage import staticfiles_storage\n+    HAS_STATICFILES = True\n+except ImportError:\n+    HAS_STATICFILES = False\n\n- [start of django/templatetags/static.py]\n-0 class StaticNode(template.Node):\n-1     def __init__(self, varname=None, path=None):\n-2         if path is None:\n-3             raise template.TemplateSyntaxError(\n-4                 \"Static template nodes must be given a path to return.\")\n-5         self.path = path\n-6         self.varname = varname\n-7\n-8     def url(self, context):\n-9         path = self.path.resolve(context)\n-10         return self.handle_simple(path)\n-11\n-12     def render(self, context):\n-13         url = self.url(context)\n-14         if context.autoescape:\n-15             url = conditional_escape(url)\n-16         if self.varname is None:\n-17             return url\n-18         context[self.varname] = url\n-19         return ''\n-20\n-21     @classmethod\n-22     def handle_simple(cls, path):\n-23         if apps.is_installed('django.contrib.staticfiles'):\n-24             from django.contrib.staticfiles.storage import staticfiles_storage\n-25             return staticfiles_storage.url(path)\n-26         else:\n-27             return urljoin(PrefixNode.handle_simple(\"STATIC_URL\"), quote(path))\n-28\n-29     @classmethod\n-30     def handle_token(cls, parser, token):\n-31         \"\"\"\n-32         Class method to parse prefix node and return a Node.\n-33         \"\"\"\n-34         bits = token.split_contents()\n-35\n-36         if len(bits) < 2:\n-37             raise template.TemplateSyntaxError(\n-38                 \"'%s' takes at least one argument (path to file)\" % bits[0])\n-39\n-40         path = parser.compile_filter(bits[1])\n-41\n-42         if len(bits) >= 2 and bits[-2] == 'as':\n-43             varname = bits[3]\n-44         else:\n-45             varname = None\n-46\n-47         return cls(varname, path)\n-48\n-49\n-50 @register.tag('static')\n-51 def do_static(parser, token):\n-52     \"\"\"\n-\n"}
{"instance_id": "django__django-11583", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -130,14 +130,21 @@\n             continue\n         # If the path is a file, add it and its containing directory.\n         # Use resolve() to follow symlinks.\n+        resolved_path = None\n         try:\n-            results.add(path.resolve().absolute())\n+            resolved_path = path.resolve().absolute()\n+        except ValueError as e:\n+            # Handle the specific \"embedded null byte\" error.\n+            if '\\x00' in str(e):\n+                logger.debug('Skipping path %s due to resolution error: %s', path, e)\n+                continue  # Skip this path and its parent.\n+            else:\n+                raise  # Re-raise other ValueErrors\n         except FileNotFoundError:\n             # Path may not exist, e.g. if it's been deleted since the\n             # module was imported.\n             continue\n-        results.add(path.parent)\n+        results.add(resolved_path)\n+        results.add(resolved_path.parent)\n\n     # Add paths from extra_files.\n     for path_str in extra_files:\n@@ -145,8 +152,15 @@\n         try:\n             results.add(path.resolve().absolute())\n         except FileNotFoundError:\n+            # Path may not exist, e.g. if it's been deleted.\n             continue\n+        except ValueError as e:\n+            # Handle the specific \"embedded null byte\" error.\n+            if '\\x00' in str(e):\n+                logger.debug('Skipping path %s due to resolution error: %s', path, e)\n+                continue  # Skip this path.\n+            else:\n+                raise  # Re-raise other ValueErrors\n\n     yield from results\n\n```\n"}
{"instance_id": "django__django-11620", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -1,22 +1,31 @@\n def technical_404_response(request, exception):\n     \"\"\"Create a technical 404 error response. `exception` is the Http404.\"\"\"\n+    error_url = request.path_info[1:]  # Default: Trim leading slash.\n+    tried = []                         # Default.\n+    resolver_info_available = False\n+\n+    # Check if exception args match the resolver's structure.\n+    if exception.args and isinstance(exception.args[0], dict):\n+        resolver_info = exception.args[0]\n+        resolver_info_available = True\n+        try:\n+            error_url = resolver_info['path']\n+        except KeyError:\n+            pass  # Keep default error_url.\n+        try:\n+            tried = resolver_info['tried']\n+        except KeyError:\n+            pass  # Keep default tried = [].\n     try:\n-        error_url = exception.args[0]['path']\n-    except (IndexError, TypeError, KeyError):\n-        error_url = request.path_info[1:]  # Trim leading slash\n-\n-    try:\n-        tried = exception.args[0]['tried']\n-    except (IndexError, TypeError, KeyError):\n-        tried = []\n-    else:\n-        if (not tried or (                  # empty URLconf\n-            request.path == '/' and\n-            len(tried) == 1 and             # default URLconf\n-            len(tried[0]) == 1 and\n-            getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin'\n-        )):\n+        # Check for default URLconf only if resolver info was available and matched structure.\n+        if resolver_info_available and (not tried or (  # empty URLconf\n+                request.path == '/' and\n+                len(tried) == 1 and             # default URLconf\n+                len(tried[0]) == 1 and\n+                getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin'\n+        )):\n             return default_urlconf(request)\n+    except Exception:\n+        # If accessing tried patterns somehow fails, ignore the check for\n+        # default URLconf. It's not worth crashing for.\n+        pass\n \n     urlconf = getattr(request, 'urlconf', settings.ROOT_URLCONF)\n     if isinstance(urlconf, types.ModuleType):\n@@ -25,6 +34,8 @@\n     caller = ''\n     try:\n         resolver_match = resolve(request.path)\n+    except Http404:\n+        # Raised by the resolver's pattern finding logic or a converter.\n+        pass\n     except Resolver404:\n         pass\n     else:\n```\n"}
{"instance_id": "django__django-11630", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/checks.py\n+++ b/django/db/models/checks.py\n@@ -15,7 +15,10 @@\n     errors = []\n     for model in apps.get_models(include_auto_created=True):\n         errors.extend(model.check(**kwargs))\n-    errors.extend(check_db_table_clashes(app_configs))\n+    # Skip E028 check for db_table clashes across all models.\n+    # This check does not account for multi-database setups where identical\n+    # table names in different databases are valid.\n+    # errors.extend(check_db_table_clashes(app_configs))\n     return errors\n\n\n@@ -27,7 +30,7 @@\n     # Group models by db_table\n     tables = defaultdict(list)\n     for model in apps.get_models():\n-        if model._meta.managed and not model._meta.proxy:\n+        if model._meta.managed and not model._meta.proxy and model._meta.db_table:\n             tables[model._meta.db_table].append(model._meta.label)\n\n     # Check for clashes\n\n```\n"}
{"instance_id": "django__django-11742", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -10,6 +10,7 @@\n         return [\n             *super().check(**kwargs),\n             *self._check_max_length_attribute(**kwargs),\n+            *self._check_choices_max_length(**kwargs),\n         ]\n \n     def _check_max_length_attribute(self, **kwargs):\n@@ -33,6 +34,23 @@\n         else:\n             return []\n \n+    def _check_choices_max_length(self, **kwargs):\n+        if self.choices is None or self.max_length is None:\n+            return []\n+\n+        errors = []\n+        for value, _ in self.flatchoices:\n+            if len(str(value)) > self.max_length:\n+                errors.append(\n+                    checks.Error(\n+                        f\"Choice '{value}' ({len(str(value))} characters) \"\n+                        f\"is longer than the max_length ({self.max_length}).\",\n+                        obj=self,\n+                        id='fields.E122',\n+                    )\n+                )\n+        return errors\n+\n     def cast_db_type(self, connection):\n         if self.max_length is None:\n             return connection.ops.cast_char_field_without_max_length\n\n```\n"}
{"instance_id": "django__django-11797", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -604,8 +604,10 @@\n             # guaranteed to be selected. Select it explicitly.\n             # If the queryset has been filtered, then the primary key is not\n             # guaranteed to be selected. Select it explicitly.\n-            if value.query.select_related or value.query.has_filters() or field.primary_key:\n-                value = value.values('pk')\n+            if not value.query.values_select and (value.query.select_related or value.query.has_filters() or field.primary_key):\n+                 # If values() has not been called, and any of these conditions are true,\n+                 # ensure the PK is selected for the subquery.\n+                 value = value.values('pk')\n\n         if hasattr(value.query, 'get_compiler'):\n             compiler = value.query.get_compiler(self.using, self.connection)\n\n```\n"}
{"instance_id": "django__django-11815", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -48,7 +48,13 @@\n\n class ChoicesSerializer(BaseSerializer):\n     def serialize(self):\n-        return serializer_factory(self.value.value).serialize()\n+        enum_class = type(self.value)\n+        module_name = enum_class.__module__\n+        enum_class_name = enum_class.__qualname__\n+        member_name = self.value.name\n+        imports = {f\"import {module_name}\"}\n+        representation = f\"{module_name}.{enum_class_name}.{member_name}\"\n+        return representation, imports\n\n\n class DateTimeSerializer(BaseSerializer):\n\n```\n"}
{"instance_id": "django__django-11848", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -18,13 +18,18 @@\n     else:\n         raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n     try:\n-        year = int(m.group('year'))\n-        if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n-        month = MONTHS.index(m.group('mon').lower()) + 1\n+        g = m.groupdict()\n+        year = int(g['year'])\n+        if len(g['year']) == 2:\n+            # RFC 7231 \u00a7 7.1.1.1: A recipient that parses a timestamp value with\n+            # a two-digit year MUST interpret YY as representing the\n+            # corresponding year in the current century if YY is less than or\n+            # equal to the last two digits of the current year + 50, otherwise\n+            # interpret YY as representing the corresponding year in the\n+            # preceding century.\n+            current_year = datetime.datetime.utcnow().year\n+            current_century = current_year // 100 * 100\n+            year += current_century - 100 if year > (current_year + 50) % 100 else current_century\n+        month = MONTHS.index(g['mon'].lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n         min = int(m.group('min'))\n\n```\n"}
{"instance_id": "django__django-11905", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -496,6 +496,12 @@\n \n         self.check_filterable(value)\n \n+        # Django ticket #30972: Prevent non-bool values for isnull lookup.\n+        if lookups == ['isnull'] and not isinstance(value, bool):\n+            raise ValueError(\n+                \"The QuerySet value for an isnull lookup must be True or False.\"\n+            )\n+\n         clause = self.where_class()\n         if reffed_expression:\n             condition = self.build_lookup(lookups, reffed_expression, value)\n\n```\n"}
{"instance_id": "django__django-11910", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -18,9 +18,6 @@\n                 remote_field_name = getattr(new_field.remote_field, 'field_name', None)\n                 if remote_field_name:\n                     to_field_rename_key = rename_key + (remote_field_name,)\n-                    if to_field_rename_key in self.renamed_fields:\n-                        # If the field referenced by to_field is renamed, revert\n-                        # the corresponding attribute on the new field before\n-                        # comparison to avoid generating AlterField operation.\n-                        new_field.remote_field.field_name = old_field.remote_field.field_name\n                 # Handle ForeignObjects which can have multiple from_fields/to_fields.\n                 from_fields = getattr(new_field, 'from_fields', None)\n                 if from_fields:\n\n```\n"}
{"instance_id": "django__django-11964", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -16,8 +16,8 @@\n                 len(value) > 1 and\n                 isinstance(value[-1], (Promise, str))\n             ):\n-                *value, label = value\n-                value = tuple(value)\n+                *values, label = value\n+                value = values[0] if len(values) == 1 else tuple(values)\n             else:\n                 label = key.replace('_', ' ').title()\n             labels.append(label)\n\n```\n"}
{"instance_id": "django__django-11999", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -761,9 +761,10 @@\n             # if the model defines a field with the same name as a classmethod.\n             if not isinstance(getattr(cls, self.attname, None), classmethod):\n                 setattr(cls, self.attname, self)\n-        if self.choices:\n+        # Only contribute the get_FIELD_display() method if the model doesn't\n+        # already define a method with that name.\n+        if self.choices and not hasattr(cls, 'get_%s_display' % self.name):\n             setattr(cls, 'get_%s_display' % self.name,\n                     curry(cls._get_FIELD_display, field=self))\n \n     def _check_fix_default_value(self):\n\n```\n"}
{"instance_id": "django__django-12113", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -45,7 +45,9 @@\n         # who are testing on databases without transactions or who are using\n         # a TransactionTestCase still get a clean database on every test run.\n         if serialize:\n-            self.connection._test_serialized_contents = self.serialize_db_to_string()\n+            # Don't serialize the database state when using keepdb with SQLite.\n+            if not (self.connection.vendor == 'sqlite' and keepdb):\n+                self.connection._test_serialized_contents = self.serialize_db_to_string()\n \n         call_command('createcachetable', database=self.connection.alias)\n \n\n```\n"}
{"instance_id": "django__django-12125", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -166,7 +166,11 @@\n             keywords[name] = value\n\n         # Work out path. The base class is Field, assume models.Field.\n-        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)\n+        # Use qualname for inner classes. If __qualname__ is not available\n+        # (Python < 3.3), fallback to __name__.\n+        klass = self.__class__\n+        module = klass.__module__\n+        name = getattr(klass, '__qualname__', klass.__name__)\n+        path = \"%s.%s\" % (module, name)\n         # If it's a core field, use \"models.\" shortcut.\n         if path.startswith('django.db.models.fields.'):\n             path = path.replace('django.db.models.fields.', 'django.db.models.', 1)\n\n```\n"}
{"instance_id": "django__django-12184", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "django__django-12284", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -598,5 +598,8 @@\n                 return getattr(self, field.attname)\n\n         def _get_FIELD_display(self, field):\n+            # Ensure we use the field from the instance's class, not potentially\n+            # one inherited from an abstract base class and passed via curry.\n+            field = self._meta.get_field(field.name)\n             value = getattr(self, field.attname)\n             return force_str(dict(field.flatchoices).get(value, value), strings_only=True)\n\n```\n"}
{"instance_id": "django__django-12286", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/checks/translation.py\n+++ b/django/core/checks/translation.py\n@@ -55,8 +55,10 @@\n @register(Tags.translation)\n def check_language_settings_consistent(app_configs, **kwargs):\n     \"\"\"Error if language settings are not consistent with each other.\"\"\"\n-    available_tags = {i for i, _ in settings.LANGUAGES} | {'en-us'}\n-    if settings.LANGUAGE_CODE not in available_tags:\n+    # Include LANGUAGES setting and the default LANGUAGE_CODE 'en-us',\n+    # which might not be in LANGUAGES.\n+    available_tags = {lang_code for lang_code, lang_name in settings.LANGUAGES} | {'en-us'}\n+    lang_code = settings.LANGUAGE_CODE\n+    base_lang_code = lang_code.split('-')[0]\n+    if lang_code not in available_tags and base_lang_code not in available_tags:\n         return [E004]\n     return []\n\n```\n"}
{"instance_id": "django__django-12308", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -20,6 +20,12 @@\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        try:\n+            return field.get_prep_value(value)\n+        except Exception:\n+            # Fallback for non-serializable values.\n+            return display_for_value(value, empty_value_display)\n     else:\n         return display_for_value(value, empty_value_display)\n \n```\n"}
{"instance_id": "django__django-12453", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -4,7 +4,7 @@ import time\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n from django.utils.six import StringIO\n from django.utils.six.moves import input\n \n@@ -128,8 +128,9 @@ class BaseDatabaseCreation(object):\n          the serialize_db_to_string method.\n          \"\"\"\n          data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n+                obj.save()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"\n\n```\n"}
{"instance_id": "django__django-12470", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1280,7 +1280,10 @@\n                             continue\n                         # We are ordering by the primary key, so we use the\n                         # primary key alias of the main table.\n-                    order_by.append(('%s.%s' % (self.quote_name_unless_alias(self.base_table), pk_col), descending))\n+                    order_by.append((\n+                        '%s.%s' % (self.quote_name_unless_alias(self.base_table), pk_col),\n+                        descending or name.startswith('-'),\n+                    ))\n                     else:\n                         # Ordering by a field from another model requires joining\n                         # that model. Extra tables are added only if they aren't\n\n```\n"}
{"instance_id": "django__django-12497", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -37,15 +37,7 @@\n                               \"which foreign key Django should use via the \"\n                               \"through_fields keyword argument.\") % (self, from_model_name),\n                             hint=(\n-                                'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n-                            ) % (\n-                                RECURSIVE_RELATIONSHIP_CONSTANT,\n-                                relationship_model_name,\n-                            ),\n-                            obj=self,\n-                            id='fields.E334',\n-                        )\n+                                'Specify the foreign keys for this relationship using '\n+                                'through_fields.'\n+                            ), obj=self, id='fields.E334')\n                     )\n \n                 if seen_to > 1 and not self.remote_field.through_fields:\n@@ -57,15 +49,7 @@\n                              \"which foreign key Django should use via the \"\n                              \"through_fields keyword argument.\" % (self, to_model_name),\n                             hint=(\n-                                'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n-                            ) % (\n-                                RECURSIVE_RELATIONSHIP_CONSTANT,\n-                                relationship_model_name,\n-                            ),\n-                            obj=self,\n-                            id='fields.E335',\n-                        )\n+                                'Specify the foreign keys for this relationship using '\n+                                'through_fields.'\n+                            ), obj=self, id='fields.E335')\n                     )\n \n                 if seen_from == 0 or seen_to == 0:\n```\n"}
{"instance_id": "django__django-12589", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -44,19 +44,17 @@\n              # Converts string references to expressions.\n              for expr in self.query.group_by:\n                  if not hasattr(expr, 'as_sql'):\n-                     expressions.append(self.query.resolve_ref(expr))\n+                     expr = self.query.resolve_ref(expr)\n+                 # If the expression is a Ref to an annotation, use the\n+                 # underlying annotation expression for grouping.\n+                 if isinstance(expr, Ref) and expr.refs in self.query.annotations:\n+                     expressions.append(self.query.annotations[expr.refs])\n                  else:\n                      expressions.append(expr)\n-         # Note that even if the group_by is set, it is only the minimal\n-         # set to group by. So, we need to add cols in select, order_by, and\n-         # having into the select in any case.\n          ref_sources = {\n              expr.source for expr in expressions if isinstance(expr, Ref)\n          }\n          for expr, _, _ in select:\n-             # Skip members of the select clause that are already included\n-             # by reference.\n-             if expr in ref_sources:\n-                 continue\n              cols = expr.get_group_by_cols()\n              for col in cols:\n                  expressions.append(col)\n```\n"}
{"instance_id": "django__django-12700", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -16,6 +16,8 @@\n                 cleansed = self.cleansed_substitute\n             elif isinstance(value, dict):\n                 cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n+            elif isinstance(value, (list, tuple)):\n+                cleansed = type(value)(self.cleanse_setting('', v) for v in value)\n             else:\n                 cleansed = value\n         except TypeError:\n\n```\n"}
{"instance_id": "django__django-12708", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -22,6 +22,18 @@\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n             **constraint_kwargs\n         )\n+        # If multiple constraints were found for an index, it might be\n+        # because there are both a unique and a non-unique index defined by\n+        # unique_together and index_together, respectively. In this case,\n+        # filter out the unique constraints and continue if only one index\n+        # remains.\n+        if len(constraint_names) > 1 and constraint_kwargs.get('index'):\n+            unique_constraint_names = self._constraint_names(\n+                model, columns, unique=True,\n+                exclude=meta_constraint_names | meta_index_names,\n+            )\n+            constraint_names = [name for name in constraint_names if name not in unique_constraint_names]\n+\n         if len(constraint_names) != 1:\n             raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n                 len(constraint_names),\n\n```\n"}
{"instance_id": "django__django-12747", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -61,4 +61,8 @@\n         for model, instances in self.data.items():\n             for instance in instances:\n                 setattr(instance, model._meta.pk.attname, None)\n+        # Ensure all collected models are present in the counter, even if the\n+        # deletion count is 0. Models are sorted alphabetically for stability.\n+        for model in sorted(self.data, key=lambda m: m._meta.label):\n+            deleted_counter.setdefault(model._meta.label, 0)\n         return sum(deleted_counter.values()), dict(deleted_counter)\n\n```\n"}
{"instance_id": "django__django-12856", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -413,6 +413,7 @@\n         errors.extend(cls._check_fields(**kwargs))\n         errors.extend(cls._check_m2m_through_same_relationship())\n         errors.extend(cls._check_ordering())\n+        errors.extend(cls._check_constraints())\n         errors.extend(cls._check_indexes(databases=kwargs.get('databases')))\n         errors.extend(cls._check_unique_together())\n         errors.extend(cls._check_swappable())\n@@ -459,6 +460,30 @@\n                     id='models.E016',\n                 )\n             ]\n+\n+    @classmethod\n+    def _check_constraints(cls):\n+        \"\"\"Check constraints for invalid field references.\"\"\"\n+        errors = []\n+        # Use total_constraints to include constraints from abstract parents.\n+        from django.db import models  # Avoid circular import\n+\n+        for constraint in cls._meta.total_constraints:\n+            if isinstance(constraint, models.UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        cls._meta.get_field(field_name)\n+                    except models.FieldDoesNotExist:\n+                        errors.append(\n+                            checks.Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                hint=\"Check the fields attribute of the UniqueConstraint.\",\n+                                obj=cls,\n+                                id='models.E040',\n+                            )\n+                        )\n         return errors\n \n     @classmethod\n\n```\n"}
{"instance_id": "django__django-12908", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -58,6 +58,7 @@\n         \"\"\"\n         Return a new QuerySet instance that will select only distinct results.\n         \"\"\"\n+        self._not_support_combined_queries('distinct')\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n         obj = self._chain()\n\n```\n"}
{"instance_id": "django__django-12915", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/staticfiles/handlers.py\n+++ b/django/contrib/staticfiles/handlers.py\n@@ -8,6 +8,7 @@\n from django.core.handlers.wsgi import WSGIHandler, get_path_info\n from django.http import Http404\n \n+from django.utils.asyncio import sync_to_async\n \n class StaticFilesHandlerMixin:\n     \"\"\"\n@@ -52,6 +53,13 @@\n         except Http404 as e:\n             return response_for_exception(request, e)\n \n+    async def get_response_async(self, request):\n+        try:\n+            return await sync_to_async(self.serve, thread_sensitive=True)(request)\n+        except Http404 as e:\n+            # response_for_exception() is synchronous.\n+            return await sync_to_async(response_for_exception, thread_sensitive=True)(request, e)\n+\n \n class StaticFilesHandler(StaticFilesHandlerMixin, WSGIHandler):\n     \"\"\"\n\n```\n"}
{"instance_id": "django__django-12983", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -10,4 +10,4 @@\n     else:\n         value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n     value = re.sub(r'[^\\w\\s-]', '', value.lower()).strip()\n-    return re.sub(r'[-\\s]+', '-', value)\n+    return re.sub(r'[-\\s]+', '-', value).strip('-_')\n\n```\n"}
{"instance_id": "django__django-13028", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -17,7 +17,7 @@\n from django.db.models.constants import LOOKUP_SEP\n from django.db.models.deletion import CASCADE, DO_NOTHING, SET_NULL\n from django.db.models.expressions import (\n-    Case, Col, Exists, ExpressionList, ExpressionWrapper, F, Func, OrderBy,\n+    Case, Col, Exists, Expression, ExpressionList, ExpressionWrapper, F, Func, OrderBy,\n     OuterRef, RawSQL, Ref, Star, Subquery, Value, When, Window, WindowFrame,\n )\n from django.db.models.fields import Field\n@@ -1128,15 +1128,17 @@\n\n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        # Check filterable attribute only if it's an Expression subclass.\n+        # Model instances used as filter values should not be checked this way,\n+        # nor should simple values like strings or numbers.\n+        if isinstance(expression, Expression) and not getattr(expression, 'filterable', True):\n             raise NotSupportedError(\n-                expression.__class__.__name__ + ' is disallowed in the filter '\n-                'clause.'\n+                f'{expression.__class__.__name__} is disallowed in the filter clause.'\n             )\n         if hasattr(expression, 'get_source_expressions'):\n             for expr in expression.get_source_expressions():\n-                self.check_filterable(expr)\n-\n+                if expr is not expression:  # Avoid infinite recursion.\n+                    self.check_filterable(expr)\n \n     def build_lookup(self, lookups, lhs, rhs):\n         \"\"\"\n\n```\n"}
{"instance_id": "django__django-13033", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1500,25 +1500,28 @@\n                 continue\n \n             if final_alias and final_field.is_relation:\n+                # Check if the ordering is on the relation field itself (e.g.\n+                # 'author') or on the foreign key column (e.g. 'author_id').\n+                lookup_name = names[-1]\n                 # Ordering by related field name orders by the remote model's\n                 # ordering. Only do this if the lookup targeted the relation\n                 # name, not the fk attribute name (e.g. 'author' not 'author_id').\n-                if not path[-1].m2m:\n+                if lookup_name == final_field.name and not path[-1].m2m:\n                     # Add ordering by the related model's meta ordering.\n                     # Ensure that the remote model's ordering is applied.\n                     related_ordering = final_field.related_model._meta.ordering\n                     if related_ordering:\n                         for order in related_ordering:\n                             self.add_ordering(\n-                                order, final_alias, False,\n-                                related_field_ordering=True,\n-                                descending=descending,\n+                                order, final_alias, False, related_field_ordering=True,\n+                                # Reverse ordering if the original field was descending.\n+                                descending=descending != order.startswith('-'),\n                             )\n                         continue\n                     else:\n                         # Order by the related model's PK if there's no default ordering.\n                         pk_ordering = final_field.related_model._meta.pk.name\n+                        # Apply original direction to PK ordering.\n                         if descending:\n                             pk_ordering = '-' + pk_ordering\n                         self.add_ordering(\n@@ -1526,6 +1529,8 @@\n                             related_field_ordering=True,\n                         )\n                         continue\n+                # If lookup_name != final_field.name (e.g. 'author_id'),\n+                # or if it's an M2M, fall through to order by the column.\n \n             if not getattr(final_field, 'contains_aggregate', False):\n                 # Use the default column for ordering if it's not an aggregate.\n\n```\n"}
{"instance_id": "django__django-13158", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -908,8 +908,13 @@\n \n     def none(self):\n         \"\"\"Return an empty QuerySet.\"\"\"\n-        clone = self._chain()\n+        clone = self._chain()\n+        # If this is a combined query, cloning it will preserve the\n+        # combinator. Clear the combination state to ensure the query is truly\n+        # empty.\n+        if clone.query.combinator:\n+            clone.query.combinator = None\n+            clone.query.combined_queries = ()\n+            clone.query.combinator_all = False\n         clone.query.set_empty()\n         return clone\n \n\n```\n"}
{"instance_id": "django__django-13220", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/exceptions.py\n+++ b/django/core/exceptions.py\n@@ -63,3 +63,43 @@\n         else:\n             error_dict.setdefault(NON_FIELD_ERRORS, []).extend(self.error_list)\n         return error_dict\n+\n+    def __eq__(self, other):\n+        if not isinstance(other, ValidationError):\n+            return NotImplemented\n+\n+        def _get_error_sort_key(error):\n+            \"\"\"\n+            Generate a sort key for a ValidationError. Used to compare lists\n+            of errors independent of their order. Make sure the key is stable\n+            and handles different types for params.\n+            \"\"\"\n+            params_repr = tuple(sorted(error.params.items())) if isinstance(error.params, dict) else error.params\n+            return (str(error.message), error.code, params_repr)\n+\n+        def _compare_error_lists(list1, list2):\n+            \"\"\"Compare two lists of ValidationErrors independent of order.\"\"\"\n+            if len(list1) != len(list2):\n+                return False\n+            try:\n+                sorted_list1 = sorted(list1, key=_get_error_sort_key)\n+                sorted_list2 = sorted(list2, key=_get_error_sort_key)\n+            except TypeError:\n+                # If params contains unorderable types, sorting fails.\n+                # Consider these ValidationErrors unequal.\n+                return False\n+\n+            for e1, e2 in zip(sorted_list1, sorted_list2):\n+                if not (e1.message == e2.message and e1.code == e2.code and e1.params == e2.params):\n+                    return False\n+            return True\n+\n+        self_is_dict = hasattr(self, 'error_dict')\n+        other_is_dict = hasattr(other, 'error_dict')\n+\n+        if self_is_dict != other_is_dict:\n+            return False\n+\n+        if self_is_dict:  # Both have error_dict\n+            if set(self.error_dict.keys()) != set(other.error_dict.keys()):\n+                return False\n+            return all(_compare_error_lists(self.error_dict[k], other.error_dict[k]) for k in self.error_dict)\n+        else:  # Both have error_list\n+            return _compare_error_lists(self.error_list, other.error_list)\n\n```\n"}
{"instance_id": "django__django-13230", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -131,6 +131,7 @@\n             if updateddate and is_naive(updateddate):\n                 updateddate = make_aware(updateddate, tz)\n \n+            comments = self._get_dynamic_attr('item_comments', item)\n             feed.add_item(\n                 title=title,\n                 link=link,\n@@ -144,6 +145,7 @@\n                 author_name=author_name,\n                 author_email=author_email,\n                 author_link=author_link,\n+                comments=comments,\n                 categories=self._get_dynamic_attr('item_categories', item),\n                 item_copyright=self._get_dynamic_attr('item_copyright', item),\n                 **self.item_extra_kwargs(item)\n\n```\n"}
{"instance_id": "django__django-13265", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -45,14 +45,17 @@\n         self.database_forwards(app_label, schema_editor, from_state, to_state)\n \n     def references_field(self, model_name, name, app_label):\n-        return (\n-            self.references_model(model_name, app_label) and\n-            (\n-                self.order_with_respect_to is None or\n-                name == self.order_with_respect_to\n-            )\n-        )\n+        # Check if the operation targets the specified model\n+        if not self.references_model(model_name, app_label):\n+            return False\n+\n+        # Check if the field being queried is the ForeignKey field\n+        if name == self.order_with_respect_to:\n+            return True\n+\n+        # Check if the field being queried is the implicit '_order' field\n+        if name == '_order':\n+            return True\n+\n+        return False\n \n     def describe(self):\n         return \"Set order_with_respect_to on %s to %s\" % (self.name, self.order_with_respect_to)\n\n```\n"}
{"instance_id": "django__django-13315", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -29,5 +29,5 @@\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to).distinct()\n\n```\n"}
{"instance_id": "django__django-13321", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -1,4 +1,5 @@\n import base64\n+import binascii\n import logging\n import string\n import warnings\n@@ -113,7 +114,11 @@\n \n     def _legacy_decode(self, session_data):\n         # RemovedInDjango40Warning: pre-Django 3.1 format will be invalid.\n-        encoded_data = base64.b64decode(session_data.encode('ascii'))\n+        try:\n+            encoded_data = base64.b64decode(session_data.encode('ascii'))\n+        except (binascii.Error, ValueError):\n+            # If session_data is not valid base64, treat it as empty.\n+            return {}\n         try:\n             # could produce ValueError if there is no ':'\n             hash, serialized = encoded_data.split(b':', 1)\n\n```\n"}
{"instance_id": "django__django-13401", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -10,17 +10,34 @@\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            # Compare creation_counter first for performance.\n+            if self.creation_counter != other.creation_counter:\n+                return False\n+            # If creation counters are equal, compare models.\n+            self_model = getattr(self, 'model', None)\n+            other_model = getattr(other, 'model', None)\n+            return self_model == other_model\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n         if isinstance(other, Field):\n-            return self.creation_counter < other.creation_counter\n+            # Order by creation_counter first, then model.\n+            if self.creation_counter != other.creation_counter:\n+                return self.creation_counter < other.creation_counter\n+            self_model = getattr(self, 'model', None)\n+            other_model = getattr(other, 'model', None)\n+            # Model instances should sort after None.\n+            if self_model is None and other_model is None:\n+                return False  # Equal\n+            if self_model is None:\n+                return True   # self (None) < other (Model)\n+            if other_model is None:\n+                return False  # self (Model) > other (None)\n+            # Both have models, compare by model label.\n+            return self.model._meta.label < other.model._meta.label\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash((self.creation_counter, getattr(self, 'model', None)))\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n\n```\n"}
{"instance_id": "django__django-13447", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -2,7 +2,7 @@\n         Return a sorted list of all the installed apps that have been\n         registered in this site.\n         \"\"\"\n-        app_dict = self._build_app_dict(request)\n+        app_dict = self.build_app_dict(request)\n\n         # Sort the apps alphabetically.\n         app_list = sorted(app_dict.values(), key=lambda x: x['name'].lower())\n@@ -33,7 +33,7 @@\n         return TemplateResponse(request, self.index_template or 'admin/index.html', context)\n\n     def app_index(self, request, app_label, extra_context=None):\n-        app_dict = self._build_app_dict(request, app_label)\n+        app_dict = self.build_app_dict(request, app_label)\n         if not app_dict:\n             raise Http404('The requested admin page does not exist.')\n         # Sort the models alphabetically within each app.\n@@ -54,3 +54,58 @@\n             'admin/%s/app_index.html' % app_label,\n             'admin/app_index.html'\n         ], context)\n+\n+    def build_app_dict(self, request, app_label=None):\n+        \"\"\"\n+        Build the app dictionary. Filtered by app_label if provided.\n+        \"\"\"\n+        from django.urls import NoReverseMatch\n+\n+        app_dict = {}\n+\n+        if app_label:\n+            models = {\n+                m: ma for m, ma in self._registry.items()\n+                if m._meta.app_label == app_label\n+            }\n+        else:\n+            models = self._registry\n+\n+        for model, model_admin in models.items():\n+            app_label = model._meta.app_label\n+\n+            has_module_perms = model_admin.has_module_permission(request)\n+            if not has_module_perms:\n+                continue\n+\n+            perms = model_admin.get_model_perms(request)\n+\n+            # Check whether user has any perm for this module.\n+            # If so, add the module to the model_list.\n+            if True not in perms.values():\n+                continue\n+\n+            info = (app_label, model._meta.model_name)\n+            model_dict = {\n+                'name': capfirst(model._meta.verbose_name_plural),\n+                'object_name': model._meta.object_name,\n+                'model': model,\n+                'perms': perms,\n+                'admin_url': None,\n+                'add_url': None,\n+            }\n+            if perms.get('change') or perms.get('view'):\n+                try:\n+                    model_dict['admin_url'] = reverse('admin:%s_%s_changelist' % info, current_app=self.name)\n+                except NoReverseMatch:\n+                    pass\n+            if perms.get('add'):\n+                try:\n+                    model_dict['add_url'] = reverse('admin:%s_%s_add' % info, current_app=self.name)\n+                except NoReverseMatch:\n+                    pass\n+\n+            if app_label in app_dict:\n+                app_dict[app_label]['models'].append(model_dict)\n+            else:\n+                app_dict[app_label] = {\n+                    'name': apps.get_app_config(app_label).verbose_name,\n+                    'app_label': app_label,\n+                    'app_url': reverse(\n+                        'admin:app_list',\n+                        kwargs={'app_label': app_label},\n+                        current_app=self.name,\n+                    ),\n+                    'has_module_perms': has_module_perms,\n+                    'models': [model_dict],\n+                }\n+\n+        return app_dict\n```\n"}
{"instance_id": "django__django-13448", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -57,9 +57,10 @@\n         # We then serialize the current state of the database into a string\n         # and store it on the connection. This slightly horrific process is so people\n         # who are testing on databases without transactions or who are using\n-        # a TransactionTestCase still get a clean database on every test run.\n-        if serialize:\n+        # a TransactionTestCase still get a clean database on every test run. Only\n+        # serialize the database if migrations are applied, because the database\n+        # tables might not exist otherwise.\n+        if serialize and self.connection.settings_dict['TEST']['MIGRATE']:\n             self.connection._test_serialized_contents = self.serialize_db_to_string()\n \n         call_command('createcachetable', database=self.connection.alias)\n\n```\n"}
{"instance_id": "django__django-13551", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -1,20 +1,21 @@\n     def _make_hash_value(self, user, timestamp):\n         \"\"\"\n         Hash the user's primary key and some user state that's sure to change\n-        after a password reset to produce a token that invalidated when it's\n-        used:\n-        1. The password field will change upon a password reset (even if the\n-           same password is chosen, due to password salting).\n-        2. The last_login field will usually be updated very shortly after\n-           a password reset.\n-        Failing those things, settings.PASSWORD_RESET_TIMEOUT eventually\n-        invalidates the token.\n+        after a password reset or email change to produce a token that is\n+        invalidated when it's used:\n+\n+        1. The user's primary key.\n+        2. The user's password hash.\n+        3. The last login timestamp.\n+        4. The user's email address.\n+        5. The timestamp when the token was generated.\n+\n+        Failing these things, settings.PASSWORD_RESET_TIMEOUT eventually\n+        invalidates the token. Any change to the user's password or email\n+        address invalidates the token.\n\n         Running this data through salted_hmac() prevents password cracking\n         attempts using the reset token, provided the secret isn't compromised.\n         \"\"\"\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n         login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        email_field_name = user.__class__.get_email_field_name()\n+        email = getattr(user, email_field_name, None) or ''\n+        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp) + email\n\n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n\n```\n"}
{"instance_id": "django__django-13590", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1320,10 +1320,13 @@\n         # The items of the iterable may be expressions and need resolving.\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and need resolving.\n-            value = type(value)(\n-                self.resolve_lookup_value(item, can_reuse, allow_joins)\n-                for item in value\n-            )\n+            resolved_values = []\n+            for item in value:\n+                resolved_values.append(\n+                    self.resolve_lookup_value(item, can_reuse, allow_joins)\n+                )\n+            # Preserve the type (list or tuple) of the value.\n+            value = type(value)(resolved_values)\n         elif isinstance(value, QuerySet):\n             value = value.query\n         elif hasattr(value, 'resolve_expression'):\n```\n"}
{"instance_id": "django__django-13658", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -10,7 +10,12 @@\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(\n+            prog=self.prog_name,\n+            usage='%(prog)s subcommand [options] [args]',\n+            add_help=False,\n+            allow_abbrev=False,\n+        )\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n\n```\n"}
{"instance_id": "django__django-13660", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -42,14 +42,16 @@\n \n     def handle(self, **options):\n         # Execute the command and exit.\n+        # Execution environment contains __name__ = '__main__' to mimic execution via\n+        # python -m module.\n         if options['command']:\n-            exec(options['command'])\n+            exec(options['command'], {'__name__': '__main__'})\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n         if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+            exec(sys.stdin.read(), {'__name__': '__main__'})\n             return\n \n         available_shells = [options['interface']] if options['interface'] else self.shells\n\n```\n"}
{"instance_id": "django__django-13710", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -25,11 +25,18 @@\n         self.parent_model = parent_model\n         self.opts = self.model._meta\n         self.has_registered_model = admin_site.is_registered(self.model)\n+        # Store verbose_name/plural defined on the InlineModelAdmin subclass\n+        # before defaulting to related model opts values.\n+        _verbose_name = self.verbose_name\n+        _verbose_name_plural = self.verbose_name_plural\n         super().__init__()\n         if self.verbose_name is None:\n             self.verbose_name = self.model._meta.verbose_name\n         if self.verbose_name_plural is None:\n-            self.verbose_name_plural = self.model._meta.verbose_name_plural\n+            # If verbose_name was manually specified, pluralize that. Otherwise,\n+            # use the model's default plural name.\n+            if _verbose_name:\n+                self.verbose_name_plural = '%ss' % _verbose_name\n+            else:\n+                self.verbose_name_plural = self.model._meta.verbose_name_plural\n \n     @property\n     def media(self):\n\n```\n"}
{"instance_id": "django__django-13757", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/json.py\n+++ b/django/db/models/fields/json.py\n@@ -43,14 +43,18 @@\n     # key__isnull=False is the same as has_key='key'\n     def as_oracle(self, compiler, connection):\n         if not self.rhs:\n-            return HasKey(self.lhs.lhs, self.lhs.key_name).as_oracle(compiler, connection)\n-        return super().as_sql(compiler, connection)\n+            has_key_lookup = HasKey(self.lhs.lhs, self.lhs.key_name)\n+            return has_key_lookup.as_oracle(compiler, connection)\n+        # key__isnull=True should be the negation of HasKey.\n+        has_key_lookup = HasKey(self.lhs.lhs, self.lhs.key_name)\n+        sql, params = has_key_lookup.as_oracle(compiler, connection)\n+        return 'NOT (%s)' % sql, params\n \n     def as_sqlite(self, compiler, connection):\n         if not self.rhs:\n-            return HasKey(self.lhs.lhs, self.lhs.key_name).as_sqlite(compiler, connection)\n-        return super().as_sql(compiler, connection)\n+            has_key_lookup = HasKey(self.lhs.lhs, self.lhs.key_name)\n+            return has_key_lookup.as_sqlite(compiler, connection)\n+        # key__isnull=True should be the negation of HasKey.\n+        has_key_lookup = HasKey(self.lhs.lhs, self.lhs.key_name)\n+        sql, params = has_key_lookup.as_sqlite(compiler, connection)\n+        return 'NOT (%s)' % sql, params\n\n```\n"}
{"instance_id": "django__django-13768", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/dispatch/dispatcher.py\n+++ b/django/dispatch/dispatcher.py\n@@ -1,7 +1,11 @@\n+import logging\n import weakref\n from collections import defaultdict\n \n from .utils import NO_RECEIVERS, ref\n \n+\n+logger = logging.getLogger('django.dispatch')\n+\n # A marker for caching\n NO_RECEIVERS_MARKER = object()\n \n@@ -56,8 +60,9 @@\n \n         Return a list of tuple pairs [(receiver, response), ... ].\n \n-        If any receiver raises an error (specifically any subclass of\n-        Exception), return the error instance as the result for that receiver.\n+        If any receiver raises an error (specifically any subclass of Exception),\n+        the error instance is returned as the result for that receiver and\n+        logged (`logger.exception()`).\n         \"\"\"\n         if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n             return []\n@@ -69,6 +74,10 @@\n             try:\n                 response = receiver(signal=self, sender=sender, **named)\n             except Exception as err:\n+                logger.exception(\n+                    'Exception caught in signal handler %s', receiver,\n+                    # extra={'signal': self, 'sender': sender, 'receiver': receiver}\n+                )\n                 responses.append((receiver, err))\n             else:\n                 responses.append((receiver, response))\n\n```\n"}
{"instance_id": "django__django-13925", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/checks/model_checks.py\n+++ b/django/core/checks/model_checks.py\n@@ -51,7 +51,10 @@\n     for model in models:\n         if model._meta.managed and not model._meta.proxy and not model._meta.abstract:\n             # Check for W042.\n-            if not any(f.primary_key for f in model._meta.local_fields):\n+            # If the model has an explicit primary key, any primary key field\n+            # inherited from an abstract base class, or a parent link to\n+            # another model, use that field. Otherwise, check if default\n+            # auto field is configured.\n+            if model._meta.pk is None:\n                 app_label = model._meta.app_label\n                 try:\n                     app_config = apps.get_app_config(app_label)\n\n```\n"}
{"instance_id": "django__django-13933", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -80,8 +80,8 @@\n \t# This class is a subclass of ChoiceField for purity, but it doesn't\n \t# actually use any of ChoiceField's implementation.\n \tdefault_error_messages = {\n-\t\t'invalid_choice': _('Select a valid choice. That choice is not one of'\n-\t\t\t\t\t\t\t' the available choices.'),\n+\t\t'invalid_choice': _('Select a valid choice. %(value)s is not one of the'\n+\t\t\t\t\t\t\t' available choices.'),\n \t}\n \titerator = ModelChoiceIterator\n\n@@ -111,6 +111,7 @@\n \t\t\traise ValidationError(\n \t\t\t\tself.error_messages['invalid_choice'],\n \t\t\t\tcode='invalid_choice',\n+\t\t\t\tparams={'value': value},\n \t\t\t)\n \t\treturn value\n\n```\n"}
{"instance_id": "django__django-13964", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -29,8 +29,10 @@\n                 # If the relationship's pk/to_field was changed, clear the\n                 # cached relationship.\n                 if getattr(obj, field.target_field.attname) != getattr(self, field.attname):\n-                    field.delete_cached_value(self)\n-\n+                    field.delete_cached_value(self)\n+                    # Update the foreign key attribute value, otherwise it may\n+                    # be stale (e.g. assigned before the related object's pk was set).\n+                    setattr(self, field.attname, obj.pk)\n\n     def delete(self, using=None, keep_parents=False):\n         using = using or router.db_for_write(self.__class__, instance=self)\n\n```\n"}
{"instance_id": "django__django-14016", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -17,13 +17,23 @@\n         if not isinstance(other, Q):\n             raise TypeError(other)\n\n-        # If the other Q() is empty, ignore it and just use `self`.\n+        # If the other Q object is empty, ignore it and return a copy of self.\n         if not other:\n-            return copy.deepcopy(self)\n-        # Or if this Q is empty, ignore it and just use `other`.\n+            # Recreate the Q object to avoid modifying the original object\n+            # when the new Q object is combined or mutated later.\n+            obj = type(self)(\n+                *self.children, _connector=self.connector, _negated=self.negated\n+            )\n+            return obj\n+        # Or if this Q object is empty, ignore it and return a copy of other.\n         elif not self:\n-            return copy.deepcopy(other)\n+            # Recreate the Q object to avoid modifying the original object\n+            # when the new Q object is combined or mutated later.\n+            obj = type(self)(\n+                *other.children, _connector=other.connector, _negated=other.negated\n+            )\n+            return obj\n\n         obj = type(self)()\n         obj.connector = conn\n\n```\n"}
{"instance_id": "django__django-14017", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -1,5 +1,6 @@\n from django.db.models.constants import LOOKUP_SEP\n from django.utils.tree import Node\n+from django.db.models.expressions import Expression\n \n \n class Q(Node):\n@@ -14,19 +15,29 @@\n         super().__init__(children=[*args, *sorted(kwargs.items())], connector=_connector, negated=_negated)\n \n     def _combine(self, other, conn):\n-        if not isinstance(other, Q):\n-            raise TypeError(other)\n+        # self is the Q instance. other is the operand (Q or Expression).\n+        if not isinstance(other, (Q, Expression)):\n+            raise TypeError(\n+                f\"Cannot combine Q object with object of type \"\n+                f\"{type(other).__name__}: {other}\"\n+            )\n+\n+        other_is_expression = isinstance(other, Expression)\n \n         # If the other Q() is empty, ignore it and just use `self`.\n-        if not other:\n-            _, args, kwargs = self.deconstruct()\n-            return type(self)(*args, **kwargs)\n+        if isinstance(other, Q) and not other:\n+            return self\n         # Or if this Q is empty, ignore it and just use `other`.\n         elif not self:\n-            _, args, kwargs = other.deconstruct()\n-            return type(other)(*args, **kwargs)\n+            # Return other (if Q) or Q(other) (if Expression)\n+            if other_is_expression:\n+                obj = type(self)()\n+                obj.add(other, conn)  # Add expression with the correct connector\n+                return obj\n+            else:  # other is a non-empty Q\n+                return other\n \n+        # Both self and other are non-empty (Q or Expression)\n         obj = type(self)()\n         obj.connector = conn\n         obj.add(self, conn)\n@@ -37,8 +48,22 @@\n     def __or__(self, other):\n         return self._combine(other, self.OR)\n \n+    def __ror__(self, other):\n+        # Handles `Expression | Q`\n+        if not isinstance(other, Expression):\n+            return NotImplemented\n+        # Delegates to Q | Expression\n+        return self._combine(other, self.OR)\n+\n     def __and__(self, other):\n         return self._combine(other, self.AND)\n+\n+    def __rand__(self, other):\n+        # Handles `Expression & Q`\n+        if not isinstance(other, Expression):\n+            return NotImplemented\n+        # Delegates to Q & Expression\n+        return self._combine(other, self.AND)\n \n     def __invert__(self):\n         obj = type(self)()\n\n```\n"}
{"instance_id": "django__django-14155", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -31,9 +31,18 @@\n \n class ResolverMatch:\n     def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n-        self.func = func\n-        self.args = args\n-        self.kwargs = kwargs\n+        # If the passed function is a partial, replace it with the real function\n+        # and merge the partial arguments.\n+        if isinstance(func, functools.partial):\n+            self.func = func.func\n+            self.args = func.args + args\n+            self.kwargs = func.keywords.copy()\n+            self.kwargs.update(kwargs)\n+        else:\n+            self.func = func\n+            self.args = args\n+            self.kwargs = kwargs\n+\n         self.url_name = url_name\n         self.route = route\n         self.tried = tried\n@@ -46,13 +55,13 @@\n         self.namespaces = [x for x in namespaces if x] if namespaces else []\n         self.namespace = ':'.join(self.namespaces)\n \n-        if not hasattr(func, '__name__'):\n+        if not hasattr(self.func, '__name__'):\n             # A class-based view\n-            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n+            self._func_path = self.func.__class__.__module__ + '.' + self.func.__class__.__name__\n         else:\n             # A function-based view\n-            self._func_path = func.__module__ + '.' + func.__name__\n+            self._func_path = self.func.__module__ + '.' + self.func.__name__\n \n         view_path = url_name or self._func_path\n         self.view_name = ':'.join(self.namespaces + [view_path])\n\n```\n"}
{"instance_id": "django__django-14238", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -74,7 +74,7 @@\n         return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n\n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        return issubclass(subclass, self._subclasses) or super().__subclasscheck__(subclass)\n\n\n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n\n```\n"}
{"instance_id": "django__django-14382", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -16,7 +16,10 @@\n                  raise CommandError(e)\n          else:\n              if app_or_project == 'app':\n-                 self.validate_name(os.path.basename(target), 'directory')\n+                 # Force removal of trailing path separator, if present\n+                 target = target.rstrip(os.sep)\n+                 if not os.path.basename(target):\n+                     raise CommandError(\"'%s' is not a valid directory name. Please make sure the directory name is a valid identifier.\" % target)\n+                 self.validate_name(os.path.basename(target), 'directory')\n              top_dir = os.path.abspath(os.path.expanduser(target))\n              if not os.path.exists(top_dir):\n                  raise CommandError(\"Destination directory '%s' does not \"\n\n```\n"}
{"instance_id": "django__django-14411", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/contrib/auth/widgets.py\n+++ b/django/contrib/auth/widgets.py\n@@ -15,3 +15,8 @@\n         context = super().get_context(name, value, attrs)\n         context['widget']['hash'] = value or _('Unknown')\n         return context\n+\n+    def id_for_label(self, id_):\n+        \"\"\"\n+        Don't bind the 'for' attribute to the ID for this widget.\n+        \"\"\"\n+        return None  # No labelable element is rendered.\n```\n"}
{"instance_id": "django__django-14534", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -244,7 +244,7 @@\n     @property\n     def id_for_label(self):\n         \"\"\"Return the ID for the label.\"\"\"\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs'].get('id')\n\n     @property\n     def choice_label(self):\n\n```\n"}
{"instance_id": "django__django-14580", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -170,6 +170,7 @@\n             # It's a Model subclass\n             elif isinstance(value, type) and issubclass(value, models.Model):\n                 if value is models.Model:\n+                    self.imports.add(\"from django.db import models\")\n                     return \"models.Model\"\n                 elif hasattr(value, '_meta') and value._meta.auto_created:\n                     # Using a class which was created during migration execution\n```\n"}
{"instance_id": "django__django-14608", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -5,5 +5,8 @@\n         \"\"\"\n         if self._non_form_errors is None:\n             self.full_clean()\n+        # Ensure the ErrorList rendered via __str__ uses the 'nonform' class.\n+        if self._non_form_errors is not None:\n+            self._non_form_errors.error_class = 'nonform'\n         return self._non_form_errors\n \n     @property\n\n```\n"}
{"instance_id": "django__django-14667", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "django__django-14672", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -1,7 +1,7 @@\n from django.core import exceptions\n from django.db.models.query_utils import PathInfo\n from django.utils.functional import cached_property\n-\n+from django.utils.hashable import make_hashable\n\n # Private API\n\n@@ -137,7 +137,7 @@\n         # ManyToManyRel specific identity values.\n         return super().identity + (\n             self.through._meta.label_lower if self.through else None,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )\n\n\n```\n"}
{"instance_id": "django__django-14730", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1017,6 +1017,9 @@\n             )\n         self.has_null_arg = 'null' in kwargs\n\n+        # Store the original related_name argument for checks\n+        self._related_name_passed_by_user = related_name\n+\n         super().__init__(\n             related_name=related_name,\n             related_query_name=related_query_name,\n@@ -1034,6 +1037,7 @@\n             *self._check_relationship_model(**kwargs),\n             *self._check_ignored_options(**kwargs),\n             *self._check_table_uniqueness(**kwargs),\n+            *self._check_related_name_for_symmetrical(**kwargs),\n         ]\n\n     def _check_unique(self, **kwargs):\n@@ -1106,6 +1110,19 @@\n             ]\n         return []\n\n+    def _check_related_name_for_symmetrical(self, **kwargs):\n+        if self.remote_field.symmetrical and self._related_name_passed_by_user is not None:\n+            return [\n+                checks.Error(\n+                    \"related_name must not be provided for symmetrical \"\n+                    \"ManyToManyField instances.\",\n+                    hint=\"Remove the related_name argument.\",\n+                    obj=self,\n+                    id='fields.E332',\n+                )\n+            ]\n+        return []\n+\n     def _check_relationship_model(self, from_model=None, **kwargs):\n         if self.remote_field.through is not None and not self.remote_field.through._meta.auto_created:\n             # Skip checks if the through model is abstract.\n\n```\n"}
{"instance_id": "django__django-14752", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -19,13 +19,7 @@\n\n         self.object_list = self.get_queryset()\n         context = self.get_context_data()\n-        return JsonResponse({\n-            'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n-            ],\n-            'pagination': {'more': context['page_obj'].has_next()},\n-        })\n+        return self.render_to_response(context, to_field_name)\n\n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n@@ -40,3 +34,13 @@\n         if search_use_distinct:\n             qs = qs.distinct()\n         return qs\n+\n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"Convert an object to an autocomplete result dictionary.\"\"\"\n+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n+\n+    def render_to_response(self, context, to_field_name):\n+        \"\"\"Return a JSON response containing results.\"\"\"\n+        return JsonResponse({\n+            'results': [self.serialize_result(obj, to_field_name) for obj in context['object_list']],\n+            'pagination': {'more': context['page_obj'].has_next()},\n+        })\n```\n"}
{"instance_id": "django__django-14787", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -37,8 +37,11 @@\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n         bound_method = partial(method.__get__(self, type(self)))\n+        # Ensure the partial has the attributes of the original method\n+        # for decorators like @wraps to work correctly.\n+        update_wrapper(bound_method, method)\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\n\n     # Copy any attributes that a decorator adds to the function it decorates.\n\n```\n"}
{"instance_id": "django__django-14855", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -240,15 +240,17 @@\n                 elif isinstance(f.remote_field, models.ManyToOneRel) and value is not None:\n                     # Handle ForeignKey or OneToOneField.\n                     remote_obj = f.remote_field.model._base_manager.get(pk=value)\n-                    view_name = 'admin:%s_%s_change' % (\n+                    admin_site = self.model_admin.admin_site\n+                    view_name = '%s:%s_%s_change' % (\n+                        admin_site.name,\n                         f.remote_field.model._meta.app_label,\n                         f.remote_field.model._meta.model_name,\n                     )\n                     try:\n-                        url = reverse(view_name, args=[quote(remote_obj.pk)])\n+                        url = reverse(view_name, args=[quote(remote_obj.pk)], current_app=admin_site.name)\n                         result_repr = format_html(\n                             '<a href=\"{}\"{}>{}</a>',\n                             url,\n-                            mark_safe(f' data-popup-opener=\"{quote(remote_obj.pk)}\"') if model_admin.is_popup(request=None) else '',\n+                            mark_safe(f' data-popup-opener=\"{quote(remote_obj.pk)}\"') if model_admin.is_popup() else '',\n                             remote_obj,\n                         )\n                     except NoReverseMatch:\n\n```\n"}
{"instance_id": "django__django-14915", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1168,6 +1168,9 @@\n     def __str__(self):\n         return str(self.value)\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n     def __eq__(self, other):\n         if isinstance(other, ModelChoiceIteratorValue):\n             other = other.value\n\n```\n"}
{"instance_id": "django__django-14997", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -1,6 +1,7 @@\n import copy\n import logging\n \n+from django.db.backends.base.schema import BaseDatabaseSchemaEditor\n from django.db.backends.ddl_references import Statement\n from django.db.backends.sqlite3.introspection import DatabaseIntrospection\n from django.db.models.fields.related import ManyToManyField\n@@ -9,7 +10,7 @@\n logger = logging.getLogger('django.db.backends.schema')\n \n \n-class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n+class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n \n     sql_rename_table = \"ALTER TABLE %(old_table)s RENAME TO %(new_table)s\"\n     sql_drop_table = \"DROP TABLE %(table)s\"\n@@ -148,6 +149,26 @@\n         # Roll back the temporary table rename.\n         self.execute(self.sql_rename_table % {'old_table': self.quote_name(temp_table_name), 'new_table': table})\n \n+    def execute(self, sql, params=()):\n+        # Override execute to handle Statements containing column expressions\n+        # which may need unqualified column names in index definitions.\n+        if isinstance(sql, Statement) and \\\n+           (sql.template == self.sql_create_unique_index or sql.template == self.sql_create_index):\n+            # Importing here avoids potential circular import errors.\n+            from django.db.models.sql.datastructures import Expressions\n+            columns_part = sql.parts.get('columns')\n+            if isinstance(columns_part, Expressions) and columns_part.expressions:\n+                compiler = columns_part.compiler\n+                setattr(compiler, 'omit_col_alias', True)\n+                try:\n+                    # Compile the statement with the modified compiler context.\n+                    sql, params = sql.as_sql(self.connection)\n+                finally:\n+                    delattr(compiler, 'omit_col_alias')\n+                # Execute the compiled SQL string.\n+                super().execute(sql, params)\n+                return  # Don't execute again below.\n+        super().execute(sql, params)\n+\n     def quote_value(self, value):\n         # The backend's make_debug_cursor wrapper creates Database.Cursor objects\n         # which have quote_value().\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -409,6 +409,9 @@\n \n     def as_sql(self, compiler, connection):\n         qn = compiler.quote_name_unless_alias\n+        # Some backends (SQLite) don't support qualified column names in\n+        # index expressions.\n+        if getattr(compiler, 'omit_col_alias', False):\n+            return qn(self.target.column)\n         if self.alias:\n             return '%s.%s' % (qn(self.alias), qn(self.target.column))\n         return qn(self.target.column)\n```\n"}
{"instance_id": "django__django-14999", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -321,22 +321,24 @@\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n-            schema_editor.alter_db_table(\n-                new_model,\n-                old_model._meta.db_table,\n-                new_model._meta.db_table,\n-            )\n-            # Rename M2M fields whose name is based on this model's db_table\n-            for (old_field, new_field) in zip(\n-                old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n-            ):\n-                if new_field.remote_field.through._meta.auto_created:\n-                    schema_editor.alter_db_table(\n-                        new_field.remote_field.through,\n-                        old_field.remote_field.through._meta.db_table,\n-                        new_field.remote_field.through._meta.db_table,\n-                    )\n+            # If the db_table was explicitly set on the old model and is the\n+            # same as the new model's db_table, there is no database table\n+            # rename to perform. The model name change is purely a Python-level\n+            # concept as far as the database is concerned.\n+            if old_model._meta.db_table != new_model._meta.db_table:\n+                schema_editor.alter_db_table(\n+                    new_model,\n+                    old_model._meta.db_table,\n+                    new_model._meta.db_table,\n+                )\n+                # Rename M2M fields whose name is based on this model's db_table.\n+                for (old_field, new_field) in zip(\n+                    old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n+                ):\n+                    if new_field.remote_field.through._meta.auto_created:\n+                        schema_editor.alter_db_table(\n+                            new_field.remote_field.through,\n+                            old_field.remote_field.through._meta.db_table,\n+                            new_field.remote_field.through._meta.db_table,\n+                        )\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         old_model = to_state.apps.get_model(app_label, self.old_name)\n@@ -344,20 +346,22 @@\n             new_model = from_state.apps.get_model(app_label, self.new_name)\n             # If the db_table was explicitly set on the old model and is the\n             # same as the new model's db_table, there is no database table\n-            # rename to perform. The model name change is purely a Python-level\n-            # concept as far as the database is concerned.\n-            schema_editor.alter_db_table(\n-                old_model,\n-                new_model._meta.db_table,\n-                old_model._meta.db_table,\n-            )\n-            # Rename M2M fields whose name is based on this model's db_table\n-            for (old_field, new_field) in zip(\n-                old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n-            ):\n-                if old_field.remote_field.through._meta.auto_created:\n+            # rename to perform.\n+            if old_model._meta.db_table != new_model._meta.db_table:\n+                schema_editor.alter_db_table(\n+                    old_model,\n+                    new_model._meta.db_table,\n+                    old_model._meta.db_table,\n+                )\n+                # Rename M2M fields whose name is based on this model's db_table.\n+                for (old_field, new_field) in zip(\n+                    old_model._meta.local_many_to_many, new_model._meta.local_many_to_many\n+                ):\n+                    if old_field.remote_field.through._meta.auto_created:\n+                        schema_editor.alter_db_table(\n+                            old_field.remote_field.through,\n+                            new_field.remote_field.through._meta.db_table,\n+                            old_field.remote_field.through._meta.db_table,\n+                        )\n \n     def describe(self):\n\n```\n"}
{"instance_id": "django__django-15061", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -55,12 +55,6 @@\n         context['widget']['subwidgets'] = subwidgets\n         return context\n \n-    def id_for_label(self, id_):\n-        if id_:\n-            id_ += '_0'\n-        return id_\n-\n     def value_from_datadict(self, data, files, name):\n         return [\n             widget.value_from_datadict(data, files, name + widget_name)\n\n```\n"}
{"instance_id": "django__django-15202", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -128,8 +128,11 @@\n                 raise\n         else:\n             # Now verify IPv6 in the netloc part\n-            host_match = re.search(r'^\\[(.+)\\](?::\\d{1,5})?$', urlsplit(value).netloc)\n+            try:\n+                netloc = urlsplit(value).netloc\n+            except ValueError:  # e.g. \"Invalid IPv6 URL\"\n+                raise ValidationError(self.message, code=self.code, params={'value': value})\n+            host_match = re.search(r'^\\[(.+)\\](?::\\d{1,5})?$', netloc)\n             if host_match:\n                 potential_ip = host_match[1]\n                 try:\n\n```\n"}
{"instance_id": "django__django-15213", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1,7 +1,8 @@\n from django.db.models.constants import LOOKUP_SEP\n-from django.db.models.fields import Field\n+from django.db.models.fields import BooleanField, Field\n from django.db.models.functions import Cast\n from django.db.models.lookups import Lookup\n+from django.db.models.sql.datastructures import EmptyResultSet\n from django.db.models.sql.where import WhereNode\n\n\n@@ -23,7 +24,21 @@\n         return super().get_group_by_cols()\n\n     def as_sql(self, compiler, connection):\n-        return compiler.compile(self.expression)\n+        try:\n+            sql, params = compiler.compile(self.expression)\n+        except EmptyResultSet:\n+            # If the inner expression cannot produce results, return NULL.\n+            # If the output_field is boolean, return False instead.\n+            if isinstance(self.output_field, BooleanField):\n+                expression = Value(False, output_field=BooleanField())\n+                return expression.as_sql(compiler, connection)\n+            return compiler.connection.ops.quote_name('NULL'), []\n+        if sql == '':\n+            # If the inner expression is EverythingNode, it results in ('', []).\n+            # If the output_field is boolean, return True instead. Otherwise, NULL.\n+            if isinstance(self.output_field, BooleanField):\n+                expression = Value(True, output_field=BooleanField())\n+                return expression.as_sql(compiler, connection)\n+            return compiler.connection.ops.quote_name('NULL'), []\n+        return sql, params\n\n     def __repr__(self):\n         return \"{}({})\".format(self.__class__.__name__, self.expression)\n\n```\n"}
{"instance_id": "django__django-15252", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,5 +1,9 @@\n+from django.apps.registry import Apps\n from django.db import DatabaseError, models\n+from django.db.utils import ConnectionRouter\n from django.utils.functional import classproperty\n+from django.utils.timezone import now\n+\n from .exceptions import MigrationSchemaMissing\n \n \n@@ -54,6 +58,10 @@\n         # in the codebase.\n         if self.has_table():\n             return\n+        # Check if the related app is allowed to be migrated\n+        router = ConnectionRouter(self.connection.alias)\n+        if not router.allow_migrate_model(self.connection.alias, self.Migration):\n+            return\n         # Make the table\n         try:\n             with self.connection.schema_editor() as editor:\n\n```\n"}
{"instance_id": "django__django-15320", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1601,4 +1601,5 @@\n             if key in query.alias_map\n         }\n         query.table_map = {key: val for key, val in query.table_map.items() if key in query.alias_map}\n+        query.subquery = True\n         return query\n```\n"}
{"instance_id": "django__django-15347", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -18,7 +18,7 @@\n             # Using 0/1 here instead of False/True to produce more compact json\n             is_safedata = 1 if isinstance(obj.message, SafeData) else 0\n             message = [self.message_key, is_safedata, obj.level, obj.message]\n-            if obj.extra_tags:\n+            if obj.extra_tags is not None:\n                 message.append(obj.extra_tags)\n             return message\n         return super().default(obj)\n\n```\n"}
{"instance_id": "django__django-15388", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -105,4 +105,4 @@\n                 for directory in get_app_template_dirs(app_config.path):\n                     yield directory\n         for directory in engine.get(\"DIRS\", []):\n-            yield directory\n+            yield str(directory)\n\n```\n"}
{"instance_id": "django__django-15400", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/functional.py\n+++ b/django/utils/functional.py\n@@ -163,6 +163,12 @@\n             memo[id(self)] = result\n             return result\n         return copy.deepcopy(self._wrapped, memo)\n+\n+    def __radd__(self, other):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return other + self._wrapped\n+\n\n def partition(predicate, values):\n     \"\"\"\n\n```\n"}
{"instance_id": "django__django-15498", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/views/static.py\n+++ b/django/views/static.py\n@@ -23,6 +23,9 @@\n     size is the size of the resource.\n     \"\"\"\n     try:\n+        # Ignore empty header value.\n+        if not header:\n+            return True\n         # RFC 7232 section 3.3 says that If-Modified-Since can only be handled\n         # by servers when the date is valid. If the date is invalid, the header\n         # MUST be ignored.\n```\n"}
{"instance_id": "django__django-15695", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "django__django-15738", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -27,12 +27,23 @@\n \n         # Work out the new value of unique_together, taking renames into\n         # account\n-        unique_together = [\n+        unique_together = []\n+        if model._meta.unique_together:\n+            for unique in model._meta.unique_together:\n+                renamed_unique = [rename_mapping.get(n, n) for n in unique]\n+                # Skip unique_together if it involves a deleted field.\n+                if delete_field and delete_field.name in renamed_unique:\n+                    continue\n+                # Skip unique_together if it involves a field altered to not\n+                # have a column (e.g. M2M).\n+                if alter_field:\n+                    old_f, new_f = alter_field\n+                    if new_f.name in renamed_unique and new_f.column is None:\n+                        continue\n+                unique_together.append(renamed_unique)\n+\n+        # Work out the new value for index_together, taking renames into account\n+        index_together = [\n             [rename_mapping.get(n, n) for n in unique]\n-            for unique in model._meta.unique_together\n-        ]\n-\n-        # Work out the new value for index_together, taking renames into\n-        # account\n-        index_together = [\n-            [rename_mapping.get(n, n) for n in index]\n             for index in model._meta.index_together\n         ]\n \n\n```\n"}
{"instance_id": "django__django-15781", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -4,7 +4,7 @@\n import argparse\n import os\n import sys\n-from argparse import ArgumentParser, HelpFormatter\n+from argparse import ArgumentParser, HelpFormatter, RawDescriptionHelpFormatter\n from io import TextIOBase\n \n import django\n@@ -244,6 +244,7 @@\n         parser = CommandParser(\n             prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None,\n+            formatter_class=RawDescriptionHelpFormatter,\n             missing_args_message=getattr(self, \"missing_args_message\", None),\n             called_from_command_line=getattr(self, \"_called_from_command_line\", None),\n             **kwargs,\n\n```\n"}
{"instance_id": "django__django-15789", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -8,6 +8,7 @@\n from django.utils.functional import Promise, keep_lazy, keep_lazy_text\n from django.utils.http import RFC3986_SUBDELIMS, RFC3986_UNRESERVED\n from django.utils.safestring import SafeData, SafeString, mark_safe\n+from django.core.serializers.json import DjangoJSONEncoder\n \n # Configuration for urlize() function.\n LEADING_PUNCTUATION = [\"(\", \"<\", \"&lt;\"]\n@@ -38,18 +39,20 @@\n     ord(\"&\"): \"\\\\u0026\",\n }\n \n-def json_script(value, element_id=None):\n+def json_script(value, element_id=None, encoder=DjangoJSONEncoder):\n     \"\"\"\n     Escape characters for embedding JSON in HTML.\n \n     Arguments:\n         value: Python object to be serialized.\n         element_id: ID attribute of the <script> tag.\n+        encoder: JSON encoder class to use.\n     \"\"\"\n-    from django.core.serializers.json import DjangoJSONEncoder\n-\n-    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n+    # Escape channel binding names as well, because they can be used in attribute\n+    # selectors in CSS. Typically this happens in tests. It's not known to be a\n+    # security issue, but it's likely confusing.\n+    json_str = json.dumps(value, cls=encoder).translate(_json_script_escapes)\n     if element_id:\n+        # Attributes are escaped by conditional_escape.\n         template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n         return mark_safe(template.format(conditional_escape(element_id), json_str))\n     else:\n```\n"}
{"instance_id": "django__django-15790", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/checks/templates.py\n+++ b/django/core/checks/templates.py\n@@ -61,12 +61,13 @@\n         libraries[module_name].append(module_path)\n \n     for library_name, items in libraries.items():\n-        if len(items) > 1:\n+        unique_items = set(items)\n+        if len(unique_items) > 1:\n             errors.append(\n                 Error(\n                     E003.msg.format(\n                         repr(library_name),\n-                        \", \".join(repr(item) for item in items),\n+                        \", \".join(repr(item) for item in unique_items),\n                     ),\n                     id=E003.id,\n                 )\n\n```\n"}
{"instance_id": "django__django-15814", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -752,7 +752,9 @@\n                     \"from_parent\": from_parent,\n                 }\n                 columns = self.get_default_columns(\n-                    start_alias=alias, opts=model._meta, from_parent=opts.model\n+                    start_alias=alias,\n+                    opts=model._meta.concrete_model._meta,\n+                    from_parent=opts.model,\n                 )\n                 select_fields = []\n                 for col in columns:\n@@ -761,7 +763,10 @@\n                 klass_info[\"select_fields\"] = select_fields\n                 next = requested.get(f.name, {})\n                 next_klass_infos = self.get_related_selections(\n-                    select, model._meta, alias, cur_depth + 1, next, restricted\n+                    select,\n+                    model._meta.concrete_model._meta,\n+                    alias,\n+                    cur_depth + 1, next, restricted,\n                 )\n                 get_related_klass_infos(klass_info, next_klass_infos)\n \n@@ -797,7 +802,9 @@\n                 }\n                 related_klass_infos.append(klass_info)\n                 select_fields = []\n-                columns = self.get_default_columns(start_alias=alias, opts=model._meta)\n+                columns = self.get_default_columns(\n+                    start_alias=alias, opts=model._meta.concrete_model._meta\n+                )\n                 for col in columns:\n                     select_fields.append(len(select))\n                     select.append((col, None))\n@@ -805,7 +812,10 @@\n                 next = requested.get(f.related_query_name(), {})\n                 # This is the recursive call.\n                 next_klass_infos = self.get_related_selections(\n-                    select, model._meta, alias, cur_depth + 1, next, restricted\n+                    select,\n+                    model._meta.concrete_model._meta,\n+                    alias,\n+                    cur_depth + 1, next, restricted,\n                 )\n                 get_related_klass_infos(klass_info, next_klass_infos)\n \n```\n"}
{"instance_id": "django__django-15819", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1,6 +1,7 @@\n+from django.db.models.constants import RECURSIVE_RELATIONSHIP_CONSTANT\n+\n def contribute_to_class(self, cls, name, **kwargs):\n     # To support multiple relations to self, it's useful to have a non-None\n     # related name on symmetrical relations for internal reasons. The\n     # concept doesn't make a lot of sense externally (\"you want me to\n@@ -21,6 +22,30 @@\n             cls.__name__.lower(),\n             name,\n         )\n+    # Check for potential clashes if no related_name is explicitly provided\n+    # and it wasn't handled by symmetrical/hidden logic above.\n+    elif self.remote_field.related_name is None:\n+        default_related_name = self.remote_field.get_accessor_name()\n+        # Avoid checks for '+' names or if default is None (e.g. symmetrical m2m handled above)\n+        if default_related_name and not default_related_name.endswith('+'):\n+            potential_clash = False\n+            for other_field in cls._meta.get_fields(include_hidden=True):\n+                # Check other relations on the same model targeting the same remote model\n+                if (\n+                    other_field.is_relation\n+                    and other_field != self\n+                    and other_field.remote_field.model == self.remote_field.model\n+                    and not other_field.remote_field.is_hidden()\n+                    # Check if the other field *also* uses the default name and it matches ours\n+                    # AND ensure the other field isn't handled by symmetrical/hidden logic either\n+                    and other_field.remote_field.related_name is None\n+                    and not (other_field.remote_field.symmetrical and (other_field.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT or other_field.remote_field.model == cls._meta.object_name)) # Exclude symmetrical self M2M\n+                    and other_field.remote_field.get_accessor_name() == default_related_name\n+                ):\n+                    potential_clash = True\n+                    break\n+            if potential_clash:\n+                self.remote_field.related_name = name\n\n     super().contribute_to_class(cls, name, **kwargs)\n\n```\n"}
{"instance_id": "django__django-15851", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,9 @@\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n+        args.extend(parameters)\n         if dbname:\n             args += [dbname]\n-        args.extend(parameters)\n \n         env = {}\n         if passwd:\n\n```\n"}
{"instance_id": "django__django-15902", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -119,6 +119,10 @@\n                     MAX_NUM_FORM_COUNT: self.max_num,\n                 },\n                 renderer=self.renderer,\n             )\n+        # Set a default template name to avoid a deprecation warning when\n+        # rendering the management form using {{ form }}. ManagementForm renders\n+        # only hidden fields and doesn't use the template structure.\n+        form.template_name = self.template_name_div\n         return form\n\n     def total_form_count(self):\n\n```\n"}
{"instance_id": "django__django-15996", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -3,7 +3,7 @@\n import datetime\n import decimal\n import enum\n-import functools\n+import functools  # NOQA: F401\n import math\n import os\n import pathlib\n@@ -18,6 +18,10 @@\n from django.utils.functional import LazyObject, Promise\n from django.utils.version import get_docs_version\n \n+# Before Python 3.11, enum._decompose was not public.\n+_has_decompose = hasattr(enum, \"_decompose\")\n+\n+\n \n class BaseSerializer:\n     def __init__(self, value):\n@@ -95,11 +99,33 @@\n         return repr(self.value), set(imports)\n \n \n-class EnumSerializer(BaseSerializer):\n+class EnumSerializer(BaseSerializer):\n+    \"\"\"Serialize enum members to themselves.\"\"\"\n+\n     def serialize(self):\n         enum_class = type(self.value)\n         module = enum_class.__module__\n         imports = {f\"import {module}\"}\n-        return f\"{module}.{enum_class.__name__}.{self.value.name}\", imports\n+        member_name = getattr(self.value, \"name\", None)\n+\n+        # Check if it's a direct member first.\n+        if member_name is not None and getattr(enum_class, member_name, None) is self.value:\n+            return f\"{module}.{enum_class.__name__}.{member_name}\", imports\n+\n+        # Handle Flags using _decompose if available (Python >= 3.6).\n+        if _has_decompose and isinstance(self.value, enum.Flag):\n+            try:\n+                members, uncovered_value = enum._decompose(enum_class, self.value.value)\n+                # Check if all bits correspond to defined flags.\n+                if uncovered_value == 0:\n+                    member_strings = [\n+                        f\"{module}.{enum_class.__name__}.{m.name}\" for m in members\n+                    ]\n+                    # Handle the zero flag or combine members.\n+                    return f\"{module}.{enum_class.__name__}(0)\" if not member_strings else \" | \".join(member_strings), imports\n+            except ValueError:\n+                # Value cannot be decomposed.\n+                pass\n+\n+        # Fallback: Represent by value using the constructor ClassName(value).\n+        value_repr, value_imports = serializer_factory(self.value.value).serialize()\n+        imports.update(value_imports)\n+        return f\"{module}.{enum_class.__name__}({value_repr})\", imports\n \n \n class FieldSerializer(BaseSerializer):\n\n```\n"}
{"instance_id": "django__django-16041", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -41,13 +41,15 @@\n \n     @property\n     def empty_form(self):\n+        # Allow form_kwargs to override the defaults for empty_form.\n+        # Remove `empty_permitted` as it isn't relevant to the empty form.\n+        form_kwargs = self.get_form_kwargs(None)\n+        form_kwargs.pop(\"empty_permitted\", None)\n         form = self.form(\n             auto_id=self.auto_id,\n             prefix=self.add_prefix(\"__prefix__\"),\n             empty_permitted=True,\n             use_required_attribute=False,\n-            **self.get_form_kwargs(None),\n-            renderer=self.renderer,\n+            renderer=self.renderer,\n+            **form_kwargs,\n         )\n         self.add_fields(form, None)\n         return form\n\n```\n"}
{"instance_id": "django__django-16046", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -45,6 +45,10 @@\n     # Convert to string\n     str_number = str(number)\n\n+    # Return empty string for empty inputs, avoids IndexError below.\n+    if not str_number:\n+        return \"\"\n+\n     # Sign\n     sign = \"\"\n     if str_number[0] == \"-\":\n\n```\n"}
{"instance_id": "django__django-16139", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -7,6 +7,7 @@\n from django.contrib.auth.tokens import default_token_generator\n from django.contrib.sites.shortcuts import get_current_site\n from django.core.exceptions import ValidationError\n+from django.urls import reverse\n from django.utils.crypto import get_random_string\n from django.utils.html import strip_tags\n from django.utils.http import urlsafe_base64_decode\n@@ -156,8 +157,11 @@\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n-        if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+        # The password field is read-only, so report the actual password change\n+        # URL. The view requires the user pk, so be sure to use it.\n+        if password and self.instance.pk:\n+            password_change_url = reverse(\"admin:auth_user_password_change\", args=[self.instance.pk])\n+            password.help_text = password.help_text.format(password_change_url)\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n\n```\n"}
{"instance_id": "django__django-16229", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/contrib/postgres/fields/array.py\n+++ b/django/contrib/postgres/fields/array.py\n@@ -23,6 +23,10 @@\n     # This prevents Django's Field._check_default() from raising a\n     # validation error.\n     _default_hint = (\"list\", \"[]\")\n+    # If the widget doesn't render the initial value correctly, don't render\n+    # a hidden initial input. This prevents issues where the default value\n+    # (e.g., []) is formatted incorrectly, leading to has_changed returning\n+    # incorrect results (Trac-34987).\n+    show_hidden_initial = False\n \n     def __init__(self, base_field, size=None, **kwargs):\n         self.base_field = base_field\n```\n"}
{"instance_id": "django__django-16255", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -167,7 +167,7 @@\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod\n\n```\n"}
{"instance_id": "django__django-16379", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/core/cache/backends/filebased.py\n+++ b/django/core/cache/backends/filebased.py\n@@ -75,9 +75,9 @@\n \n     def has_key(self, key, version=None):\n         fname = self._key_to_file(key, version)\n-        if os.path.exists(fname):\n+        try:\n             with open(fname, \"rb\") as f:\n                 return not self._is_expired(f)\n-        return False\n+        except FileNotFoundError:\n+            return False\n\n```\n"}
{"instance_id": "django__django-16400", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "django__django-16408", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -115,7 +115,7 @@\n                         \"model\": model,\n                         \"field\": final_field,\n                         \"reverse\": True,\n-                        \"local_setter\": partial(local_setter, final_field),\n+                        \"local_setter\": partial(remote_setter, name),\n                         \"remote_setter\": partial(remote_setter, name),\n                         \"from_parent\": from_parent,\n                     }\n\n```\n"}
{"instance_id": "django__django-16527", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -39,6 +39,7 @@\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\n\n```\n"}
{"instance_id": "django__django-16595", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -55,6 +55,9 @@\n             operation\n         ):\n             return [operation]\n+        elif isinstance(operation, AlterField) and self.is_same_field_operation(\n+            operation\n+        ):\n+            return [operation]\n         elif (\n             isinstance(operation, RenameField)\n             and self.is_same_field_operation(operation)\n\n```\n"}
{"instance_id": "django__django-16816", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/django/contrib/admin/checks.py\n+++ b/django/contrib/admin/checks.py\n@@ -1,6 +1,7 @@\n from collections import Counter\n from itertools import chain\n \n+from django.contrib.contenttypes.fields import GenericRelation\n from django.core import checks\n from django.core.checks.urls import check_url_config\n from django.core.exceptions import FieldDoesNotExist\n@@ -400,14 +401,39 @@\n                     # model admin but is an attribute of the model. This is valid.\n                     pass\n                 else:\n-                    errors.append(\n-                        checks.Error(\n-                            \"The value of 'list_display[%d]' refers to '%s', \"\n-                            \"which is not a callable, an attribute of '%s', or \"\n-                            \"an attribute or method on '%s'.\"\n-                            % (index, field_name, cls.__name__, opts.object_name),\n-                            obj=cls,\n-                            id=\"admin.E108\",\n+                    # Check if the field_name refers to a relation object that is not\n+                    # directly on the model (reverse relation or GenericRelation).\n+                    field_is_reverse_relation = False\n+                    field_is_generic_relation = False\n+                    for f in opts.get_fields(include_hidden=True):\n+                        if f.name == field_name:\n+                            if f.auto_created and not f.concrete:\n+                                field_is_reverse_relation = True\n+                                break\n+                            if isinstance(f, GenericRelation):\n+                                field_is_generic_relation = True\n+                                break\n+                    if field_is_reverse_relation:\n+                        errors.append(\n+                            checks.Error(\n+                                \"The value of 'list_display[%d]' refers to '%s', which \"\n+                                \"is a reverse relation. This is not supported.\"\n+                                % (index, field_name),\n+                                obj=cls,\n+                                id=\"admin.E108\",\n+                            )\n+                        )\n+                    elif field_is_generic_relation:\n+                        errors.append(\n+                            checks.Error(\n+                                \"The value of 'list_display[%d]' refers to '%s', which \"\n+                                \"is a generic relation. This is not supported.\"\n+                                % (index, field_name),\n+                                obj=cls,\n+                                id=\"admin.E108\",\n+                            )\n+                        )\n+                    else:\n+                        errors.append(\n+                            checks.Error(\n+                                \"The value of 'list_display[%d]' refers to '%s', \"\n+                                \"which is not a callable, an attribute of '%s', or \"\n+                                \"an attribute or method on '%s'.\"\n+                                % (index, field_name, cls.__name__, opts.object_name),\n+                                obj=cls,\n+                                id=\"admin.E108\",\n+                            )\n                         )\n         else:\n             # It is a field; we can proceed checking.\n--- a/tests/admin_checks/tests.py\n+++ b/tests/admin_checks/tests.py\n@@ -1,6 +1,7 @@\n from django.contrib import admin\n from django.contrib.admin.checks import ModelAdminChecks\n from django.contrib.admin.options import HORIZONTAL, VERTICAL\n+from django.contrib.admin.sites import AdminSite\n from django.core.checks import Error, Info, Warning\n from django.db import models\n from django.forms import BaseModelFormSet, CharField, ModelForm\n@@ -10,6 +11,7 @@\n     Album,\n     Author,\n     Band,\n+    Bookmark,\n     Chapter,\n     Edition,\n     EmptyModel,\n@@ -18,6 +20,7 @@\n     Membership,\n     Movie,\n     Musician,\n+    Place,\n     RelatedModel,\n     RelatedModelInline,\n     Song,\n@@ -25,6 +28,7 @@\n     User,\n     UserAdmin,\n     UserNonrelatedAdmin,\n+    Restaurant,\n )\n from django.test import SimpleTestCase, override_settings\n from django.test.utils import isolate_apps\n@@ -100,6 +104,7 @@\n \n @isolate_apps(\"admin_checks\")\n class ListDisplayCheckTests(AdminCheckTestCase):\n+    site = AdminSite()\n \n     def test_non_field_in_list_display(self):\n         class SongAdmin(admin.ModelAdmin):\n@@ -200,3 +205,63 @@\n             )\n         ]\n         self.assertEqual(errors, expected_errors)\n+\n+    def test_list_display_reverse_fk_relation(self):\n+        # Album has FK to Musician. Check MusicianAdmin for 'album'.\n+        class MusicianAdmin(admin.ModelAdmin):\n+            list_display = [\"album\"]\n+\n+        errors = MusicianAdmin(Musician, self.site).check()\n+        expected_errors = [\n+            Error(\n+                \"The value of 'list_display[0]' refers to 'album', which is a \"\n+                \"reverse relation. This is not supported.\",\n+                obj=MusicianAdmin,\n+                id=\"admin.E108\",\n+            )\n+        ]\n+        self.assertEqual(errors, expected_errors)\n+\n+    def test_list_display_reverse_m2m_relation(self):\n+        # Band has M2M through Membership. Check BandAdmin for 'membership'.\n+        class BandAdmin(admin.ModelAdmin):\n+            list_display = [\"membership\"]\n+\n+        errors = BandAdmin(Band, self.site).check()\n+        expected_errors = [\n+            Error(\n+                \"The value of 'list_display[0]' refers to 'membership', which is a \"\n+                \"reverse relation. This is not supported.\",\n+                obj=BandAdmin,\n+                id=\"admin.E108\",\n+            )\n+        ]\n+        self.assertEqual(errors, expected_errors)\n+\n+    def test_list_display_reverse_o2o_relation(self):\n+        # Restaurant has O2O to Place. Check PlaceAdmin for 'restaurant'.\n+        class PlaceAdmin(admin.ModelAdmin):\n+            list_display = [\"restaurant\"]\n+\n+        errors = PlaceAdmin(Place, self.site).check()\n+        expected_errors = [\n+            Error(\n+                \"The value of 'list_display[0]' refers to 'restaurant', which is a \"\n+                \"reverse relation. This is not supported.\",\n+                obj=PlaceAdmin,\n+                id=\"admin.E108\",\n+            )\n+        ]\n+        self.assertEqual(errors, expected_errors)\n+\n+    def test_list_display_reverse_generic_relation(self):\n+        # Bookmark has GenericRelation 'tags'. Check BookmarkAdmin for 'tags'.\n+        class BookmarkAdmin(admin.ModelAdmin):\n+            list_display = [\"tags\"]\n+\n+        errors = BookmarkAdmin(Bookmark, self.site).check()\n+        expected_errors = [\n+            Error(\n+                \"The value of 'list_display[0]' refers to 'tags', which is a generic \"\n+                \"relation. This is not supported.\",\n+                obj=BookmarkAdmin,\n+                id=\"admin.E108\",\n+            )\n+        ]\n+        self.assertEqual(errors, expected_errors)\n```\n"}
{"instance_id": "django__django-16820", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -868,7 +868,35 @@\n                     (app_label, model_name, None, False),\n                 )\n \n-            yield (\n+            # Check if this change is solely due to transitioning from\n+            # index_together to Meta.indexes.\n+            should_yield = True\n+            if option_name == \"index_together\":\n+                removed = old_value.difference(new_value)\n+                added = new_value.difference(old_value)\n+                # If index_together entries were added, or if entries were\n+                # removed *without* a corresponding Meta.indexes entry, then\n+                # AlterIndexTogether is required.\n+                if not added and removed and new_model_state:\n+                    # Only removals in index_together. Check for transitions.\n+                    new_indexes = new_model_state.options.get(\"indexes\", [])\n+                    transitioned_removed = set()\n+                    for rem_tuple in removed:\n+                        for index in new_indexes:\n+                            # Check if index corresponds to rem_tuple.\n+                            # A simple index derived from index_together only\n+                            # has fields and possibly a name.\n+                            if index.fields == list(rem_tuple):\n+                                _qn, args, kwargs = index.deconstruct()\n+                                if not args and set(kwargs) <= {\"fields\", \"name\"}:\n+                                    transitioned_removed.add(rem_tuple)\n+                                    break  # Found corresponding index\n+                    # If all removed items were transitioned, no need for\n+                    # AlterIndexTogether. The transition is handled by\n+                    # AddIndex/RemoveIndex logic (which might be optimized).\n+                    if removed == transitioned_removed:\n+                        should_yield = False\n+\n+            if should_yield:\n+                yield (\n                 old_value,\n                 new_value,\n                 app_label,\n\n```\n"}
{"instance_id": "django__django-16873", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -597,7 +597,7 @@\n                 # Translators: \"literal\" is a Python term\n                 ) % {\"list\": value, \"literal\": arg}\n             )\n-@register.filter(needs_autoescape=True)\n+@register.filter(needs_autoescape=True, is_safe=True)\n def join(value, arg, autoescape=True):\n     \"\"\"\n     Join a list with a string, like Python's ``str.join(list)``.\n\n```\n"}
{"instance_id": "django__django-16910", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -34,7 +34,7 @@\n                     if o.field.unique and not o.many_to_many\n                 ]\n                 for related_field, model in related_fields:\n-                    related_select_mask = select_mask.get(related_field) or {}\n+                    related_select_mask = select_mask.get(related_field.field) or {}\n                     if not select_related_descend(\n                         related_field,\n                         restricted,\n\n```\n"}
{"instance_id": "django__django-17051", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -188,6 +188,7 @@\n         qn = self.quote_name_unless_alias\n         opts = self.query.get_meta()\n         result = [\"INSERT INTO %s\" % qn(opts.db_table)]\n+        returning_sql = \"\"\n         returning_fields = self.query.returning_fields\n \n         if self.returning_fields and self.connection.features.can_return_columns_from_insert:\n@@ -202,10 +203,7 @@\n                     field.get_placeholder(value, self, self.connection)\n                     for field in self.returning_fields\n                 )\n-            result.append(\n-                self.connection.ops.return_insert_columns_sql(self.returning_fields)\n-            )\n-\n+            returning_sql = self.connection.ops.return_insert_columns_sql(self.returning_fields)\n         has_fields = bool(fields)\n         if has_fields:\n             field_names = [f.column for f in fields]\n@@ -231,26 +229,26 @@\n             opts.db_table,\n         )\n \n-        can_bulk = (\n-            not self.returning_params and self.connection.features.has_bulk_insert\n-        )\n-\n         if has_fields:\n+            can_bulk = (\n+                not self.returning_params and self.connection.features.has_bulk_insert\n+            )\n             if can_bulk:\n                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n                 if on_conflict_suffix_sql:\n                     result.append(on_conflict_suffix_sql)\n+                if returning_sql:\n+                    result.append(returning_sql)\n                 return [(\" \".join(result), tuple(p for ps in param_rows for p in ps))]\n             else:\n-                if on_conflict_suffix_sql:\n-                    result.append(on_conflict_suffix_sql)\n                 return [\n                     (\n                         \" \".join(\n-                            result + [\"VALUES (%s)\" % \", \".join(p)]\n+                            result + [\"VALUES (%s)\" % \", \".join(p)] +\n+                            ([on_conflict_suffix_sql] if on_conflict_suffix_sql else []) +\n+                            ([returning_sql] if returning_sql else [])\n                         ),\n-                        vals,\n+                        vals\n                     )\n                     for p, vals in zip(placeholder_rows, param_rows)\n                 ]\n@@ -258,6 +256,8 @@\n             # No fields specified. Use default values.\n             result.append(self.connection.ops.insert_default_sql(opts.db_table))\n             if on_conflict_suffix_sql:\n+                # ON CONFLICT is invalid when inserting the default row.\n                 raise ValueError(\"ON CONFLICT clause cannot be used with default values.\")\n+            if returning_sql:\n+                result.append(returning_sql)\n             return [(\" \".join(result), ())]\n\n```\n"}
{"instance_id": "django__django-17087", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -168,7 +168,8 @@\n             path = module_name + \".\" + value.func.__qualname__\n         else:\n             # Ensure the full qualified name is used, including outer classes.\n-            path = module_name + \".\" + value.__qualname__\n+            # value.__qualname__ should provide the full path like Outer.Inner.method\n+            path = module_name + \".\" + value.__qualname__\n\n         # Check if the function is actually importable.\n         imported_value = import_string(path)\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-18869", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -1,11 +1,13 @@\n+import importlib\n+import logging\n+from packaging.version import parse as parse_version\n+import os\n+import sys\n+\n # Quickfix to ensure Microsoft Visual C++ redistributable\n # DLLs are loaded before importing kiwisolver\n from . import ft2font\n-\n from ._version import __version__\n\n-# Need to import numpy after ft2font, otherwise importing numpy may load an\n-# incompatible version of the library, see #19301.\n from . import _api, cbook, _docstring, rcsetup\n from matplotlib.cbook import MatplotlibDeprecationWarning, sanitize_sequence\n from matplotlib.rcsetup import defaultParams, validate_backend, cycler\n@@ -17,8 +19,14 @@\n from pathlib import Path\n import tempfile\n\n+# BEFORE importing pyplot, figures, etc.\n+_check_versions()\n+\n+# Parse the version string into a tuple.\n+_parsed_version = parse_version(__version__)\n+version_info = _parsed_version.release[:3]  # (major, minor, micro)\n+del _parsed_version  # Clean up namespace\n\n-_check_versions()\n\n\n _log = logging.getLogger(__name__)\n```\n"}
{"instance_id": "matplotlib__matplotlib-22711", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -909,13 +909,11 @@\n             xy[1] = .25, val[1]\n             xy[2] = .75, val[1]\n             xy[3] = .75, val[0]\n-            xy[4] = .25, val[0]\n         else:\n             xy[0] = val[0], .25\n             xy[1] = val[0], .75\n             xy[2] = val[1], .75\n             xy[3] = val[1], .25\n-            xy[4] = val[0], .25\n         self.poly.xy = xy\n         self.valtext.set_text(self._format(val))\n         if self.drawon:\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-22835", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/artist.py\n+++ b/lib/matplotlib/artist.py\n@@ -58,14 +58,17 @@\n             if np.ma.getmask(data):\n                 return \"[]\"\n             normed = self.norm(data)\n-            if np.isfinite(normed):\n+            if np.isfinite(normed).item():  # Ensure scalar boolean.\n                 # Midpoints of neighboring color intervals.\n-                neighbors = self.norm.inverse(\n-                    (int(self.norm(data) * n) + np.array([0, 1])) / n)\n-                delta = abs(neighbors - data).max()\n-                g_sig_digits = cbook._g_sig_digits(data, delta)\n+                try:\n+                    neighbors = self.norm.inverse(\n+                        (int(normed * n) + np.array([0, 1])) / n)\n+                    delta = abs(neighbors - data).max()\n+                    g_sig_digits = cbook._g_sig_digits(data, delta)\n+                except ValueError:  # Handle non-invertible norms.\n+                    g_sig_digits = 3\n             else:\n-                g_sig_digits = 3  # Consistent with default below.\n+                g_sig_digits = 3\n             return \"[{:-#.{}g}]\".format(data, g_sig_digits)\n         else:\n             try:\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-23299", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -740,10 +740,14 @@\n             # backend if needed.\n             if key == \"backend\":\n                 # Store the backend name that the user originally requested,\n-                # before resolution (e.g. \"agg\", \"auto\").\n-                self._user_cached_backend = val\n-                # Trigger the backend switch.\n-                self.update_user(propagate=False)\n+                # before resolution (e.g. \"agg\", \"auto\"). Don't switch if the\n+                # backend is just being set to the resolved value of \"auto\".\n+                from matplotlib import pyplot as plt\n+                if (plt._get_backend_mod() is not None and  # A backend is loaded.\n+                        val != plt._get_backend_mod().__name__):  # The new backend name differs.\n+                    plt.switch_backend(val)\n+                # Store the user requested name.\n+                self._user_cached_backend = val\n\n     def __getitem__(self, key):\n         key = self._validate_key(key)\n@@ -780,14 +784,6 @@\n         # Update the cached backend value.\n         self._user_cached_backend = self._user.get(\"backend\")\n\n-        # Propagate the changes to other modules.\n-        if propagate:\n-            # This is the only possible propagation at the moment.\n-            if self._user_cached_backend:\n-                # This may raise an ImportError, which is desired.\n-                from matplotlib import pyplot as plt\n-                plt.switch_backend(self._user_cached_backend)\n-\n     def __repr__(self):\n         class_name = self.__class__.__name__\n         indent = len(class_name) + 1\n```\n"}
{"instance_id": "matplotlib__matplotlib-23314", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -1905,6 +1905,9 @@\n     @_api.delete_parameter(\"3.5\", \"inframe\")\n     def draw(self, renderer):\n         # Draw the background patch\n+        if not self.get_visible():\n+            return\n+\n         self.patch.draw(renderer)\n\n         # Determine facing polygons\n```\n"}
{"instance_id": "matplotlib__matplotlib-23476", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/matplotlib/backends/backend_macosx.py\n+++ b/lib/matplotlib/backends/backend_macosx.py\n@@ -28,7 +28,8 @@\n         # Must be initialized before FigureCanvasBase, which calls\n         # draw_idle, which potentially calls register_callback.\n         self._idle = True\n-        _macosx.FigureCanvas.__init__(self, width, height)\n+        ratio = self._get_device_pixel_ratio()\n+        _macosx.FigureCanvas.__init__(self, width / ratio, height / ratio)\n         self._draw_pending = False\n         self._is_drawing = False\n         self.figure.dpi = self.figure.dpi\n```\n"}
{"instance_id": "matplotlib__matplotlib-23562", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -18,10 +18,10 @@\n         self.stale = True\n\n     def get_facecolor(self):\n-        return self._facecolors2d\n+        return self._facecolor3d\n\n     def get_edgecolor(self):\n-        return self._edgecolors2d\n+        return self._edgecolor3d\n\n     get_facecolors = get_facecolor\n     get_edgecolors = get_edgecolor\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-23563", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -63,8 +63,14 @@\n\n def line_2d_to_3d(line, zs=0, zdir='z'):\n     \"\"\"Convert a 2D line to 3D.\"\"\"\n+    xs, ys = line.get_data()\n     line.__class__ = Line3D\n+    # Ensure verts3d is initialized before calling set_3d_properties.\n+    # Otherwise, if set_3d_properties fails (e.g., due to incompatible\n+    # inputs), the object can be left in an invalid state (Line3D instance\n+    # without _verts3d attribute). Initialize with existing 2D data and Z=0.\n+    zs_init = np.zeros_like(xs)\n+    line._verts3d = juggle_axes(xs, ys, zs_init, zdir)\n+    # Set actual 3D properties using the provided zs. This may error\n+    # or overwrite _verts3d, but the attribute is guaranteed to exist.\n     line.set_3d_properties(zs, zdir)\n\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-23913", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -386,6 +386,7 @@\n                  shadow=None,\n                  fancybox=None,\n                  ncol=1,              # number of columns\n+                 draggable=False,\n                  **kwargs):\n         \"\"\"\n         Parameters\n@@ -481,6 +482,10 @@\n             If bool, determines whether to draw a shadow behind the legend.\n             The property can also be configured by passing a dictionary of\n             :class:`~matplotlib.patches.Patch` properties.\n+        draggable : bool, default: False\n+            Whether the legend can be dragged with the mouse. The location of\n+            the legend can be changed by pressing the mouse button over the\n+            legend, dragging it to the desired position, and releasing the button.\n \n         Other Parameters\n         ----------------\n@@ -513,7 +518,11 @@\n             raise ValueError(\"Legend location specified by 'loc' and \"\n                              \"'bbox_to_anchor' differs from the default\")\n \n-        self._draggable = None\n+        self._draggable = None  # must be defined before the check below\n+        # Must be called at the end of __init__, otherwise the default handler\n+        # may overwrite the location.\n+        if draggable:\n+            self.set_draggable(True)\n \n         self._update_prop(kwargs)\n \n```\n"}
{"instance_id": "matplotlib__matplotlib-23964", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/backends/backend_ps.py\n+++ b/lib/matplotlib/backends/backend_ps.py\n@@ -669,6 +669,9 @@\n             else:\n                 stream = self._get_text_stream(line, prop)\n\n+            if stream is None:\n+                continue\n+\n             for ps_name, xs_names in stream:\n                 self.set_color(*gc.get_rgb(), store=False)\n                 self.set_font(ps_name, prop.get_size_in_points(), store=False)\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-23987", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2967,8 +2967,7 @@\n         \"\"\"\n         Adjust the subplot layout parameters. [...]\n         \"\"\"\n-        if (self._layout_engine is not None and\n-                not self._layout_engine.adjust_compatible):\n+        if self.constrained_layout:\n             warnings.warn(\"This figure was using a layout engine that is \"\n                           \"incompatible with subplots_adjust and/or \"\n                           \"tight_layout; not calling subplots_adjust.\")\n@@ -3040,8 +3039,7 @@\n         \"\"\"\n         Adjust subplot parameters for a tight layout. [...]\n         \"\"\"\n-        if (self._layout_engine is not None and\n-                not self._layout_engine.adjust_compatible):\n+        if self.constrained_layout:\n             # constrained_layout is incompatible with tight_layout.\n             # It makes sense to just not call tight_layout if using\n             # constrained_layout. This will be called if the user does\n```\n"}
{"instance_id": "matplotlib__matplotlib-24149", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2179,11 +2179,12 @@\n             # removes the units from unit packages like `pint` that\n             # wrap numpy arrays.\n             try:\n-                x0 = cbook._safe_first_finite(x0)\n-            except (TypeError, IndexError, KeyError):\n-                pass\n-            if x0 is None:  # All nan/inf?\n+                # Find the first finite value in x0 to compute scaling.\n+                x0_finite = cbook._safe_first_finite(x0)\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                # No finite value found, or other error accessing x0.\n+                x0_finite = None\n+            if x0_finite is None:  # All non-finite or other error?\n                 return dx  # Nothing to scale relative to.\n-            dx = dx * (convert(x0 + 1) - convert(x0))\n+            dx = dx * (convert(x0_finite + 1) - convert(x0_finite))\n         return dx\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-24265", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/style/core.py\n+++ b/lib/matplotlib/style/core.py\n@@ -126,6 +126,30 @@\n         else:\n             _log.warning('Could not find Library file %s/%s.%s',\n                          path, name, STYLE_EXTENSION)\n+\n+    # Add aliases for backward compatibility with old seaborn names\n+    # Styles may exist in the library paths under their old names; if so,\n+    # don't overwrite them with the v0_8 aliases.\n+    seaborn_aliases = {\n+        'seaborn-bright': 'seaborn-v0_8-bright',\n+        'seaborn-colorblind': 'seaborn-v0_8-colorblind',\n+        'seaborn-dark': 'seaborn-v0_8-dark',\n+        'seaborn-darkgrid': 'seaborn-v0_8-darkgrid',\n+        'seaborn-dark-palette': 'seaborn-v0_8-dark-palette',\n+        'seaborn-deep': 'seaborn-v0_8-deep',\n+        'seaborn-muted': 'seaborn-v0_8-muted',\n+        'seaborn-notebook': 'seaborn-v0_8-notebook',\n+        'seaborn-paper': 'seaborn-v0_8-paper',\n+        'seaborn-pastel': 'seaborn-v0_8-pastel',\n+        'seaborn-poster': 'seaborn-v0_8-poster',\n+        'seaborn-talk': 'seaborn-v0_8-talk',\n+        'seaborn-ticks': 'seaborn-v0_8-ticks',\n+        'seaborn-white': 'seaborn-v0_8-white',\n+        'seaborn-whitegrid': 'seaborn-v0_8-whitegrid',\n+    }\n+    for old, new in seaborn_aliases.items():\n+        if new in library and old not in library:\n+            library[old] = library[new]\n+            _api.warn_deprecated(\n+                \"3.6\", name=f\"The seaborn style '{old}'\",\n+                alternative=f\"'{new}'\", obj_type=\"style\",\n+                addendum=\"If you are using seaborn directly, pass its styles \"\n+                         \"directly to Seaborn's plotting functions.\")\n+\n     return sorted(library)\n\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-24334", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -5,7 +5,7 @@\n \n import matplotlib as mpl\n from matplotlib import _api, cbook, docstring\n-import matplotlib.artist\n+import matplotlib.artist as martist\n import matplotlib.colors as mcolors\n import matplotlib.font_manager as font_manager\n import matplotlib.lines as mlines\n@@ -1039,6 +1039,18 @@\n         list of `~.axis.Tick`\\s\n             The created ticks.\n         \"\"\"\n+        # Validate kwargs intended for Text properties *before* potentially using them.\n+        # This ensures validation happens even if labels is None.\n+        if kwargs:\n+            valid_text_props = martist.ArtistInspector(mtext.Text).get_setters()\n+            invalid_kwargs = set(kwargs) - set(valid_text_props)\n+            if invalid_kwargs:\n+                raise AttributeError(\n+                    f\"Unknown Text properties {invalid_kwargs}. These kwargs \"\n+                    f\"only take effect if 'labels' is also passed. For other \"\n+                    f\"tick properties, use tick_params().\")\n+\n         self._set_tick_locations(ticks, minor=minor)\n         if labels is not None:\n             self.set_ticklabels(labels, minor=minor, **kwargs)\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-24970", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -727,13 +727,13 @@\n             # This is the most common case, so optimize for it.\n             # Note: <= and >= must be used here, not < and >, to make sure\n             # that out-of-range values are assigned the over/under colors.\n-            xa[xa > self.N - 1] = self._i_over\n-            xa[xa < 0] = self._i_under\n+            xa[xa > self.N - 1] = xa.dtype.type(self._i_over)\n+            xa[xa < 0] = xa.dtype.type(self._i_under)\n         elif self.cmap.colorbar_extend == 'min':\n-            xa[xa < 0] = self._i_under\n+            xa[xa < 0] = xa.dtype.type(self._i_under)\n         elif self.cmap.colorbar_extend == 'max':\n-            xa[xa > self.N - 1] = self._i_over\n+            xa[xa > self.N - 1] = xa.dtype.type(self._i_over)\n         if mask_bad:\n-            xa[mask_bad] = self._i_bad\n+            xa[mask_bad] = xa.dtype.type(self._i_bad)\n         return xa\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-25079", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -39,12 +39,13 @@\n         # transform from 0-1 to vmin-vmax:\n         if not self.norm.scaled():\n             self.norm.vmin = 0\n             self.norm.vmax = 1\n-        self.norm.vmin, self.norm.vmax = mtransforms.nonsingular(\n-            self.norm.vmin, self.norm.vmax, expander=0.1)\n         if (not isinstance(self.norm, colors.BoundaryNorm) and\n                 (self.boundaries is None)):\n+            # Ensure norm limits are valid before calling inverse.\n+            # This was the point of #24490 but the original placement caused\n+            # issues when swapping norms interactively (#24910).\n+            self.norm.vmin, self.norm.vmax = mtransforms.nonsingular(\n+                self.norm.vmin, self.norm.vmax, expander=0.1)\n             b = self.norm.inverse(b)\n\n         self._boundaries = np.asarray(b, dtype=float)\n```\n"}
{"instance_id": "matplotlib__matplotlib-25311", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -143,3 +143,30 @@\n     def _update_bbox_to_anchor(self, loc_in_canvas):\n         loc_in_bbox = self.legend.axes.transAxes.transform(loc_in_canvas)\n         self.legend.set_bbox_to_anchor(loc_in_bbox)\n+\n+    def __getstate__(self):\n+        \"\"\"Override to remove canvas and callbacks.\"\"\"\n+        # Get state from parent classes (Artist)\n+        state = super().__getstate__().copy()\n+        # Prune the state dictionary for pickling.\n+        state['_observers'] = []  # Clear observers list\n+        state['canvas'] = None    # Remove canvas reference\n+        state.pop('_bg_cache', None)  # Remove blit cache\n+        # DraggableOffsetBox references artist and offsetbox, which are the\n+        # legend and its _legend_box respectively. Legend pickling should\n+        # handle restoring these, so we don't explicitly save/restore them here.\n+        return state\n+\n+    def __setstate__(self, state):\n+        \"\"\"Override to restore and reconnect.\"\"\"\n+        # Restore state using parent classes' __setstate__\n+        super().__setstate__(state)\n+        # Re-connect after unpickling.\n+        # The canvas should be part of the unpickled figure/axes structure.\n+        # We rely on the legend object being correctly unpickled first,\n+        # including its figure and canvas references.\n+        if self.legend and self.legend.figure and self.legend.figure.canvas:\n+            self.canvas = self.legend.figure.canvas\n+            self.connect()  # Re-register callbacks\n+        else:\n+            # Ensure canvas is None if it couldn't be restored\n+            self.canvas = None\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-25332", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -36,6 +36,7 @@\n from matplotlib import _api, _blocking_input, cbook, docstring, rcParams\n from matplotlib import axes, gridspec as gridspec_module, legend\n from matplotlib.artist import Artist, artist_picking_meth\n+from matplotlib.cbook import Grouper\n from matplotlib.container import Container\n from matplotlib.figure import FigureBase\n from matplotlib.gridspec import GridSpec\n@@ -103,6 +104,20 @@\n         # done by the Axes themselves.\n         self._layout_engine = None\n \n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Prune the state dictionary.\n+        # _align_label_groups contains weakrefs which are not picklable.\n+        state.pop('_align_label_groups', None)\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        # Need to restore anything that was popped in __getstate__.\n+        # Re-initialize the groupers used for label alignment.\n+        # Note: This loses the alignment state, but makes the figure picklable.\n+        self._align_label_groups = {'x': Grouper(), 'y': Grouper()}\n+\n     def __repr__(self):\n         return \"<{clsname} size {w:g}x{h:g} with {n} Axes>\".format(\n             clsname=self.__class__.__name__,\n```\n"}
{"instance_id": "matplotlib__matplotlib-25433", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -2508,9 +2508,18 @@\n class RangeSlider(SliderBase):\n     def _release(self, event):\n         \"\"\"Release event handler.\"\"\"\n+        # Check if a handle was active before potentially destructive callbacks.\n         if self.active_handle is not None:\n+            # Store the fact that a handle was active.\n+            was_active = True\n+\n             self.active_handle = None\n-            self._update(event)\n-            self._observers.process('released', event)\n+            self._update(event)  # Potentially triggers 'changed' callback (e.g., clf()).\n+\n+            # Check if the widget is still valid (attached to a figure)\n+            # before calling the 'released' observer.\n+            still_valid = self.ax is not None and self.ax.figure is not None\n+            if still_valid and self.eventson:\n+                self._observers.process('released', event)\n             return True\n-        return False\n+        return False # No active handle was involved.\n```\n"}
{"instance_id": "matplotlib__matplotlib-25442", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1565,10 +1565,18 @@\n \n     def disconnect(self):\n         \"\"\"Disconnect the mouse events.\"\"\"\n-        for cid in self._cids:\n-            self.canvas.mpl_disconnect(cid)\n-        self._cids = []\n-        self.got_artist = False\n+        try:\n+            canvas = self.canvas\n+            if canvas is None:\n+                # Should not happen based on property definition, but check defensively.\n+                raise AttributeError(\"Canvas derived from ref_artist is None\")\n+        except AttributeError:\n+            # If canvas cannot be accessed (e.g., ref_artist removed),\n+            # simply clear the CIDs without trying to disconnect.\n+            pass\n+        else:\n+            for cid in self._cids:\n+                canvas.mpl_disconnect(cid)\n+        finally:\n+            # Always clear CIDs and reset flag, regardless of success.\n+            self._cids = []\n+            self.got_artist = False\n```\n"}
{"instance_id": "matplotlib__matplotlib-25498", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -958,6 +958,11 @@\n         Destroy and rebuild the colorbar. This is definitely not\n         efficient, but it is reliable.\n         \"\"\"\n+        _api.check_isinstance(cm.ScalarMappable, mappable=mappable)\n+        # Ensure the mappable's norm is autoscale before using it,\n+        # especially if the norm was recently replaced.\n+        if mappable.get_array() is not None:\n+            mappable.autoscale_None()\n \n         # Remove the current callback and connect to the new one.\n         # We need to do this because the mappable may be replaced by a new\n@@ -1008,23 +1013,26 @@\n         \"\"\"\n         Update the colormapping and ticks.\n         \"\"\"\n+        _api.check_isinstance(cm.ScalarMappable, mappable=mappable)\n         self.mappable = mappable\n-        # Ensure the given mappable's norm has appropriate vmin and vmax set\n-        # even if mappable.draw has not yet been called.\n-        self.mappable.autoscale_None()\n+\n+        # Check if the norm or cmap has changed.\n+        if self.mappable.norm is not self.norm or self.mappable.cmap is not self.cmap:\n+            # Update the colorbar's norm and cmap\n+            self.norm = self.mappable.norm\n+            self.cmap = self.mappable.cmap\n+            # Ensure the new norm is autoscale before drawing\n+            arr = self.mappable.get_array()\n+            if arr is not None:\n+                # Use autoscale_None to avoid overriding limits already set\n+                # on the norm instance by the user.\n+                self.norm.autoscale_None(arr)\n+            # Need to trigger a full redraw, mark relevant state.\n+            # This ensures that things like ticks and labels which depend\n+            # on the norm are recalculated.\n+            self._update_dict['all'] = True\n \n         # Update the text properties from the mappable\n         self._label = self.mappable.colorbar_label\n-        # Update the colorbar label font properties\n-        # Need to check whether the mappable has had these properties set\n-        # before trying to sync them\n-        if self.mappable.colorbar_label_properties:\n-            self.ax.set_ylabel(\n-                self._label,\n-                fontproperties=self.mappable.colorbar_label_properties)\n-        else:\n-            self.ax.set_ylabel(self._label)\n+        # Sync the label text and font properties.\n+        self.ax.set_ylabel(\n+            self._label,\n+            fontproperties=getattr(self.mappable,\n+                                   'colorbar_label_properties', None))\n \n         self.stale = True\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-26011", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -1218,10 +1218,12 @@\n         if auto is not None:\n             self.set_autoscale_on(auto)\n \n+        # Emit callback if limits actually changed. The emit flag is used below\n+        # to control recursive updates of shared axes, which should not\n+        # affect whether the callback is emitted on *this* axis.\n+        if changed:\n+            self.axes.callbacks.process(f'{name}lim_changed', self.axes)\n+\n         if emit:\n-            self.axes.callbacks.process(f'{name}lim_changed', self.axes)\n             # Call all of the other axes that are shared with this one\n-            # _process_unit_info may have added new shared axes, possibly\n-            # including the current one, so retrieve the list again.\n             shared = getattr(self.axes, f'_shared_{name}_axes')\n             for other in shared.get_siblings(self.axes):\n                 if other is not self.axes and other.axison:\n\n```\n"}
{"instance_id": "matplotlib__matplotlib-26020", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/lib/mpl_toolkits/axes_grid1/axes_grid.py\n+++ b/lib/mpl_toolkits/axes_grid1/axes_grid.py\n@@ -6,6 +6,7 @@\n from matplotlib.axes import Axes\n from matplotlib.figure import Figure\n from matplotlib import _api\n+import mpl_toolkits.axes_grid1.mpl_axes as mpl_axes\n \n from .axes_divider import Size, SubplotDivider, Divider\n from .mpl_axes import Axes as MplAxes\n@@ -24,11 +25,18 @@\n \n \n def _tick_only(ax, bottom_on=True, left_on=True):\n-    bottom_off = not bottom_on\n-    left_off = not left_on\n-    ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n-    ax.axis[\"top\"].toggle(ticklabels=True, label=True)\n-    ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n-    ax.axis[\"right\"].toggle(ticklabels=True, label=True)\n+    if not isinstance(ax, mpl_axes.Axes):\n+        # Standard Axes (like GeoAxes) or other custom axes\n+        ax.xaxis.set_tick_params(which='both', bottom=bottom_on, labelbottom=bottom_on)\n+        ax.xaxis.set_tick_params(which='both', top=False, labeltop=False)\n+        ax.yaxis.set_tick_params(which='both', left=left_on, labelleft=left_on)\n+        ax.yaxis.set_tick_params(which='both', right=False, labelright=False)\n+    else:\n+        # mpl_toolkits.axes_grid1.mpl_axes.Axes or derived\n+        bottom_off = not bottom_on\n+        left_off = not left_on\n+        ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n+        ax.axis[\"top\"].toggle(ticklabels=True, label=True)\n+        ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+        ax.axis[\"right\"].toggle(ticklabels=True, label=True)\n \n \n class Grid:\n```\n"}
{"instance_id": "mwaskom__seaborn-2848", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -171,6 +171,11 @@\n             else:\n                 hue_order = list(hue_order)\n\n+            # Filter the data frame to prevent error further down\n+            # when hue_order does not include all unique values GH#2375\n+            mask = data[hue].isin(hue_order)\n+            data = data[mask]\n+\n             # Map hue levels to colors\n             n_colors = len(hue_order)\n             palette = self._resolve_palette(palette, data, hue, n_colors)\n\n```\n"}
{"instance_id": "mwaskom__seaborn-3010", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/seaborn/_stats/regression.py\n+++ b/seaborn/_stats/regression.py\n@@ -22,6 +22,10 @@\n         self.gridsize = gridsize\n\n     def _fit_predict(self, data):\n+\n+        # Drop rows with missing data\n+        data = data.dropna(subset=[\"x\", \"y\"])\n+\n         x = data[\"x\"].to_numpy()\n         y = data[\"y\"].to_numpy()\n         if not x.size:\n```\n"}
{"instance_id": "mwaskom__seaborn-3190", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/seaborn/_core/typing.py\n+++ b/seaborn/_core/typing.py\n"}
{"instance_id": "mwaskom__seaborn-3407", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -1360,7 +1360,7 @@\n                 hue_vals = np.unique(hue_data)\n                 kwargs[\"hue_order\"] = hue_vals\n         else:\n-            vector = self.data[var]\n+            vector = self.data.loc[:, var]\n             if self._dropna:\n                 vector = vector.dropna()\n             func(x=vector, ax=ax, **kwargs)\n@@ -1396,8 +1396,8 @@\n                 kwargs[\"hue_order\"] = hue_vals\n                 func(x=x_data, y=y_data, hue=hue_data, ax=ax, **kwargs)\n         else:\n-            x_data = self.data[x_var]\n-            y_data = self.data[y_var]\n+            x_data = self.data.loc[:, x_var]\n+            y_data = self.data.loc[:, y_var]\n             if self._dropna:\n                 not_na = pd.notnull(x_data) & pd.notnull(y_data)\n                 x_data = x_data[not_na]\n\n```\n"}
{"instance_id": "pallets__flask-4045", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -25,6 +25,8 @@\n             root_path=root_path,\n         )\n         self.name = name\n+        if \".\" in self.name:\n+            raise ValueError(\"Blueprint name cannot contain dots.\")\n         self.url_prefix = url_prefix\n         self.subdomain = subdomain\n         self.deferred_functions: t.List[DeferredSetupFunction] = []\n\n```\n"}
{"instance_id": "pallets__flask-4992", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/flask/config.py\n+++ b/src/flask/config.py\n@@ -58,6 +58,7 @@\n         filename: str,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n+        mode: str = \"r\",\n     ) -> bool:\n         \"\"\"Update the values in the config from a file that is loaded\n         using the ``load`` parameter. The loaded data is passed to the\n@@ -68,8 +69,9 @@\n             import json\n             app.config.from_file(\"config.json\", load=json.load)\n \n-            import toml\n-            app.config.from_file(\"config.toml\", load=toml.load)\n+            # config.toml needs to be opened in binary mode\n+            import tomllib\n+            app.config.from_file(\"config.toml\", load=tomllib.load, mode=\"rb\")\n \n         :param filename: The path to the data file. This can be an\n             absolute path or relative to the config root path.\n@@ -78,6 +80,7 @@\n         :type load: ``Callable[[Reader], Mapping]`` where ``Reader``\n             implements a ``read`` method.\n         :param silent: Ignore the file if it doesn't exist.\n+        :param mode: The mode to open the file with, defaults to ``\"r\"`` (text).\n         :return: ``True`` if the file was loaded successfully.\n \n         .. versionadded:: 2.0\n@@ -85,7 +88,7 @@\n         filename = os.path.join(self.root_path, filename)\n \n         try:\n-            with open(filename) as f:\n+            with open(filename, mode=mode) as f:\n                 obj = load(f)\n         except OSError as e:\n             if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n\n```\n"}
{"instance_id": "pallets__flask-5063", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -336,7 +336,7 @@\n     Pass ``--all-methods`` to show HEAD and OPTIONS methods.\n     \"\"\"\n     from flask import current_app\n-\n+    \n     rules = sorted(\n         current_app.url_map.iter_rules(), key=lambda r: (r.subdomain or \"\", r.rule)\n     )\n@@ -344,18 +344,25 @@\n     if not rules:\n         click.echo(\"No routes were registered.\")\n         return\n-\n+    \n+    server_name = current_app.config.get(\"SERVER_NAME\") or \"<no server name>\"\n     rows = []\n-    widths = {\"endpoint\": 0, \"methods\": 0, \"rule\": 0}\n-\n+    has_subdomain = False\n+    \n     for rule in rules:\n         if endpoint and not rule.endpoint.startswith(endpoint):\n             continue\n-\n+        \n+        if rule.subdomain:\n+            has_subdomain = True\n+            domain = f\"{rule.subdomain}.{server_name}\"\n+        else:\n+            domain = server_name\n+            \n         methods = \", \".join(\n             sorted(m for m in rule.methods if include_methods or m not in {\"HEAD\", \"OPTIONS\"})\n         )\n-        rows.append((rule.endpoint, methods, rule.rule))\n+        rows.append((domain, rule.endpoint, methods, rule.rule))\n \n     if not rows:\n         msg = f\"No routes found that matched endpoint {endpoint!r}.\"\n@@ -363,17 +370,24 @@\n         click.echo(msg)\n         return\n \n-    widths[\"endpoint\"] = max(len(r[0]) for r in rows)\n-    widths[\"methods\"] = max(len(r[1]) for r in rows)\n-    widths[\"rule\"] = max(len(r[2]) for r in rows)\n+    widths = {\"domain\": 0, \"endpoint\": 0, \"methods\": 0, \"rule\": 0}\n+    \n+    if has_subdomain:\n+        widths[\"domain\"] = max(len(r[0]) for r in rows)\n+        \n+    widths[\"endpoint\"] = max(len(r[1]) for r in rows)\n+    widths[\"methods\"] = max(len(r[2]) for r in rows)\n+    widths[\"rule\"] = max(len(r[3]) for r in rows)\n \n-    header = {\n-        \"endpoint\": \"Endpoint\",\n-        \"methods\": \"Methods\",\n-        \"rule\": \"Rule\",\n-    }\n+    header_row = {\"endpoint\": \"Endpoint\", \"methods\": \"Methods\", \"rule\": \"Rule\"}\n+    \n+    if has_subdomain:\n+        header_row[\"domain\"] = \"Domain\"\n+        widths[\"domain\"] = max(widths[\"domain\"], len(header_row[\"domain\"]))\n+        \n     widths[\"endpoint\"] = max(widths[\"endpoint\"], len(header_row[\"endpoint\"]))\n     widths[\"methods\"] = max(widths[\"methods\"], len(header_row[\"methods\"]))\n     widths[\"rule\"] = max(widths[\"rule\"], len(header_row[\"rule\"]))\n-    rule = \"{endpoint:<{ew}}  {methods:<{mw}}  {rule:<{rw}}\"\n-    click.echo(rule.format(ew=widths[\"endpoint\"], mw=widths[\"methods\"], rw=widths[\"rule\"], **header))\n-    click.echo(\"-\" * (widths[\"endpoint\"] + widths[\"methods\"] + widths[\"rule\"] + 4))\n+    \n+    header_items = [\"domain\", \"endpoint\", \"methods\", \"rule\"] if has_subdomain else [\"endpoint\", \"methods\", \"rule\"]\n+    header = \"  \".join(f\"{{{h}:<{widths[h]}}}\" for h in header_items).format(**header_row)\n+    click.echo(header)\n+    click.echo(\"-\" * len(header))\n+\n+    row_template = \"  \".join(f\"{{{i}:<{widths[h]}}}\" for i, h in enumerate(header_items))\n+\n+    for row in rows:\n+        click.echo(row_template.format(*row))\n```\n"}
{"instance_id": "psf__requests-1963", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -738,7 +738,7 @@\n         hist = [] # Keep track of requests for cycles\n\n         while resp.is_redirect:\n-            prepared_request = req.copy()\n+            prepared_request = resp.request.copy()\n\n             # Exhaust read stream so that the connection can be reused.\n             # This only needs to be done if an explicit stream=True is not passed.\n@@ -749,7 +749,7 @@\n             resp.close()\n\n             url = resp.headers['location']\n-            method = req.method\n+            method = resp.request.method\n\n             # Handle redirection without scheme (see: RFC 1808 Section 4)\n             if url.startswith('//'):\n\n```\n"}
{"instance_id": "psf__requests-2148", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -615,6 +615,9 @@\n                 result = None\n                 try:\n                     result = self.raw.read(decode_content=True)\n+                except (ProtocolError, DecodeError, ReadTimeoutError, socket.error) as e:\n+                    raise ConnectionError(e)\n+\n                 except AttributeError:\n                     # If the raw object doesn't have a read() method, indicate\n                     # that the body has been consumed. This is consistent with\n@@ -641,7 +644,9 @@\n                     # This is the location of the error raised by the server,\n                     # not the location of the error inside Requests.\n                     self.close()\n-                    raise e\n+                    raise e\n+                # Catch connection-related errors from self.raw.stream\n+                except (ProtocolError, DecodeError, ReadTimeoutError, socket.error) as e:\n+                    raise ConnectionError(e)\n                 except AttributeError:\n                     # Standard file-like object.\n                     while True:\n@@ -649,6 +654,9 @@\n                             chunk = self.raw.read(chunk_size)\n+                        except (ProtocolError, DecodeError, ReadTimeoutError, socket.error) as e:\n+                            raise ConnectionError(e)\n+\n                         if not chunk:\n                             break\n                         # Don't need to check encoding because we didn't decode the stream\n```\n"}
{"instance_id": "psf__requests-2317", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -16,7 +16,7 @@\n from .hooks import default_hooks\n from .structures import CaseInsensitiveDict\n from .compat import (cookielib, urlparse, urlunparse, urljoin, urlsplit,\n-                     quote, unquote, builtin_str, CaseInsensitiveDict)\n+                     quote, unquote, builtin_str, CaseInsensitiveDict, bytes)\n \n from .utils import (requote_uri, get_environ_proxies, get_netrc_auth,\n                     should_bypass_proxies, get_auth_from_url, to_key_val_list,\n@@ -414,10 +414,13 @@\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n         # Create the Request.\n-        method = builtin_str(method)\n+        # Ensure method is a string. Correctly handle bytes in Python 3.\n+        if isinstance(method, bytes):\n+            # Decode using ASCII; HTTP methods should be ASCII safe\n+            method = method.decode('ascii')\n+        # Ensure method is represented as a native string and uppercase.\n+        method = builtin_str(method).upper()\n         req = Request(\n-            method = method.upper(),\n+            method = method,\n             url = url,\n             headers = headers,\n             files = files,\n\n```\n"}
{"instance_id": "psf__requests-2674", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/requests/exceptions.py\n+++ b/requests/exceptions.py\n@@ -7,7 +7,10 @@\n This module contains the set of Requests' exceptions.\n \n \"\"\"\n+# Grab the base exception from urllib3\n from .packages.urllib3.exceptions import HTTPError as BaseHTTPError\n+# Grab the specific exceptions from urllib3\n+from .packages.urllib3.exceptions import (TimeoutError as Urllib3TimeoutError, ConnectTimeoutError as Urllib3ConnectTimeoutError, ReadTimeoutError as Urllib3ReadTimeoutError, DecodeError as Urllib3DecodeError)\n \n \n class RequestException(IOError):\n@@ -53,12 +56,12 @@\n     \"\"\"\n \n \n-class ConnectTimeout(ConnectionError, Timeout):\n+class ConnectTimeout(ConnectionError, Timeout, Urllib3ConnectTimeoutError):\n     \"\"\"The request timed out while trying to connect to the remote server.\n \n     Requests that produced this error are safe to retry.\n     \"\"\"\n-\n+    # Note: Inherits from Urllib3ConnectTimeoutError for broader catch compatibility.\n \n class ReadTimeout(Timeout):\n     \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\n@@ -89,7 +92,7 @@\n     \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\n \n \n-class ContentDecodingError(RequestException, BaseHTTPError):\n+class ContentDecodingError(RequestException, Urllib3DecodeError):\n     \"\"\"Failed to decode response content\"\"\"\n \n \n\n```\n"}
{"instance_id": "psf__requests-3362", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -40,13 +40,19 @@\n def stream_decode_response_unicode(iterator, r):\n     \"\"\"Stream decodes a iterator.\"\"\"\n \n-    if r.encoding is None:\n+    encoding = r.encoding\n+\n+    # If no encoding is specified in the headers, test if the content\n+    # has been read partially or fully. If it has been, fall back to\n+    # apparent_encoding (codecs.chardet) like .text does.\n+    if encoding is None and r._content_consumed and r.content:\n+        if isinstance(r.content, bytes):\n+            encoding = r.apparent_encoding\n+\n+    if encoding is None:\n         for item in iterator:\n             yield item\n         return\n \n-    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')\n+    decoder = codecs.getincrementaldecoder(encoding)(errors='replace')\n     for chunk in iterator:\n         rv = decoder.decode(chunk)\n         if rv:\n\n```\n"}
{"instance_id": "psf__requests-863", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -98,8 +98,14 @@\n             hooks = {} if hooks is None else hooks\n\n             self.hooks = dict()\n-            for (k, v) in list(hooks.items()):\n-                self.register_hook(event=k, hook=v)\n+            # Register hooks from the passed dict.\n+            for event, hook in hooks.items():\n+                if callable(hook):\n+                    # Passed a single callable.\n+                    self.register_hook(event=event, hook=hook)\n+                elif hasattr(hook, '__iter__') and not isinstance(hook, (str, bytes)):\n+                    # Passed an iterable of callables.\n+                    for h in hook:\n+                        self.register_hook(event=event, hook=h)\n\n             self.method = method\n             self.url = url\n\n```\n"}
{"instance_id": "pydata__xarray-3364", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -139,15 +139,9 @@\n     result_vars = {}\n     if variables_to_merge:\n         to_merge = {var: [] for var in variables_to_merge}\n-\n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n-\n+            # if a variable is not in this dataset, it should have been added\n+            # by the align function with the fill_value\n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n \n```\n"}
{"instance_id": "pydata__xarray-4094", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -60,8 +60,12 @@\n \n         # pull variables out of datarray\n         data_dict = {}\n-        for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+        for name in variables:\n+            selected_da = self.sel({variable_dim: name})\n+            # drop the stacked coordinate (remains as scalar coord after sel)\n+            if dim in selected_da.coords:\n+                selected_da = selected_da.drop_vars(dim)\n+            data_dict[name] = selected_da.squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)\n```\n"}
{"instance_id": "pydata__xarray-4248", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/xarray/core/formatting.py\n+++ b/xarray/core/formatting.py\n@@ -118,11 +118,19 @@\n     return f\"{first_col} {dims_str:<{dims_width}} {dtype_str}{preview_str}\"\n \n \n-def summarize_coord(name: Hashable, var: Variable, col_width: int) -> str:\n+def summarize_coord(name: Hashable, var: Variable, is_index: bool, col_width: int) -> str:\n     \"\"\"Summarize a single coordinate variable.\"\"\"\n-    is_index = isinstance(var._indexes, dict) and list(var._indexes.keys()) == [name]\n+    marker = \"*\" if is_index else \" \"\n+    units = var.attrs.get(\"units\")\n+    if units is not None:\n+        name_str = f\"{name}, in {units}\"\n+    else:\n+        name_str = f\"{name}\"\n+\n+    first_col = f\"{marker}{name_str:<{col_width - 1}}\"\n+\n     dims_str = f\"({', '.join(map(str, var.dims))})\" if var.dims else \"\"\n-    first_col = f\"{'*' if is_index else ' '}{name:<{col_width - 1}}\"\n+\n     return _summarize_var_or_coord(first_col, var, dims_str, col_width)\n \n \n@@ -130,8 +138,14 @@\n     \"\"\"Summarize a single data variable.\"\"\"\n     dims_str = f\"({', '.join(map(str, var.dims))})\"\n     # first col has a single space offset\n-    first_col = f\" {name:<{col_width - 1}}\"\n+    units = var.attrs.get(\"units\")\n+    if units is not None:\n+        name_str = f\"{name}, in {units}\"\n+    else:\n+        name_str = f\"{name}\"\n+\n+    first_col = f\" {name_str:<{col_width - 1}}\"\n     return _summarize_var_or_coord(first_col, var, dims_str, col_width)\n \n \n@@ -164,16 +178,28 @@\n     max_rows: int,\n ):\n     \"\"\"Summarize coordinates in a Dataset or DataArray.\"\"\"\n+    if not coords:\n+        return []\n+\n+    is_index = {k: k in indexes for k in coords}\n+\n+    coord_names_with_units = []\n+    for k, v in coords.items():\n+        units = v.attrs.get(\"units\")\n+        coord_str = f\"{k}, in {units}\" if units is not None else f\"{k}\"\n+        coord_names_with_units.append(f\"{'*' if is_index[k] else ' '}{coord_str}\")\n+\n+    col_width = max(col_width, max(len(s) for s in coord_names_with_units))\n+\n     summary = [\"Coordinates:\"]\n-    if coords:\n-        is_index = {k: k in indexes for k in coords}\n-        coord_lines = [\n-            summarize_coord(k, v, col_width) for k, v in coords.items() if k in is_index\n-        ] + [\n-            summarize_coord(k, v, col_width) for k, v in coords.items() if k not in is_index\n-        ]\n-        summary += _maybe_truncate(coord_lines, max_rows)\n-    return \"\\n\".join(summary)\n+    coord_lines = [\n+        summarize_coord(k, v, is_index[k], col_width)\n+        for k, v in coords.items()\n+        if k in is_index\n+    ] + [\n+        summarize_coord(k, v, is_index[k], col_width) for k, v in coords.items() if k not in is_index\n+    ]\n+    return summary + _maybe_truncate(coord_lines, max_rows)\n \n \n def summarize_vars(\n@@ -183,11 +209,19 @@\n     max_rows: int,\n ):\n     \"\"\"Summarize data variables in a Dataset.\"\"\"\n+    if not variables:\n+        return []\n+\n+    var_names_with_units = []\n+    for k, v in variables.items():\n+        units = v.attrs.get(\"units\")\n+        var_str = f\"{k}, in {units}\" if units is not None else f\"{k}\"\n+        var_names_with_units.append(f\" {var_str}\")  # Add space prefix\n+\n+    col_width = max(col_width, max(len(s) for s in var_names_with_units))\n+\n     summary = [\"Data variables:\"]\n-    if variables:\n-        var_lines = [summarize_datavar(k, v, col_width) for k, v in variables.items()]\n-        summary += _maybe_truncate(var_lines, max_rows)\n-    return \"\\n\".join(summary)\n+    var_lines = [summarize_datavar(k, v, col_width) for k, v in variables.items()]\n+    return summary + _maybe_truncate(var_lines, max_rows)\n \n \n def summarize_attrs(attrs: Mapping, max_rows: int | None = None) -> list[str]:\n@@ -211,16 +245,16 @@\n     summary = [\"<xarray.Dataset>\"]\n \n     col_width = _calculate_col_width(ds.dims)\n-    dims_start = pretty_print(\"Dimensions:\", col_width)\n+    dims_start = pretty_print(\"Dimensions:\", col_width + 1)  # +1 for asterisk/space\n     summary.append(f\"{dims_start}({dim_summary})\")\n \n     summary.extend(\n-        summarize_coords(ds.coords, ds.indexes, col_width, OPTIONS[\"display_max_rows\"])\n+        summarize_coords(ds.coords, ds.indexes, col_width + 1, OPTIONS[\"display_max_rows\"])\n     )\n \n     summary.extend(\n         summarize_vars(\n-            ds.data_vars, ds.indexes, col_width, OPTIONS[\"display_max_rows\"]\n+            ds.data_vars, ds.indexes, col_width + 1, OPTIONS[\"display_max_rows\"]\n         )\n     )\n \n\n```\n"}
{"instance_id": "pydata__xarray-4493", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -16,6 +16,7 @@\n from . import dtypes, indexing\n from .arithmetic import CoercibleMapping\n from .common import AbstractArray, AbstractVariable, DataWithCoords\n+from .dataarray import DataArray\n from .formatting import (\n     diff_array_repr,\n     diff_attrs_repr,\n@@ -216,6 +217,9 @@\n                 pass\n             elif isinstance(data, Variable):\n                 # Load variable data into memory TBC by DataArray.load()\n+                return data.data\n+            elif isinstance(data, DataArray):\n+                # Load variable data into memory TBC by DataArray.load()\n                 return data.data\n             elif isinstance(data, np.ma.MaskedArray):\n                 # convert to numpy array with NaN\n\n```\n"}
{"instance_id": "pydata__xarray-5131", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/xarray/core/groupby.py\n+++ b/xarray/core/groupby.py\n@@ -400,7 +400,7 @@\n             # TODO: add dimensions to this repr?\n \n         def __repr__(self) -> str:\n-            return \"{}, grouped over {!r} \\n{!r} groups with labels {}\".format(\n+            return \"{}, grouped over {!r}\\n{!r} groups with labels {}\".format(\n                 self.__class__.__name__,\n                 self._unique_coord.name,\n                 self._unique_coord.size,\n```\n"}
{"instance_id": "pylint-dev__pylint-5859", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/pylint/checkers/misc.py\n+++ b/pylint/checkers/misc.py\n@@ -44,9 +44,9 @@\n \n         notes = \"|\".join(re.escape(note) for note in self.config.notes)\n         if self.config.notes_rgx:\n-            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n+            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\"\n         else:\n-            regex_string = rf\"#\\s*({notes})\\b\"\n+            regex_string = rf\"#\\s*({notes})\"\n \n         self._fixme_pattern = re.compile(regex_string, re.I)\n \n\n```\n"}
{"instance_id": "pylint-dev__pylint-6506", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/pylint/config/config_initialization.py\n+++ b/pylint/config/config_initialization.py\n@@ -55,7 +55,8 @@\n     if unrecognized_options:\n         msg = \", \".join(unrecognized_options)\n         linter.add_message(\"unrecognized-option\", line=0, args=msg)\n-        raise _UnrecognizedOptionError(options=unrecognized_options)\n+        # Do not raise _UnrecognizedOptionError here.\n+        # The message E0015 has been added and Pylint will exit with the correct status code.\n \n     # Set the current module to configuration as we don't know where\n     # the --load-plugins key is coming from\n```\n"}
{"instance_id": "pylint-dev__pylint-7080", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -23,6 +23,7 @@\n import itertools\n import logging\n import optparse  # pylint: disable=deprecated-module\n+import os\n import platform\n import sys\n import tokenize\n@@ -900,8 +901,14 @@\n         self, filepath: str, base_name: str, mod_name: Optional[str] = None\n     ) -> bool:\n         \"\"\"Check if the file should be ignored.\"\"\"\n-        # Ignore based on the file path\n-        if utils.is_ignored_by_regex(filepath, self.config.ignore_paths):\n+        # Ignore based on the file path: Use path relative to CWD for pattern matching\n+        # This allows patterns like '^src/...' to work correctly even if an absolute path is passed.\n+        try:\n+            relative_filepath = os.path.relpath(filepath)\n+        except ValueError:\n+            # Fallback for different drives on Windows or other errors\n+            relative_filepath = filepath\n+        if utils.is_ignored_by_regex(relative_filepath, self.config.ignore_paths):\n             return True\n \n         # Ignore based on the base name\n\n```\n"}
{"instance_id": "pylint-dev__pylint-7114", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -15,8 +15,10 @@\n                     modname = os.path.splitext(basename)[0]\n                 if os.path.isdir(something):\n                     filepath = os.path.join(something, \"__init__.py\")\n+                    is_arg_package = os.path.exists(filepath)\n                 else:\n                     filepath = something\n+                    is_arg_package = False # Input is a file, not a package directory\n             else:\n                 # suppose it's a module or package\n                 modname = something\n@@ -27,6 +29,7 @@\n                     if filepath is None:\n                         continue\n                 except (ImportError, SyntaxError) as ex:\n+                    is_arg_package = False # Module path, not a directory argument\n                     # The SyntaxError is a Python bug and should be\n                     # removed once we move away from imp.find_module: https://bugs.python.org/issue10588\n                     errors.append({\"key\": \"fatal\", \"mod\": modname, \"ex\": ex})\n@@ -47,7 +50,10 @@\n             is_namespace = modutils.is_namespace(spec)\n             is_directory = modutils.is_directory(spec)\n             is_package = is_directory and not is_namespace\n-        if not is_namespace:\n+\n+        # Add the initial argument to the result list, but only if it's\n+        # a file, a module/package found via import, or an actual package directory.\n+        if not (os.path.isdir(something) and not is_arg_package):\n             result.append(\n                 {\n                     \"path\": filepath,\n\n```\n"}
{"instance_id": "pylint-dev__pylint-7228", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/pylint/checkers/base.py\n+++ b/pylint/checkers/base.py\n@@ -100,7 +100,7 @@\n     \"function-rgx\": Option(\n         type=\"regexp\",\n         metavar=\"<regexp>\",\n-        default=re.compile(r\"^[a-z_][a-z0-9_]{2,30}$\"),\n+        default=r\"^[a-z_][a-z0-9_]{2,30}$\",\n         help=\"Regular expression matching correct function names.\",\n     ),\n     \"function-name-style\": Option(\n```\n"}
{"instance_id": "pylint-dev__pylint-7993", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -1,10 +1,12 @@\n # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html\n # For details: https://github.com/PyCQA/pylint/blob/main/LICENSE\n \n+import re\n+import string\n import sys\n import warnings\n from dataclasses import asdict\n-from typing import TYPE_CHECKING, TextIO\n+from typing import TYPE_CHECKING, Set, TextIO\n \n from pylint.interfaces import IReporter\n from pylint.message import Message\n@@ -17,13 +19,11 @@\n \n     name = \"text\"\n     extension = \"txt\"\n-    line_format = \"{path}:{line}:{column}: {msg_id}: {msg} ({symbol})\"\n+    _template = \"{path}:{line}:{column}: {msg_id}: {msg} ({symbol})\"\n \n     def __init__(self, output: TextIO | None = None) -> None:\n         super().__init__(output)\n-        self._modules: set[str] = set()\n-        self._template = self.line_format\n-        self._fixed_template = self.line_format\n+        self._modules: Set[str] = set()\n         \"\"\"The output format template with any unrecognized arguments removed.\"\"\"\n \n     def on_set_current_module(self, module: str, filepath: str | None) -> None:\n@@ -38,17 +38,16 @@\n         # Set template to the currently selected template\n         self._template = template\n \n-        # Check to see if all parameters in the template are attributes of the Message\n-        arguments = re.findall(r\"\\{(.+?)(:.*)?\\}\", template)\n-        for argument in arguments:\n-            if argument[0] not in MESSAGE_FIELDS:\n-                warnings.warn(\n-                    f\"Don't recognize the argument '{argument[0]}' in the --msg-template. \"\n-                    \"Are you sure it is supported on the current version of pylint?\"\n-                )\n-                template = re.sub(r\"\\{\" + argument[0] + r\"(:.*?)?\\}\", \"\", template)\n-        self._fixed_template = template\n+        # Check to see if all parameters in the template are attributes of the Message.\n+        # We use string.Formatter().parse() to correctly iterate through field names\n+        # and handle escaped braces {{ or }}.\n+        formatter = string.Formatter()\n+        for _, field_name, _, _ in formatter.parse(template):\n+            if field_name is not None and field_name not in MESSAGE_FIELDS:\n+                warnings.warn(\n+                    f\"Don't recognize the argument '{field_name}' in the --msg-template. \"\n+                    \"Are you sure it is supported on the current version of pylint?\",\n+                    UserWarning,\n+                )\n \n     def write_message(self, msg: Message) -> None:\n         \"\"\"Convenience method to write a formatted message with class default\n@@ -58,7 +57,7 @@\n         for key in (\"end_line\", \"end_column\"):\n             self_dict[key] = self_dict[key] or \"\"\n \n-        self.writeln(self._fixed_template.format(**self_dict))\n+        self.writeln(self._template.format(**self_dict))\n \n     def handle_message(self, msg: Message) -> None:\n         \"\"\"Manage message of different type and in the context of path.\"\"\"\n```\n"}
{"instance_id": "pytest-dev__pytest-11143", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -757,6 +757,8 @@ class AssertionRewriter(ast.NodeVisitor):\n     def is_rewrite_disabled(self, docstring: Optional[str]) -> bool:\n         \"\"\"Check if the module has disabled assertion rewriting.\"\"\"\n         # Check if the docstring exists and is actually a string.\n-        if not docstring:\n+        # The check handles None, empty string, and potentially other types (like int\n+        # as reported in #11135).\n+        if not isinstance(docstring, str):\n             return False\n+        # Now we know docstring is a non-empty string.\n         return \"PYTEST_DONT_REWRITE\" in docstring\n\n```\n"}
{"instance_id": "pytest-dev__pytest-11148", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -2,40 +2,41 @@\n from types import ModuleType\n from typing import Dict\n from typing import List\n+from typing import Optional\n from typing import TYPE_CHECKING\n from typing import Union\n \n from _pytest.compat import assert_never\n from _pytest.config import ExitCode\n from _pytest.config import PytestPluginManager\n-from _pytest.nodes import Collector\n from _pytest.outcomes import skip\n from _pytest.warning_types import PytestWarning\n \n \n def insert_missing_modules(modules: Dict[str, ModuleType], module_name: str) -> None:\n     \"\"\"\n-    Used by ``import_path`` to create intermediate modules when using mode=importlib.\n+    Ensure intermediate modules exist and parent attributes are set.\n+    Avoids creating dummy modules or interfering with sys.modules directly,\n+    relying on importlib.import_module for loading.\n \n     When we want to import a module as \"src.tests.test_foo\" for example, we need\n     to create empty modules \"src\" and \"src.tests\" after inserting \"src.tests.test_foo\",\n     otherwise \"src.tests.test_foo\" is not importable by ``__import__``.\n     \"\"\"\n     module_parts = module_name.split(\".\")\n+    # Start with the most specific module; child is initially None.\n     child_module: Union[ModuleType, None] = None\n-    module: Union[ModuleType, None] = None\n     child_name: str = \"\"\n-    while module_name:\n-        if module_name not in modules:\n+\n+    # Iterate from the full name down to the top-level package.\n+    # Example: \"a.b.c\" -> \"a.b\" -> \"a\"\n+    while module_parts:\n+        current_module_name = \".\".join(module_parts)\n+        parent_module: Union[ModuleType, None] = None\n+\n+        if current_module_name in modules:\n+            parent_module = modules[current_module_name]\n+        elif sys.meta_path:  # Only try importing if importers exist\n             try:\n                 # If sys.meta_path is empty, calling import_module will issue\n                 # a warning and raise ModuleNotFoundError. To avoid the\n                 # warning, we check sys.meta_path explicitly and raise the error\n-                # ourselves to fall back to creating a dummy module.\n-                if not sys.meta_path:\n-                    raise ModuleNotFoundError\n-                module = importlib.import_module(module_name)\n+                # ourselves to skip the import attempt.\n+                # Attempt to import the *real* module.\n+                parent_module = importlib.import_module(current_module_name)\n+                # Note: import_module already updates sys.modules.\n             except ModuleNotFoundError:\n-                module = ModuleType(\n-                    module_name,\n-                    doc=\"Empty module created by pytest's importmode=importlib.\",\n-                )\n-        else:\n-            module = modules[module_name]\n-        if child_module:\n-            # Add child attribute to the parent that can reference the child\n-            # modules.\n-            if not hasattr(module, child_name):\n-                setattr(module, child_name, child_module)\n-                modules[module_name] = module\n-        # Keep track of the child module while moving up the tree.\n-        child_module, child_name = module, module_name.rpartition(\".\")[-1]\n-        module_parts.pop(-1)\n-        module_name = \".\".join(module_parts)\n+                # Module doesn't exist, don't create a dummy.\n+                # parent_module remains None.\n+                pass\n+\n+        # If we resolved the parent module for this level,\n+        # and we have a child module from the previous level,\n+        # set the attribute on the parent to point to the child.\n+        if parent_module and child_module and not hasattr(parent_module, child_name):\n+            setattr(parent_module, child_name, child_module)\n+\n+        # Prepare for the next iteration (moving up the hierarchy).\n+        # The current parent becomes the child for the next level up.\n+        child_module = parent_module\n+        child_name = module_parts.pop()  # Get the last part (like 'c', then 'b', then 'a')\n \n \n def resolve_package_path(path: Path) -> Optional[Path]:\n```\n"}
{"instance_id": "pytest-dev__pytest-5103", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "pytest-dev__pytest-5221", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -17,10 +17,11 @@\n 15             return\n 16         if verbose > 0:\n 17             bestrel = get_best_relpath(fixture_def.func)\n-18             funcargspec = \"{} -- {}\".format(argname, bestrel)\n+19             funcargspec = \"{argname} [{scope}] -- {bestrel}\".format(\n+20                 argname=argname, scope=fixture_def.scope, bestrel=bestrel\n+21             )\n 19         else:\n-20             funcargspec = argname\n-21         tw.line(funcargspec, green=True)\n+22             funcargspec = \"{argname} [{scope}]\".format(argname=argname, scope=fixture_def.scope)\n+23         tw.line(funcargspec, green=True)\n 22         fixture_doc = fixture_def.func.__doc__\n 23         if fixture_doc:\n 24             write_docstring(tw, fixture_doc)\n@@ -100,10 +101,11 @@\n 41             continue\n 42         if verbose > 0:\n 43             funcargspec = \"%s -- %s\" % (argname, bestrel)\n+44             funcargspec = \"{argname} [{scope}] -- {bestrel}\".format(\n+45                 argname=argname, scope=fixturedef.scope, bestrel=bestrel\n+46             )\n 44         else:\n-45             funcargspec = argname\n-46         tw.line(funcargspec, green=True)\n+47             funcargspec = \"{argname} [{scope}]\".format(argname=argname, scope=fixturedef.scope)\n+48         tw.line(funcargspec, green=True)\n 47         loc = getlocation(fixturedef.func, curdir)\n 48         doc = fixturedef.func.__doc__ or \"\"\n 49         if doc:\n\n```\n"}
{"instance_id": "pytest-dev__pytest-5227", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -15,7 +15,7 @@\n from _pytest.config import create_terminal_writer\n from _pytest.pathlib import Path\n\n-DEFAULT_LOG_FORMAT = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s\"\n+DEFAULT_LOG_FORMAT = \"%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s\"\n DEFAULT_LOG_DATE_FORMAT = \"%H:%M:%S\"\n\n\n```\n"}
{"instance_id": "pytest-dev__pytest-5413", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/_code/code.py\n+++ b/src/_pytest/_code/code.py\n@@ -247,16 +247,14 @@\n         return self._excinfo == other._excinfo\n\n     def __str__(self):\n+        \"\"\"Return the string representation of the underlying exception.\"\"\"\n         try:\n             s = str(self.value)\n         except (KeyboardInterrupt, SystemExit):\n             raise\n         except:  # noqa\n-            s = \"<[{} raised in repr()]>\".format(\n+            s = \"<[{} raised in str()]>\".format(\n                 getattr(self.value, \"__class__\", \"unknown\")\n             )\n-        if self._striptext:\n-            s = s.replace(self._striptext, \"\")\n         return s\n\n     def __repr__(self):\n\n```\n"}
{"instance_id": "pytest-dev__pytest-5495", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/src/_pytest/assertion/util.py\n+++ b/src/_pytest/assertion/util.py\n@@ -262,9 +262,12 @@\n             else:\n                 side = \"Right\"\n                 seq = right\n+            extra_item = seq[idx]\n+            # Format bytes item as repr(b'x') instead of its ordinal integer\n+            formatted_item = repr(bytes([extra_item])) if isinstance(seq, bytes) else repr(extra_item)\n             diff_items.append(\n-                \"%s contains more items, first extra item: %r\\n\"\n+                \"%s contains more items, first extra item: %s\\n\"\n                 \"\\n\"\n-                \"Use -v to get the full diff\" % (side, seq[idx])\n+                \"Use -v to get the full diff\" % (side, formatted_item)\n             )\n\n         if verbose > 0:\n```\n"}
{"instance_id": "pytest-dev__pytest-5692", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/junitxml.py\n+++ b/src/_pytest/junitxml.py\n@@ -6,6 +6,8 @@\n import sys\n import time\n import functools\n+import socket\n+import datetime\n from io import StringIO\n from xml.sax.saxutils import escape\n \n@@ -39,6 +41,9 @@\n         )\n         logfile.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>')\n \n+        timestamp = datetime.datetime.fromtimestamp(self.suite_start_time).isoformat(timespec=\"seconds\")\n+        hostname = socket.gethostname()\n+\n         suite_node = Junit.testsuite(\n             self._get_global_properties_node(),\n             [x.to_xml() for x in self.node_reporters_ordered],\n@@ -48,6 +53,8 @@\n             skipped=self.stats[\"skipped\"],\n             tests=numtests,\n             time=\"%.3f\" % suite_time_delta,\n+            hostname=hostname,\n+            timestamp=timestamp,\n         )\n         logfile.write(Junit.testsuites([suite_node]).unicode(indent=0))\n         logfile.close()\n\n```\n"}
{"instance_id": "pytest-dev__pytest-6116", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/src/_pytest/main.py\n+++ b/src/_pytest/main.py\n@@ -70,6 +70,7 @@\n             help=\"show help on Python coding style checking\",\n         )\n         group.addoption(\n+            \"-C\",  # TODO: Deprecate -c.\n             \"--collect-only\",\n             action=\"store_true\",\n             help=\"only collect tests, don't execute them.\",\n```\n"}
{"instance_id": "pytest-dev__pytest-7168", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/_io/saferepr.py\n+++ b/src/_pytest/_io/saferepr.py\n@@ -8,7 +8,7 @@\n def _format_repr_exception(exc: Exception, obj: object) -> str:\n     \"\"\"Format the technical representation of an object that raised an exception during __repr__.\"\"\"\n     try:\n-        obj_cls_name = obj.__class__.__name__\n+        obj_cls_name = type(obj).__name__\n         obj_id = id(obj)\n     except Exception:\n         # Fallback if even accessing the class name fails.\n\n```\n"}
{"instance_id": "pytest-dev__pytest-7220", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/terminal.py\n+++ b/src/_pytest/terminal.py\n@@ -700,7 +700,8 @@\n             lineno = reprcrash.lineno\n             try:\n                 # Display path relative to startpath if possible.\n-                displaypath = str(path.relto(self.startpath))  # type: ignore[union-attr]\n+                # Use os.path.relpath to prevent CWD influence (issue #6428)\n+                displaypath = os.path.relpath(str(path), str(self.startpath))\n                 if self.config.getoption(\"short_test_summary\"):\n                     displaypath = os.path.basename(displaypath)\n             except ValueError:\n\n```\n"}
{"instance_id": "pytest-dev__pytest-7373", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/src/_pytest/mark/evaluate.py\n+++ b/src/_pytest/mark/evaluate.py\n@@ -1,5 +1,6 @@\n import os\n import platform\n+import _pytest._code\n import sys\n import traceback\n from typing import Any\n@@ -13,26 +14,6 @@\n from _pytest.config import Config\n from _pytest.nodes import Item\n from _pytest.store import StoreKey\n-\n-\n-evalcache_key = StoreKey[Dict[str, Any]]()\n-\n-\n-def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n-    default = {}  # type: Dict[str, object]\n-    evalcache = config._store.setdefault(evalcache_key, default)\n-    try:\n-        return evalcache[expr]\n-    except KeyError:\n-        import _pytest._code\n-\n-        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n-        evalcache[expr] = x = eval(exprcode, d)\n-        return x\n-\n-\n-# Note: This class is copied by pytest-subtesthack. Refactor with care.\n \n \n class MarkEvaluator:\n@@ -100,7 +81,8 @@\n             try:\n                 d = {\"os\": os, \"sys\": sys, \"platform\": platform, \"config\": config}\n                 d.update(globals_)\n-                result = cached_eval(config, condition, d)\n+                expr_code = _pytest._code.compile(condition, mode=\"eval\")\n+                result = eval(expr_code, d)\n             except TEST_OUTCOME:\n                 # e.g. skip(\"reason\")\n                 raise\n```\n"}
{"instance_id": "pytest-dev__pytest-7432", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -10,8 +10,6 @@\n         else:\n             rep.longrepr = \"Unexpected success\"\n         rep.outcome = \"failed\"\n-    elif item.config.option.runxfail:\n-        pass  # don't interfere\n     elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n         assert call.excinfo.value.msg is not None\n         rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n\n```\n"}
{"instance_id": "pytest-dev__pytest-7490", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -190,9 +190,21 @@\n \n     outcome = yield\n     report = outcome.get_result()\n-    evalxfail = getattr(item, \"_evalxfail\", None)\n+\n+    # Re-evaluate xfail marker for the call phase report, in case\n+    # it was added dynamically during the test execution using\n+    # request.node.add_marker(pytest.mark.xfail). Fixes #7799.\n+    if report.when == \"call\":\n+        xfail_marker = item.get_closest_marker(\"xfail\")\n+        if xfail_marker:\n+            evalxfail: Optional[EvalXFail] = EvalXFail(item, xfail_marker)\n+            item._evalxfail = evalxfail  # Update stored evalxfail for consistency.\n+        else:\n+            evalxfail = None\n+            if hasattr(item, \"_evalxfail\"):\n+                delattr(item, \"_evalxfail\")  # Clear if marker removed dynamically.\n+    else:\n+        # For setup/teardown, use the previously evaluated status.\n+        evalxfail = getattr(item, \"_evalxfail\", None)\n\n     # Check if the test item was explicitly marked as xfail.\n     if evalxfail and evalxfail.wasvalid() and evalxfail.istrue():\n\n```\n"}
{"instance_id": "pytest-dev__pytest-8365", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -119,9 +119,11 @@\n             from_env = os.environ.get(\"PYTEST_DEBUG_TEMPROOT\")\n             temproot = Path(from_env or tempfile.gettempdir()).resolve()\n             user = get_user() or \"unknown\"\n+            # Sanitize the username to make it usable as part of a directory name.\n+            # Replace non-alphanumeric characters with underscores.\n+            sanitized_user = re.sub(r\"\\W\", \"_\", user)\n             # use a sub-directory in the temproot to speed-up\n             # make_numbered_dir() call\n-            rootdir = temproot.joinpath(f\"pytest-of-{user}\")\n+            rootdir = temproot.joinpath(f\"pytest-of-{sanitized_user}\")\n             rootdir.mkdir(exist_ok=True)\n             basetemp = make_numbered_dir_with_cleanup(\n                 prefix=\"pytest-\", root=rootdir, keep=3, lock_timeout=LOCK_TIMEOUT\n\n```\n"}
{"instance_id": "pytest-dev__pytest-8906", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -38,10 +38,12 @@\n             if e.allow_module_level:\n                 raise\n             raise self.CollectError(\n-                \"Using pytest.skip outside of a test is not allowed. \"\n-                \"To decorate a test function, use the @pytest.mark.skip \"\n-                \"or @pytest.mark.skipif decorators instead, and to skip a \"\n-                \"module use `pytestmark = pytest.mark.{skip,skipif}.\"\n+                \"Using pytest.skip outside of a test function is not allowed, unless \"\n+                \"allow_module_level=True is used. To skip a test function, use the \"\n+                \"@pytest.mark.skip or @pytest.mark.skipif decorators. To skip a module during \"\n+                \"collection, use pytest.skip(..., allow_module_level=True) at the module level. \"\n+                \"Using pytestmark = pytest.mark.skipif is generally recommended for conditional skipping \"\n+                \"of modules, but may not work if the module contains syntax errors in the \"\n+                \"skipping Python version.\"\n             ) from e\n         self.config.pluginmanager.consider_module(mod)\n         return mod\n```\n"}
{"instance_id": "pytest-dev__pytest-9359", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "scikit-learn__scikit-learn-10297", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1078,10 +1078,12 @@\n     a one-versus-all approach. Concretely, this is implemented by taking\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n+    # store_cv_values was added to RidgeCV but not to RidgeClassifierCV\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv, gcv_mode=None)\n+            scoring=scoring, cv=cv, gcv_mode=None, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n\n     def fit(self, X, y, sample_weight=None):\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-10508", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/preprocessing/label.py\n+++ b/sklearn/preprocessing/label.py\n@@ -89,6 +89,10 @@\n         check_is_fitted(self, 'classes_')\n         y = column_or_1d(y, warn=True)\n\n+        # transform of empty array is empty array\n+        if y.size == 0:\n+            return np.array([], dtype=int)\n+\n         classes = np.unique(y)\n         if len(np.intersect1d(classes, self.classes_)) < len(classes):\n             diff = np.setdiff1d(classes, self.classes_)\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-10949", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -1,6 +1,7 @@\n \"\"\"Utilities for input validation\"\"\"\n \n # Authors: Olivier Grisel <olivier.grisel@ensta.org>\n+#          Gael Varoquaux <gael.varoquaux@normalesup.org>\n #          Andreas Mueller <amueller@ais.uni-bonn.de>\n #          Lars Buitinck <L.J.Buitinck@uva.nl>\n #          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n@@ -14,7 +15,7 @@\n import scipy.sparse as sp\n from ..externals import six\n \n-from ..exceptions import NotFittedError\n+from ..exceptions import NotFittedError, DataConversionWarning\n from .fixes import _object_dtype_isnan\n from ._joblib import Memory\n from .deprecation import deprecated\n@@ -451,6 +452,14 @@\n         if force_all_finite:\n             _assert_all_finite(array,\n                                allow_nan=force_all_finite == 'allow-nan')\n+\n+    # Warn if input dtype was object and converted to numeric\n+    if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n+        # Check specifically for object to numeric conversion\n+        if dtype_orig.kind == 'O' and np.issubdtype(array.dtype, np.number):\n+            warnings.warn(\"Data with input dtype %s was converted to %s%s.\"\n+                          % (dtype_orig, array.dtype, context),\n+                          DataConversionWarning)\n\n     if copy and array is array_orig:\n         # The copy was handled already if ensure_2d=True\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-11040", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/neighbors/approximate.py\n+++ b/sklearn/neighbors/approximate.py\n@@ -1,3 +1,6 @@\n+import numbers\n+\n+import numpy as np\n from ..base import BaseEstimator, NeighborsBase\n from ..utils import check_array\n from ..utils.validation import check_is_fitted\n@@ -29,6 +32,11 @@\n \n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        elif not isinstance(n_neighbors, numbers.Integral):\n+            raise TypeError(\"n_neighbors does not take %s value, enter integer value\"\n+                            % type(n_neighbors))\n+        elif n_neighbors <= 0:\n+            raise ValueError(\"Expected n_neighbors > 0. Got %d\" % n_neighbors)\n \n         X = check_array(X, accept_sparse='csr')\n \n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -1,10 +1,13 @@\n \"\"\"Base classes for nearest neighbors.\"\"\"\n # Authors: Jake Vanderplas <vanderplas@astro.washington.edu>\n #          Fabian Pedregosa <fabian.pedregosa@inria.fr>\n-#          Alexandre Gramfort <alexandre.gramfort@inria.fr>\n+#          Alexandre Gramfort <alexandre.gramfort@inria.fr>s\n #          Sparseness support by Lars Buitinck\n #          Multi-output support by Arnaud Joly <a.joly@ulg.ac.be>\n # License: BSD 3 clause (C) INRIA, University of Amsterdam\n+import numbers\n+from abc import ABCMeta, abstractmethod\n+\n import numpy as np\n from scipy.sparse import issparse\n \n@@ -14,8 +17,6 @@\n from ..utils.validation import check_is_fitted\n from ..utils.multiclass import check_classification_targets\n from ..utils import gen_even_slices, get_chunk_n_rows\n-from abc import ABCMeta, abstractmethod\n-import six\n \n from .ball_tree import BallTree\n from .kd_tree import KDTree\n@@ -56,6 +57,12 @@\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n \n+        if not isinstance(n_neighbors, numbers.Integral):\n+            raise TypeError(\"n_neighbors does not take %s value, enter integer value\"\n+                            % type(n_neighbors))\n+        elif n_neighbors <= 0:\n+            raise ValueError(\"Expected n_neighbors > 0. Got %d\" % n_neighbors)\n+\n         if X is not None:\n             query_is_train = False\n             X = check_array(X, accept_sparse='csr')\n@@ -81,7 +88,7 @@\n         n_jobs = _get_n_jobs(self.n_jobs)\n \n \n-class RadiusNeighborsMixin(object):\n+class RadiusNeighborsMixin:\n     \"\"\"Mixin for radius-based neighbors searches\"\"\"\n \n     def radius_neighbors(self, X=None, radius=None, return_distance=True):\n@@ -158,7 +165,7 @@\n         return result\n \n \n-class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n+class NeighborsBase(BaseEstimator, metaclass=ABCMeta):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n     @abstractmethod\n@@ -167,6 +174,12 @@\n                  p=2, metric_params=None, n_jobs=1):\n \n         self.n_neighbors = n_neighbors\n+        if (self.n_neighbors is not None and\n+                not isinstance(self.n_neighbors, numbers.Integral)):\n+            raise TypeError(\"n_neighbors does not take %s value, enter integer value\"\n+                            % type(self.n_neighbors))\n+        if self.n_neighbors is not None and self.n_neighbors <= 0:\n+            raise ValueError(\"Expected n_neighbors > 0. Got %d\" % n_neighbors)\n         self.radius = radius\n         self.algorithm = algorithm\n         self.leaf_size = leaf_size\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-11281", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -8,14 +8,14 @@\n from __future__ import print_function\n\n import warnings\n-from abc import ABCMeta, abstractmethod\n+from abc import ABCMeta, abstractmethod\n from time import time\n\n import numpy as np\n\n from .. import cluster\n from ..base import BaseEstimator\n-from ..base import DensityMixin\n+from ..base import DensityMixin # Keep this import\n from ..externals import six\n from ..exceptions import ConvergenceWarning\n from ..utils import check_array, check_random_state\n@@ -64,3 +64,44 @@\n                           \"but got %d features\"\n                           % (n_features, X.shape[1]))\n      return X\n+\n+\n+class _BaseMixture(six.with_metaclass(ABCMeta, BaseEstimator,\n+                                      DensityMixin)):\n+    \"\"\"Base class for mixture models.\n+\n+    This abstract class specifies an interface for all mixture classes and\n+    provides basic common methods for mixture models.\n+    \"\"\"\n+\n+    @abstractmethod\n+    def _get_parameters(self):\n+        pass\n+\n+    @abstractmethod\n+    def _set_parameters(self, params):\n+        pass\n+\n+    @abstractmethod\n+    def fit(self, X, y=None):\n+        \"\"\"Estimate model parameters.\"\"\"\n+        pass\n+\n+    @abstractmethod\n+    def predict(self, X):\n+        \"\"\"Predict the labels for the data samples in X using trained model.\"\"\"\n+        pass\n+\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Estimate model parameters using X and predict the labels for X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y=y)\n+        return self.labels_\n--- a/sklearn/mixture/bayesian_mixture.py\n+++ b/sklearn/mixture/bayesian_mixture.py\n@@ -14,7 +14,7 @@\n from ..utils.validation import check_is_fitted\n from ._gaussian_mixture import _compute_precision_cholesky\n from ._gaussian_mixture import _estimate_gaussian_parameters\n-from .base import _check_X\n+from .base import _check_X, _BaseMixture\n\n\n # Values used in the model. We can't change this constants !\n@@ -22,7 +22,7 @@\n LOG_2 = np.log(2.)\n\n\n-class BayesianGaussianMixture(BaseEstimator, DensityMixin):\n+class BayesianGaussianMixture(_BaseMixture):\n     \"\"\"Variational Bayesian estimation of a Gaussian mixture.\n\n     This class allows to infer an approximate posterior distribution over the\n@@ -280,6 +280,9 @@\n         self.converged_ = is_converged\n         self.n_iter_ = n_iter + 1\n\n+        # Store labels for fit_predict compatibility\n+        self.labels_ = self.predict(X)\n+\n         return self\n\n     def _e_step(self, X):\n--- a/sklearn/mixture/gaussian_mixture.py\n+++ b/sklearn/mixture/gaussian_mixture.py\n@@ -13,7 +13,7 @@\n from ..utils.validation import check_is_fitted\n from ._gaussian_mixture import _estimate_gaussian_parameters\n from ._gaussian_mixture import _estimate_log_gaussian_prob\n-from .base import _check_X\n+from .base import _check_X, _BaseMixture\n\n\n warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n@@ -21,7 +21,7 @@\n # XXX remove in 0.20\n warnings.filterwarnings(\"ignore\", message=\"The covariance matrix is singular\")\n\n\n-class GaussianMixture(BaseEstimator, DensityMixin):\n+class GaussianMixture(_BaseMixture):\n     \"\"\"Gaussian Mixture.\n\n     Representation of a Gaussian mixture model probability distribution.\n@@ -258,6 +258,9 @@\n             self.precisions_cholesky_ = _compute_precision_cholesky(\n                 self.covariances_, self.covariance_type)\n\n+        # Store labels for fit_predict compatibility\n+        self.labels_ = self.predict(X)\n+\n         return self\n\n     def _e_step(self, X):\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-12471", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -111,10 +111,21 @@\n     # The dtype of the converted X will be the same as the categories_\n     # XXX: We need to find a better solution, see\n     # https://github.com/numpy/numpy/issues/11799\n-    X_copy = X.copy()\n+\n+    # Determine the dtype for the copy of X\n+    # Default to the dtype of the categories\n+    X_dtype = categories_[0].dtype\n+\n+    # Check if original X has string-like dtype\n+    is_string_like = (X.dtype.kind in ('S', 'U', 'O'))\n+\n+    # If ignoring unknowns and dealing with strings/objects,\n+    # use object dtype for the copy to prevent truncation issues.\n+    if handle_unknown == 'ignore' and is_string_like:\n+        X_dtype = object\n+    X_copy = X.astype(X_dtype, copy=True)\n+\n     diff, valid_mask = _check_unknown(X_copy, categories_, handle_unknown)\n-\n-    # Compute numerical representation of X\n     X_int = np.zeros(X.shape, dtype=int)\n     X_mask = np.ones(X.shape, dtype=bool)\n \n@@ -122,41 +133,30 @@\n         Xi = X_copy[:, i]\n         valid_mask_i = valid_mask[:, i]\n \n+        # Use dictionary mapping if X_copy is object type, otherwise searchsorted\n+        use_dict_mapping = (X_dtype == object)\n+\n+        if use_dict_mapping:\n+            map_to = {cat: k for k, cat in enumerate(categories_[i])}\n+\n         if diff is None:\n             # All categories are known, avoid overhead of checking unknown\n             # categories\n             # categories_ is already sorted\n-            if categories_[i].dtype.kind == 'O':\n-                # searchsorted has known bug with object type\n-                map_to = {cat: k for k, cat in enumerate(categories_[i])}\n+            if use_dict_mapping:\n                 X_int[:, i] = np.array([map_to[x] for x in Xi])\n             else:\n                 X_int[:, i] = np.searchsorted(categories_[i], Xi)\n         else:\n             # Some categories are unknown, handle them accordingly\n             # Assign index to known categories, leave unknown categories (-1)\n-            # Masking is needed because searchsorted does not handle -1\n             X_int[:, i] = -1\n-            valid_mask_i = valid_mask[:, i]\n-            X_mask[:, i] = valid_mask_i\n-            # searchsorted has known bug with object type\n-            if categories_[i].dtype.kind == 'O':\n-                X_int[:, i] = -1\n-                # Create map for faster lookup\n-                map_to = {cat: k for k, cat in enumerate(categories_[i])}\n-                # Assign indices only for valid rows\n-                ix = np.where(valid_mask_i)[0]\n-                for j in ix:\n+            valid_indices = np.where(valid_mask_i)[0]\n+            X_mask[:, i] = valid_mask_i # Update overall mask\n+\n+            if use_dict_mapping:\n+                for j in valid_indices:\n                     X_int[j, i] = map_to[Xi[j]]\n             else:\n-                # Assign indices only for valid rows\n-                X_int[:, i][valid_mask_i] = np.searchsorted(categories_[i],\n-                                                            Xi[valid_mask_i])\n-\n-    # 2. Perform encoding\n-    mask = valid_mask.ravel()\n-    n_values = [len(cats) for cats in categories_]\n+                X_int[valid_indices, i] = np.searchsorted(categories_[i], Xi[valid_mask_i])\n \n+    # 2. Perform encoding\n+    mask = X_mask.ravel()\n+    n_values = [len(cats) for cats in categories_]\n     feature_indices = np.cumsum([0] + n_values)\n     indices = (X_int + feature_indices[:-1]).ravel()[mask]\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-13142", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -250,4 +250,6 @@\n                         # Set converged status based on best run\n                         self.converged_ = is_converged\n \n-            return resp.argmax(axis=1)\n+        # Calculate labels using the final fitted parameters\n+        _, log_resp = self._e_step(X)\n+        return log_resp.argmax(axis=1)\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-13241", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -1,10 +1,11 @@\n \"\"\"Kernel Principal component analysis (KPCA)\"\"\"\n \n+import numpy as np\n from scipy import linalg\n from scipy.sparse.linalg import eigsh\n \n from ..base import BaseEstimator, TransformerMixin, _UnstableOn32BitMixin\n-from ..utils.validation import check_is_fitted, check_array, check_random_state\n+from ..utils.validation import check_is_fitted, check_array, check_random_state\n from ..metrics.pairwise import pairwise_kernels\n from ..preprocessing import KernelCenterer\n from ..utils.arpack import eigsh as _eigsh  # needs to be imported earlier\n@@ -35,6 +36,10 @@\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # flip eigenvectors' sign to enforce deterministic output\n+        # we choose the sign based on the element with largest absolute value\n+        self.alphas_, _ = svd_flip(self.alphas_, np.zeros((self.alphas_.shape[1], 1)))\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-13439", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -253,6 +253,12 @@\n                                  self.steps[ind])\n             return Pipeline(steps, memory=self.memory)\n \n+    def __len__(self):\n+        \"\"\"\n+        Returns the length of the Pipeline\n+        \"\"\"\n+        return len(self.steps)\n+\n     # Estimator interface\n \n     def _validate_steps(self):\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-13496", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -11,6 +11,7 @@\n from ..tree import ExtraTreeRegressor\n from ..utils import check_random_state, check_array, gen_batches\n from ..utils.validation import check_is_fitted, _num_samples\n+from ..utils.fixes import _joblib_parallel_args\n \n from .base import BaseEnsemble, _partition_estimators\n \n@@ -109,6 +110,10 @@\n     n_jobs : int or None, optional (default=None)\n         The number of jobs to run in parallel for both `fit` and `predict`.\n         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n+        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n+        for more details.\n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n         new forest. See :term:`the Glossary <warm_start>`.\n     behaviour : 'old' or 'new', optional (default='old')\n         Behaviour of the ``decision_function`` which can be either 'old' or\n@@ -146,7 +151,8 @@\n                   n_jobs=None,\n                   behaviour='old',\n                   random_state=None,\n-                  verbose=0):\n+                  verbose=0,\n+                  warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -160,7 +166,8 @@\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-13497", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/feature_selection/mutual_info_.py\n+++ b/sklearn/feature_selection/mutual_info_.py\n@@ -50,10 +50,11 @@\n     \"\"\"\n     X, y = check_X_y(X, y, accept_sparse='csc', y_numeric=not discrete_target)\n     n_samples, n_features = X.shape\n-\n-    if discrete_features == 'auto':\n+\n+    # Determine the discrete mask\n+    if isinstance(discrete_features, str) and discrete_features == 'auto':\n         discrete_features = issparse(X)\n-\n+    # Now discrete_features is bool or array-like\n     if isinstance(discrete_features, bool):\n         discrete_mask = np.empty(n_features, dtype=bool)\n         discrete_mask.fill(discrete_features)\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-13584", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -19,6 +19,7 @@\n from .utils._tags import _safe_tags\n from .utils.validation import check_X_y, check_array, _check_y\n from .utils.validation import _deprecate_positional_args\n+from .utils.validation import _is_arraylike_not_scalar\n \n from . import __version__\n \n@@ -218,10 +219,24 @@\n             if k not in init_params:\n                 changed_params[k] = v\n                 continue\n-            # XXX: We should delegate this logic to `__eq__`\n-            if init_params[k] != v:\n+\n+            default_value = init_params[k]\n+\n+            # XXX: We should delegate this logic to `__eq__` but\n+            # arrays are not comparable with `==`\n+            if type(v) is not type(default_value):\n+                # Treat None and 0 as same default value for backward compat\n+                # This avoids display complexity for user when array defaults\n+                # are None\n+                if not (_is_arraylike_not_scalar(v) and default_value is None):\n+                    changed_params[k] = v\n+            elif _is_arraylike_not_scalar(v):\n+                if not np.array_equal(v, default_value):\n+                    changed_params[k] = v\n+            elif v != default_value:\n                 changed_params[k] = v\n \n+\n         return changed_params\n \n     def __repr__(self, N_CHAR_MAX=700):\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-13779", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -41,6 +41,8 @@\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n+                if step is None:\n+                    continue\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-14087", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2190,7 +2190,7 @@\n                     w = w.reshape(len(classes_), len(folds), -1)\n                     w = np.mean(w, axis=1)\n                 else:\n-                    w = np.mean([coefs_paths[:, i, best_indices[i], :]\n+                    w = np.mean([coefs_paths[i, best_indices[i], :, :]\n                                  for i in range(len(folds))], axis=0)\n\n                 best_indices_C = best_indices % len(self.Cs_)\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-14092", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -11,6 +11,7 @@\n from __future__ import print_function\n \n from warnings import warn\n+import numbers\n import numpy as np\n import sys\n import time\n@@ -40,7 +41,8 @@\n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n             check_scalar(self.n_components, 'n_components', int, 1)\n-            check_scalar(self.n_components, 'n_components', int, 1)\n+            check_scalar(self.n_components, 'n_components', numbers.Integral,\n+                         min_val=1)\n \n             if self.n_components > X.shape[1]:\n                 raise ValueError('The preferred dimensionality of the '\n@@ -59,9 +61,12 @@\n                                   'previously learned transformation ({}).'\n                                   .format(X.shape[1],\n                                           self.components_.shape[1]))\n-\n-        check_scalar(self.max_iter, 'max_iter', int, 1)\n-        check_scalar(self.tol, 'tol', float, 0.)\n-        check_scalar(self.verbose, 'verbose', int, 0)\n+        \n+        check_scalar(self.max_iter, 'max_iter', numbers.Integral, min_val=1)\n+        # Ensure tol is a non-negative float\n+        check_scalar(self.tol, 'tol', numbers.Real, min_val=0.)\n+        # Ensure verbose is a non-negative integer\n+        check_scalar(self.verbose, 'verbose', numbers.Integral, min_val=0)\n \n         if self.callback is not None:\n             if not callable(self.callback):\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-14894", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -305,11 +305,18 @@\n         else:  # regression\n             n_class = 1\n\n-        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n+        # dual_coef_data comes from libsvm_sparse_train\n+\n+        if n_SV == 0:\n+            # No support vectors, result is empty matrix (shape n_class x 0)\n+            dual_coef_indices = np.array([], dtype=np.int32)\n+            dual_coef_indptr = np.zeros(n_class + 1, dtype=np.int32)\n+        else:\n+            # Construct indices and indptr for non-empty support vectors\n+            dual_coef_indices = np.tile(np.arange(n_SV, dtype=np.int32), n_class)\n+            # indptr is cumulative sum of row nnz, each row has n_SV entries\n+            dual_coef_indptr = np.arange(0, n_class * n_SV + 1, step=n_SV,\n+                                         dtype=np.int32)\n+\n         self.dual_coef_ = sp.csr_matrix(\n             (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n             (n_class, n_SV))\n-\n-    def predict(self, X):\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-14983", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -17,6 +17,7 @@\n from ..utils.validation import _num_samples, check_array\n from ..utils.validation import _deprecate_positional_args\n from ..utils.multiclass import type_of_target\n+from ..base import BaseEstimator\n \n __all__ = ['BaseCrossValidator',\n            'KFold',\n@@ -1007,7 +1008,7 @@\n ###############################################################################\n # Repeated K-Fold and Stratified K-Fold cross validators\n \n-class _RepeatedSplits(metaclass=ABCMeta):\n+class _RepeatedSplits(BaseEstimator, metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n     Repeats splits for cross-validators n times with different randomization\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-15512", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -57,8 +57,8 @@\n 56     <sphx_glr_auto_examples_cluster_plot_affinity_propagation.py>`.\n 57 \n 58     When the algorithm does not converge, it returns an empty array as\n-59     ``cluster_center_indices`` and ``-1`` as label for each training sample.\n-60 \n+59     ``cluster_centers_indices`` and ``-1`` as label for each training sample.\n+60\n 61     When all training samples have equal similarities and equal preferences,\n 62     the assignment of cluster centers and labels depends on the preference.\n 63     If the preference is smaller than the similarities, a single cluster center\n@@ -218,6 +218,7 @@\n     e = np.zeros((n_samples, convergence_iter))\n     ind = np.arange(n_samples)\n \n+    # Run affinity propagation\n     converged = False\n     for it in range(max_iter):\n         # tmp = A + S; compute responsibilities\n@@ -261,36 +262,36 @@\n             unconverged = (np.sum((se == convergence_iter) + (se == 0))\n                            != n_samples)\n             if (not unconverged and (K > 0)) or (it == max_iter):\n+            # Check convergence\n+            if not unconverged and K > 0:\n                 if verbose:\n-                    print(\"Converged after %d iterations.\" % it)\n+                    print(\"Converged after %d iterations.\" % (it + 1))\n+                converged = True\n                 break\n     else:\n+        # Loop finished without converging\n         if verbose:\n-            print(\"Did not converge\")\n+            print(\"Did not converge after %d iterations.\" % max_iter)\n\n-    I = np.flatnonzero(E)\n-    K = I.size  # Identify exemplars\n-\n-    if K > 0:\n-        c = np.argmax(S[:, I], axis=1)\n-        c[I] = np.arange(K)  # Identify clusters\n-        # Refine the final set of exemplars and clusters and return results\n-        for k in range(K):\n-            ii = np.where(c == k)[0]\n-            j = np.argmax(np.sum(S[ii[:, np.newaxis], ii], axis=0))\n-            I[k] = ii[j]\n-\n-        c = np.argmax(S[:, I], axis=1)\n-        c[I] = np.arange(K)\n-        labels = I[c]\n-        # Reduce labels to a sorted, gapless, list\n-        cluster_centers_indices = np.unique(labels)\n-        labels = np.searchsorted(cluster_centers_indices, labels)\n-    else:\n-        labels = np.empty(n_samples, dtype=np.intp)\n-        labels.fill(-1)\n+    if not converged:\n+        # Return empty results as per docstring\n+        labels = np.full(n_samples, -1, dtype=np.int64)\n         cluster_centers_indices = np.array([])\n+        n_iter_final = max_iter\n+    else:\n+        # Converged: Calculate final clusters\n+        I = np.flatnonzero(E)\n+        K = I.size  # Identify exemplars\n+        if K > 0:\n+            c = np.argmax(S[:, I], axis=1)\n+            c[I] = np.arange(K)  # Identify clusters\n+            # Refine the final set of exemplars and clusters\n+            for k in range(K):\n+                ii = np.where(c == k)[0]\n+                j = np.argmax(np.sum(S[ii[:, np.newaxis], ii], axis=0))\n+                I[k] = ii[j]\n+            c = np.argmax(S[:, I], axis=1)\n+            c[I] = np.arange(K)\n+            labels = I[c]\n+            # Reduce labels to a sorted, gapless, list\n+            cluster_centers_indices = np.unique(labels)\n+            labels = np.searchsorted(cluster_centers_indices, labels)\n+        else:\n+            # Converged, but K=0 (e.g., preference too low)\n+            labels = np.full(n_samples, -1, dtype=np.int64)\n+            cluster_centers_indices = np.array([])\n+        n_iter_final = it + 1\n\n     if return_n_iter:\n-        return cluster_centers_indices, labels, it + 1\n+        return cluster_centers_indices, labels, n_iter_final\n     else:\n         return cluster_centers_indices, labels\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-15535", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/metrics/cluster/_supervised.py\n+++ b/sklearn/metrics/cluster/_supervised.py\n@@ -42,10 +42,10 @@\n         The predicted labels.\n     \"\"\"\n     labels_true = check_array(\n-        labels_true, ensure_2d=False, ensure_min_samples=0\n+        labels_true, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n     labels_pred = check_array(\n-        labels_pred, ensure_2d=False, ensure_min_samples=0\n+        labels_pred, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n \n     # input checks\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-25500", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/calibration.py\n+++ b/sklearn/calibration.py\n@@ -761,7 +761,10 @@\n             this_pred = predictions[:, class_idx]\n\n             # Predict the calibrated probability using the current class's calibrator\n-            proba[:, class_idx] = calibrator.predict(this_pred)\n+            calibrated_prediction = calibrator.predict(this_pred)\n+            # Ensure the output is a 1D numpy array to be assigned to the slice\n+            # Handles cases where calibrator.predict returns a DataFrame (e.g., isotonic)\n+            proba[:, class_idx] = np.asarray(calibrated_prediction).squeeze(axis=-1)\n\n         # Normalize the probabilities\n         if n_classes == 2:\n\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-25570", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -644,8 +644,6 @@\n                     trans = self._name_to_fitted_passthrough[name]\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n\n             if column_as_strings:\n                 # Convert all columns to using their string labels\n```\n"}
{"instance_id": "scikit-learn__scikit-learn-25638", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sklearn/utils/multiclass.py\n+++ b/sklearn/utils/multiclass.py\n@@ -37,14 +37,26 @@\n         raise ValueError(\"No argument has been passed.\")\n     # Check that we don't mix label format\n \n+    # Keep track of original types for error reporting\n     ys_types = set(type_of_target(x) for x in ys)\n+    original_ys_types = ys_types.copy()\n+\n+    # Handle the case where nullable pandas dtypes might be classified as 'unknown'.\n+    # We want to allow mixing 'unknown' with 'binary' or 'multiclass', assuming\n+    # the 'unknown' type is compatible.\n+    if \"unknown\" in ys_types:\n+        ys_types.remove(\"unknown\")\n+\n+    # Allow mixing binary and multiclass labels, treating as multiclass\n     if ys_types == {\"binary\", \"multiclass\"}:\n         ys_types = {\"multiclass\"}\n \n-    if len(ys_types) > 1:\n-        raise ValueError(\"Mix type of y not allowed, got types %s\" % ys_types)\n+    # If, after removing 'unknown', we are left with no types or mixed types, raise error.\n+    if len(ys_types) == 0:\n+        # Only 'unknown' types were found\n+        raise ValueError(\"Mix type of y not allowed, got types %s\" % original_ys_types)\n+    elif len(ys_types) > 1:\n+        raise ValueError(\"Mix type of y not allowed, got types %s\" % original_ys_types)\n \n     label_type = ys_types.pop()\n \n```\n"}
{"instance_id": "scikit-learn__scikit-learn-25747", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -56,13 +56,19 @@\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # If the index does not match the length of the data, then we\n+            # assume the transformer has manipulated the index and thus we\n+            # do not overwrite it.\n+            if len(index) == data_to_wrap.shape[0]:\n+                data_to_wrap.index = index\n         return data_to_wrap\n\n     if _is_pandas_series(data_to_wrap):\n         if index is not None:\n-            data_to_wrap.index = index\n-        # TODO: Use `columns` to name the series?\n+            # If the index does not match the length of the data, then we\n+            # assume the transformer has manipulated the index and thus we\n+            # do not overwrite it.\n+            if len(index) == data_to_wrap.shape[0]:\n+                data_to_wrap.index = index\n         return data_to_wrap\n\n     # data_to_wrap is np.ndarray\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-10325", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sphinx-doc__sphinx-10451", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -12,7 +12,7 @@\n from types import ModuleType\n from typing import (TYPE_CHECKING, Any, Callable, Dict, Iterator, List, Optional, Sequence,\n                     Set, Tuple, Type, TypeVar, Union)\n-\n+from collections import defaultdict\n from docutils.statemachine import StringList\n \n import sphinx\n@@ -616,44 +616,55 @@\n         if 'return' in fields:\n             self._merge_typehints_for_return(fields['return'], sig)\n \n-    def _merge_typehints_for_params(self, fields: List[Tuple[str, List[str]]],\n+    def _merge_typehints_for_params(self, fields: List[Tuple[str, List[str]]],  # NoQA: C901\n                                     sig: Signature) -> None:\n         \"\"\"Merge typehints from signature to docstring.\"\"\"\n         annotations = get_type_hints(self.object, None, self.config)\n-        param_fields = {}\n-        for name, lines in fields:\n-            param_fields.setdefault(name, []).append(lines)\n \n+        # Keep track of parameters from the signature that have been handled\n+        handled_sig_params: Set[str] = set()\n+\n+        # First pass: Iterate through existing fields and merge type hints from signature\n+        for i in range(len(fields)):\n+            name, lines = fields[i]\n+\n+            # Determine the corresponding signature parameter based on the field name\n+            param = None\n+            sig_param_name = None\n+            if name.startswith('**'):\n+                _sig_param_name = name[2:]\n+                if _sig_param_name in sig.parameters and sig.parameters[_sig_param_name].kind == Parameter.VAR_KEYWORD:\n+                    param = sig.parameters[_sig_param_name]\n+                    sig_param_name = _sig_param_name\n+            elif name.startswith('*'):\n+                _sig_param_name = name[1:]\n+                if _sig_param_name in sig.parameters and sig.parameters[_sig_param_name].kind == Parameter.VAR_POSITIONAL:\n+                    param = sig.parameters[_sig_param_name]\n+                    sig_param_name = _sig_param_name\n+            elif name in sig.parameters and sig.parameters[name].kind not in (Parameter.VAR_POSITIONAL, Parameter.VAR_KEYWORD):\n+                 param = sig.parameters[name]\n+                 sig_param_name = name\n+\n+            if param and param.annotation is not Parameter.empty:\n+                # Found a match in the signature with an annotation, merge it\n+                annotation = stringify_typehint(annotations.get(param.name, param.annotation))\n+                if param.kind == Parameter.VAR_POSITIONAL:\n+                    marker = '*%s* --' % restify(annotation)\n+                elif param.kind == Parameter.VAR_KEYWORD:\n+                    marker = '**%s* --' % restify(annotation)\n+                else:\n+                    marker = '*%s* --' % restify(annotation)\n+\n+                field_lines = lines  # Use the lines directly from the current field tuple\n+                if not field_lines or field_lines[0].strip() == '--':\n+                    field_lines.insert(0, marker)\n+                elif field_lines[0].strip().startswith(':') and '--' not in field_lines[0]:\n+                    field_lines.insert(0, marker)\n+                elif field_lines[0].strip().endswith('--'):\n+                    field_lines[0] = field_lines[0].strip()[:-2] + marker\n+                else:\n+                    field_lines.insert(0, marker)\n+\n+                # Mark this signature parameter as handled\n+                if sig_param_name:\n+                    handled_sig_params.add(sig_param_name)\n+\n+        # Second pass: Add fields for signature parameters that were not in the docstring fields\n         for param in sig.parameters.values():\n-            if param.name not in param_fields:\n+            if param.name not in handled_sig_params and param.annotation is not Parameter.empty:\n                 # Add a brief description for undocumented parameters\n                 # using typehints\n-                if param.annotation is not Parameter.empty:\n-                    annotation = stringify_typehint(annotations.get(param.name, param.annotation))\n-                    if param.kind == Parameter.VAR_POSITIONAL:\n-                        field = ('*' + param.name, ['*%s* --' % restify(annotation)])\n-                    elif param.kind == Parameter.VAR_KEYWORD:\n-                        field = ('**' + param.name, ['**%s* --' % restify(annotation)])\n-                    else:\n-                        field = (param.name, ['*%s* --' % restify(annotation)])\n-\n-                    fields.append(field)\n-            elif param.annotation is not Parameter.empty:\n-                # Merge typehint into field list\n                 annotation = stringify_typehint(annotations.get(param.name, param.annotation))\n                 if param.kind == Parameter.VAR_POSITIONAL:\n-                    marker = '*%s* --' % restify(annotation)\n+                    field = ('*' + param.name, ['*%s* --' % restify(annotation)])\n                 elif param.kind == Parameter.VAR_KEYWORD:\n-                    marker = '**%s* --' % restify(annotation)\n+                    field = ('**' + param.name, ['**%s* --' % restify(annotation)])\n                 else:\n-                    marker = '*%s* --' % restify(annotation)\n-\n-                field_lines = param_fields[param.name][0]  # Get the first definition\n-                if not field_lines or field_lines[0].strip() == '--':\n-                    # parameter is documented, but has no description.\n-                    field_lines.insert(0, marker)\n-                elif field_lines[0].strip().startswith(':') and '--' not in field_lines[0]:\n-                    # parameter is documented, but has no description (ex. for :type:).\n-                    field_lines.insert(0, marker)\n-                elif field_lines[0].strip().endswith('--'):\n-                    # parameter is documented, but has no description.\n-                    field_lines[0] = field_lines[0].strip()[:-2] + marker\n-                else:\n-                    # parameter is documented. merge typehint to the description.\n-                    field_lines.insert(0, marker)\n+                    field = (param.name, ['*%s* --' % restify(annotation)])\n+                fields.append(field)  # Append the new field\n\n     def _merge_typehints_for_return(self, fields: List[Tuple[str, List[str]]],\n                                     sig: Signature) -> None:\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-11445", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sphinx-doc__sphinx-7686", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/ext/autosummary/generate.py\n+++ b/sphinx/ext/autosummary/generate.py\n@@ -68,7 +68,25 @@\n     ns.update(context)\n\n     if doc.objtype == 'module':\n-        ns['members'] = dir(obj)\n+        # find out all members that are documented documented\n+        members = []\n+        for name in dir(obj):\n+            try:\n+                value = safe_getattr(obj, name)\n+                doc_cls = get_documenter(app, value, obj)\n+                if (imported_members or\n+                        getattr(value, '__module__', None) == obj.__name__):\n+                    # skip members varaibles (cf. autodoc-skip-member event)\n+                    if skip_member(value, name, doc_cls.objtype):\n+                        continue\n+                    members.append(name)\n+            except AttributeError:\n+                continue\n+            except Exception as exc:\n+                logger.warning(__('autosummary: failed to determine %r to be documented, '\n+                                  'the following exception was raised:\\n%s'),\n+                               name, exc, type='autosummary')\n+                continue\n+        ns['members'] = members\n         ns['functions'], ns['all_functions'] = \\\n             get_members(obj, {'function'}, imported=imported_members)\n         ns['classes'], ns['all_classes'] = \\\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-7738", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -460,6 +460,11 @@\n     _google_typed_arg_regex = re.compile(r'\\s*(.+?)\\s*\\(\\s*(.*[^\\s]+)\\s*\\)')\n\n\n+    # Copied from sphinx.util.rst.escape, but without escaping backslash\n+    rst_escape_table = {ord('*'): r'\\*', ord('`'): r'\\`'}\n+    rst_escape_regex = re.compile(r'([*`])')\n+\n+\n     def __init__(self, docstring: Union[str, List[str]], config: SphinxConfig = None,\n                  app: Sphinx = None, what: str = '', name: str = '',\n                  obj: Any = None, options: Any = None) -> None:\n@@ -520,6 +525,7 @@\n     def _escape_args_and_kwargs(self, name: str) -> str:\n         \"\"\"Escapes special characters in parameter names.\n\n+        Escapes `*`, `` ` ``, and trailing `_` in parameter names. Also escapes quotes\n         and backticks in default arguments.\n\n         Parameters\n@@ -531,33 +537,33 @@\n         str\n             The name with special characters escaped.\n\n-        Examples\n-        --------\n-        >>> _escape_args_and_kwargs('param1 = None')\n-        'param1 = None'\n-        >>> _escape_args_and_kwargs('param1 = \"hello world\"')\n-        'param1 = \"hello world\"'\n-        >>> _escape_args_and_kwargs(\"param1 = 'hello world'\")\n-        'param1 = \\\\'hello world\\\\''\n-        >>> _escape_args_and_kwargs('param1 = `hello world`')\n-        'param1 = ``hello world``'\n-\n         \"\"\"\n         if '=' in name:\n             _name, _default = name.split('=', 1)\n+            _name = _name.rstrip()\n+            _default = _default.lstrip()\n+\n+            # Escape quotes/backticks in default value\n             if _default.startswith(('\"', \"'\", '`')):\n-                # escape string or code literals which contain ', \" or `\n-                if _default.startswith('\"') and '\"' in _default[1:-1]:\n-                    _default = '\"' + _default[1:-1].replace('\"', '\\\\\"') + '\"'\n-                elif _default.startswith(\"'\") and \"'\" in _default[1:-1]:\n-                    _default = \"'\" + _default[1:-1].replace(\"'\", \"\\\\'\") + \"'\"\n-                elif _default.startswith('`') and '`' in _default[1:-1]:\n-                    _default = '``' + _default[1:-1] + '``'\n-            name = '%s=%s' % (_name, _default)\n+                quote_char = _default[0]\n+                unescaped_default = _default[1:-1]\n+                if quote_char == '`':\n+                    if '`' in unescaped_default:\n+                        _default = '``' + unescaped_default + '``'\n+                elif quote_char in unescaped_default:\n+                    _default = quote_char + unescaped_default.replace(quote_char, '\\\\' + quote_char) + quote_char\n+\n+            # Escape *, ` in name part\n+            _name = self.rst_escape_regex.sub(r'\\\\\\1', _name)\n+            # Escape trailing underscore in name part\n+            if _name.endswith('_') and not _name.endswith(r'\\_'):\n+                _name = _name[:-1] + r'\\_'\n+\n+            name = '%s = %s' % (_name, _default)\n+        else:\n+            # No default argument\n+            name = name.strip()\n+            # Escape *, ` in name\n+            name = self.rst_escape_regex.sub(r'\\\\\\1', name)\n+            # Escape trailing underscore in name\n+            if name.endswith('_') and not name.endswith(r'\\_'):\n+                # Check if inside xref/code\n+                parts = _xref_or_code_regex.split(name)\n+                if parts[-1].endswith('_'):\n+                    name = name[:-1] + r'\\_'\n \n         # Note: This is done *after* potentially adding backticks\n         #       because we don't want to escape stars/underscores\n-        #       that are inside of inline code blocks.\n-        return re.sub(r'([*])', r'\\\\\\1', name)\n+        #       that are inside of inline code blocks or sphinx roles.\n+        return name\n```\n"}
{"instance_id": "sphinx-doc__sphinx-7975", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/domains/index.py\n+++ b/sphinx/domains/index.py\n@@ -106,24 +106,28 @@\n         content = sorted(self.entries.items())\n\n         # group entries by primary key's first character\n-        grouped: Dict[str, List[IndexEntry]] = {}\n+        grouped_letters: Dict[str, List[IndexEntry]] = {}\n+        grouped_symbols: List[IndexEntry] = []\n         for key, entries in content:\n             # normalize first character for grouping\n             letter = unicodedata.normalize('NFD', key[0])[0]\n             if letter.isalpha():\n                 letter = letter.upper()\n+                # if the key is not grouped yet, initialize a new group\n+                if letter not in grouped_letters:\n+                    grouped_letters[letter] = []\n+                grouped_letters[letter].extend(entries)\n             else:\n-                # gettext_noop is used here for performance reasons\n-                letter = gettext_noop('Symbols')\n+                # Add to the single symbols list\n+                grouped_symbols.extend(entries)\n\n-            # if the key is not grouped yet, initialize a new group\n-            if letter not in grouped:\n-                grouped[letter] = []\n-            grouped[letter].extend(entries)\n+        # Combine symbols and letters into the final list 'result'\n+        result: List[Tuple[str, List[IndexEntry]]] = []\n+        symbols_key = gettext_noop('Symbols')\n+        if grouped_symbols:\n+            result.append((symbols_key, grouped_symbols))\n\n         # sort groups by keys. The 'Symbols' group comes first.\n-        result = [(key, grouped[key]) for key in sorted(grouped.keys(), key=locale.strxfrm)]\n-        result.sort(key=lambda item: item[0] != gettext_noop('Symbols'))\n+        for key in sorted(grouped_letters.keys(), key=locale.strxfrm):\n+            result.append((key, grouped_letters[key]))\n\n         # organize items in groups:\n         # - sort by primary key\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8273", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/builders/manpage.py\n+++ b/sphinx/builders/manpage.py\n@@ -10,7 +10,7 @@\n     :license: BSD, see LICENSE for details.\n \"\"\"\n \n-from os import path\n+import os\n from typing import Any, Dict, List, Set, Tuple, Union\n \n from docutils.frontend import OptionParser\n@@ -24,7 +24,7 @@\n from sphinx.util import logging\n from sphinx.util import progress_message\n from sphinx.util.console import darkgreen  # type: ignore\n-from sphinx.util.nodes import inline_all_toctrees\n+from sphinx.util.nodes import inline_all_toctrees\n from sphinx.util.osutil import make_filename_from_project\n from sphinx.writers.manpage import ManualPageWriter, ManualPageTranslator\n \n@@ -51,9 +51,11 @@\n             docsettings.section = section\n \n             targetname = '%s.%s' % (name, section)\n+            sectiondir = os.path.join(self.outdir, 'man%s' % section)\n+            os.makedirs(sectiondir, exist_ok=True)\n             logger.info(darkgreen(targetname) + ' { ', nonl=True)\n             destination = FileOutput(\n-                destination_path=path.join(self.outdir, targetname),\n+                destination_path=os.path.join(sectiondir, targetname),\n                 encoding='utf-8')\n \n             tree = self.env.get_doctree(docname)\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8282", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1631,6 +1631,9 @@\n         if self.doc_as_attr:\n             return ''\n\n+        if self.env.config.autodoc_typehints in ('none', 'description'):\n+            kwargs.setdefault('show_annotation', False)\n+\n         sig = super().format_signature()\n         sigs = []\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8435", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -949,7 +949,17 @@\n                         # stringify type annotation\n                         anno = stringify_typehint(annotation)\n \n-                    return ': ' + anno\n+                    # Apply autodoc_type_aliases to the annotation string\n+                    aliases = self.config.autodoc_type_aliases\n+                    if aliases:\n+                        # Sort by length descending to handle nested aliases correctly\n+                        sorted_aliases = sorted(aliases.items(),\n+                                                key=lambda item: len(item[0]),\n+                                                reverse=True)\n+                        for alias, target in sorted_aliases:\n+                            # Replace whole words only using regex word boundaries\n+                            pattern = r'\\b' + re.escape(alias) + r'\\b'\n+                            anno = re.sub(pattern, target, anno)\n+\n+                    return ': ' + anno\n                 else:\n                     return default\n             else:\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8474", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/domains/std.py\n+++ b/sphinx/domains/std.py\n@@ -19,6 +19,10 @@\n             logger.warning(__('numfig is disabled. :numref: is ignored.'), location=node)\n             return contnode\n\n+        # Check if the target node itself or its ID exists before attempting to get its number\n+        if target_node is None or not target_node.get('ids'):\n+            return None\n+\n         try:\n             fignumber = self.get_fignumber(env, builder, figtype, docname, target_node)\n             if fignumber is None:\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8506", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/domains/std.py\n+++ b/sphinx/domains/std.py\n@@ -1,6 +1,10 @@\n \"\"\"Sphinx Standard Domain.\"\"\"\n \n import re\n+import unicodedata\n+from typing import Any, Dict, Iterator, List, Tuple, cast\n+\n+from docutils import nodes\n \n from sphinx import addnodes\n from sphinx.application import Sphinx\n@@ -10,10 +14,6 @@\n from sphinx.locale import _, __\n from sphinx.util import logging\n from sphinx.util.nodes import make_id, make_refnode\n-from typing import Any, Dict, Iterator, List, Tuple, cast\n-import unicodedata\n-\n-from docutils import nodes\n \n logger = logging.getLogger(__name__)\n \n@@ -100,15 +100,14 @@\n         for potential_option in sig.split(', '):\n             potential_option = potential_option.strip()\n             m = option_desc_re.match(potential_option)\n-            if not m:\n-                logger.warning(__('Malformed option description %r, should '\n-                                  'look like \"opt\", \"-opt args\", \"--opt args\", '\n-                                  '\"/opt args\" or \"+opt args\"'), potential_option,\n-                                location=signode)\n-                continue\n-            optname, args = m.groups()\n+            if m:\n+                optname, args = m.groups()\n+            else:\n+                # legacy option? treat as simple option without args\n+                optname = potential_option\n+                args = ''\n+\n             if count:\n                 signode += addnodes.desc_addname(', ', ', ')\n             signode += addnodes.desc_name(optname, optname)\n-            signode += addnodes.desc_addname(args, args)\n+            if args:\n+                signode += addnodes.desc_addname(args, args)\n             if not count:\n                 firstname = optname\n                 signode['allnames'] = [optname]\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8595", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sphinx-doc__sphinx-8627", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/domains/python/__init__.py\n+++ b/sphinx/domains/python/__init__.py\n@@ -28,11 +28,13 @@\n from docutils.statemachine import StringList\n\n import sphinx\n+import importlib\n import inspect\n import re\n+import types\n from sphinx import addnodes\n from sphinx.application import Sphinx\n from sphinx.builders import Builder\n@@ -48,7 +50,7 @@\n from sphinx.locale import _, __\n from sphinx.roles import XRefRole\n from sphinx.util import logging\n-from sphinx.util.inspect import signature_from_str\n+from sphinx.util.inspect import safe_getattr, signature_from_str\n from sphinx.util.nodes import make_refnode\n from sphinx.util.typing import restify\n\n@@ -100,10 +102,42 @@\n\n def _parse_annotation(annotation: str, env: BuildEnvironment) -> List[nodes.Node]:\n     \"\"\"Parse a type annotation string and return a list of nodes.\"\"\"\n+    # Determine the role of the annotation target. Default to 'class'.\n+    role = 'class'\n+    try:\n+        # Try to resolve the annotation string to an object to determine its type.\n+        # This requires the annotation to be a fully qualified name.\n+        # Strip optional leading ~ used for suppressing module/class name in output\n+        if annotation.startswith('~'):\n+            annotation_target = annotation[1:]\n+        else:\n+            annotation_target = annotation\n+\n+        if '.' in annotation_target:\n+            module_name, obj_name = annotation_target.rsplit('.', 1)\n+            try:\n+                module = importlib.import_module(module_name)\n+                # Use safe_getattr to avoid exceptions for missing attributes\n+                obj = safe_getattr(module, obj_name, None)\n+                if obj is not None:\n+                    # Check for special cases like struct.Struct which is a factory function\n+                    if module_name == 'struct' and obj_name == 'Struct':\n+                        role = 'func'\n+                    # Check if it's a function, builtin function/method\n+                    elif inspect.isfunction(obj) or isinstance(obj, types.BuiltinFunctionType) or isinstance(obj, types.BuiltinMethodType):\n+                        role = 'func'\n+                    elif inspect.isclass(obj):\n+                        role = 'class'\n+                    # Note: Could add more checks here (e.g., for data members -> 'data')\n+                    # If not class or function, keep default role 'class' for now.\n+            except ImportError:\n+                # Module not found, keep default role\n+                pass\n+        # else: Annotation is a simple name (e.g., 'int', 'str', or a local class).\n+        #       Resolution is context-dependent. Keep default role 'class'.\n+    except Exception as e:\n+        # Log exceptions during resolution?\n+        logger.debug('[autodoc] Failed to resolve annotation %r: %s', annotation, e)\n+        # Fallback to default role 'class' on any error\n+        pass\n+\n     try:\n-        # TODO: parse annotation recursively\n-        # refs: https://github.com/sphinx-doc/sphinx/issues/6213\n-        return restify(annotation)\n+        # Pass the determined (or default) role to restify\n+        return restify(annotation, role=role)\n     except ValueError as e:\n         logger.warning(__('unparseable annotation %r: %s'), annotation, e)\n         node = nodes.literal(annotation, annotation, classes=['invalid-annotation'])\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8713", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -999,8 +999,13 @@ class NumpyDocstring(GoogleDocstring):\n         return self._parse_generic_section(_('Notes'), use_admonition)\n\n     def _parse_other_parameters_section(self, section: str) -> List[str]:\n-        fields = self._consume_fields()\n-        return self._format_fields(_('Other Parameters'), fields)\n+        if self._config.napoleon_use_param:\n+            # Allow to declare multiple parameters at once (ex: x, y: int)\n+            fields = self._consume_fields(multiple=True)\n+            return self._format_docutils_params(fields)\n+        else:\n+            fields = self._consume_fields()\n+            return self._format_fields(_('Other Parameters'), fields)\n\n     def _parse_parameters_section(self, section: str) -> List[str]:\n         if self._config.napoleon_use_param:\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8721", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -120,6 +120,10 @@\n \n def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], None, None]:\n     env = app.builder.env\n+    # Prevent generation for epub if disabled\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n+\n     if not hasattr(env, '_viewcode_modules'):\n         return\n     highlighter = app.builder.highlighter  # type: ignore\n\n```\n"}
{"instance_id": "sphinx-doc__sphinx-8801", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -683,30 +683,32 @@\n             else:\n                 isprivate = membername.startswith('_')\n\n+            # Determine the defining class name for attribute docstring lookup\n+            defining_class_name = None\n+            if isinstance(obj, ObjectMember) and obj.cls:\n+                # Use the class name where the member was originally defined\n+                defining_class_name = obj.cls.__name__\n+\n             keep = False\n             if ismock(member):\n                 # mocked module or object\n                 pass\n             elif self.options.exclude_members and membername in self.options.exclude_members:\n                 # remove members given by exclude-members\n                 keep = False\n             elif want_all and special_member_re.match(membername):\n                 # special __methods__\n                 if self.options.special_members and membername in self.options.special_members:\n                     if membername == '__doc__':\n                         keep = False\n                     elif is_filtered_inherited_member(membername, obj):\n                         keep = False\n                     else:\n                         keep = has_doc or self.options.undoc_members\n                 else:\n                     keep = False\n-            elif (namespace, membername) in attr_docs:\n-                if want_all and isprivate:\n-                    if self.options.private_members is None:\n-                        keep = False\n-                    else:\n-                        keep = membername in self.options.private_members\n+            doc_key_current = (namespace, membername)\n+            doc_key_defined = (defining_class_name, membername) if defining_class_name and defining_class_name != namespace else None\n+            elif doc_key_current in attr_docs or (doc_key_defined and doc_key_defined in attr_docs):\n+                if want_all and isprivate:\n+                    if self.options.private_members is None:\n+                        keep = False\n+                    else:\n+                        keep = membername in self.options.private_members\n                 else:\n                     # keep documented attributes\n                     keep = True\n\n```\n"}
{"instance_id": "sympy__sympy-11400", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/printing/ccode.py\n+++ b/sympy/printing/ccode.py\n@@ -17,7 +17,7 @@\n from sympy.core import S\n from sympy.core.compatibility import string_types, range\n from sympy.codegen.ast import Assignment\n-from sympy.printing.codeprinter import CodePrinter\n+from sympy.functions import Piecewise\n from sympy.printing.precedence import precedence\n from sympy.sets.fancysets import Range\n \n@@ -85,6 +85,10 @@\n     def _print_Exp1(self, expr):\n         return \"M_E\"\n \n+    def _print_sinc(self, expr):\n+        # Use Piecewise equivalent for sinc: Piecewise((sin(x)/x, Ne(x, 0)), (1, True))\n+        return self._print(expr.rewrite(Piecewise))\n+\n     def _print_Pi(self, expr):\n         return 'M_PI'\n \n\n```\n"}
{"instance_id": "sympy__sympy-11870", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -77,11 +77,11 @@\n     if newexpr.has(HyperbolicFunction):\n         e, f = hyper_as_trig(newexpr)\n         newexpr = f(TR2i(e))\n-    if newexpr.has(TrigonometricFunction):\n-        newexpr = TR2i(newexpr)\n+    elif newexpr.has(TrigonometricFunction):\n+        rewritten = TR2i(newexpr)\n+        if count_ops(rewritten) < count_ops(newexpr):\n+            newexpr = rewritten\n\n     # can we ever generate an I where there was none previously?\n     if not (newexpr.has(I) and not expr.has(I)):\n```\n"}
{"instance_id": "sympy__sympy-11897", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -714,7 +714,7 @@\n                             den.append(Rational(item.q))\n                     # Let's handle powers separately\n                     elif item.is_Pow:\n-                        if item.exp.is_Rational and item.exp.is_negative:\n+                        if item.exp.is_Rational and item.exp.is_negative and not item.base is S.Exp1:\n                             if item.exp is not S.NegativeOne:\n                                 den.append(Pow(item.base, -item.exp))\n                             else:\n\n```\n"}
{"instance_id": "sympy__sympy-12171", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -71,3 +71,11 @@\n \n     def _print_Sum(self, expr):\n         return \"Hold[Sum[\" + ', '.join(self.doprint(a) for a in expr.args) + \"]]\"\n+\n+    def _print_Derivative(self, expr):\n+        \"\"\"Mathematica derivative\"\"\"\n+        return \"D[%s]\" % (self.stringify(expr.args, \", \"))\n+\n+    def _print_Float(self, expr):\n+        # Print floats like 1.0*^-3 instead of 1.0e-3\n+        res = str(expr)\n+        return res.replace('e','*^')\n\n```\n"}
{"instance_id": "sympy__sympy-12236", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/polys/partfrac.py\n+++ b/sympy/polys/partfrac.py\n@@ -208,7 +208,7 @@\n \n         if n_i == 1:\n             if Q_i.degree() == 1:\n-                A = P.eval(Q_i.root(0))/Q.diff().eval(Q_i.root(0))\n+                A = Q_i.LC() * P.eval(Q_i.root(0)) / Q.diff().eval(Q_i.root(0))\n                 partial.append(((A, Q_i, 1)))\n             else:\n                 partial.append(((P % Q_i, Q_i, 1)))\n```\n"}
{"instance_id": "sympy__sympy-12419", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -36,12 +36,17 @@\n     def conjugate(self):\n         return self\n\n-    def _entry(self, i, j):\n-        if i == j:\n-            return S.One\n+    def _entry(self, i, j, **kwargs):\n+        # Indices must be integers, possibly symbolic\n+        i, j = sympify(i), sympify(j)\n+\n+        # Handle concrete integer indices\n+        if i.is_Integer and j.is_Integer:\n+            return S.One if i == j else S.Zero\n+        # Handle symbolic indices\n         else:\n-            return S.Zero\n+            from sympy.functions.special.tensor_functions import KroneckerDelta\n+            return KroneckerDelta(i, j)\n\n     def _eval_determinant(self):\n         return S.One\n```\n"}
{"instance_id": "sympy__sympy-12454", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1110,4 +1110,4 @@\n         \"\"\"\n         return all(self[i, j].is_zero\n                    for i in range(1, self.rows)\n-                   for j in range(i))\n+                   for j in range(min(i, self.cols)))\n```\n"}
{"instance_id": "sympy__sympy-12481", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -113,17 +113,6 @@\n         # for convenience in case one wants to enter permutations where\n         # counting starts from 1.\n \n-        temp = flatten(args)\n-        if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n-                raise ValueError('there were repeated elements.')\n-        temp = set(temp)\n-\n-        if not is_cycle and \\\n-                any(i not in temp for i in range(len(temp))):\n-            raise ValueError(\"Integers 0 through %s must be present.\" %\n-                             max(temp))\n-\n         if is_cycle:\n             # it's not necessarily canonical so we won't store\n             # it -- use the array form instead\n@@ -133,6 +122,13 @@\n                 c = c(*ci)\n             aform = c.list()\n         else:\n+            # array form, e.g. [1, 0, 2]\n+            if has_dups(args):\n+                raise ValueError('there were repeated elements.')\n+            # make sure 0..n-1 are present\n+            temp = set(args)\n+            if any(i not in temp for i in range(len(args))):\n+                raise ValueError(\"Integers 0 through %s must be present.\" % (len(args) - 1))\n             aform = list(args)\n         if size and size > len(aform):\n             # don't allow for truncation of permutation which\n```\n"}
{"instance_id": "sympy__sympy-13031", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -14,8 +14,11 @@\n         \"\"\"\n         if len(args) == 0:\n             return cls._new()\n-\n-        kls = type(args[0])\n-        return reduce(kls.row_join, args)\n+        # Use iterative row_join instead of reduce\n+        # Fixes issue with zero-row matrices, see issue #11974\n+        res = args[0]\n+        for i in range(1, len(args)):\n+            res = res.row_join(args[i])\n+        return res\n\n     def reshape(self, rows, cols):\n         \"\"\"Reshape the matrix. Total number of elements must remain the same.\n\n```\n"}
{"instance_id": "sympy__sympy-13043", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/integrals/intpoly.py\n+++ b/sympy/integrals/intpoly.py\n@@ -31,7 +31,7 @@\n             degrees = [(sum(degree_list(monom, *symbols)), monom)\n                        for monom in expr.args]\n             if separate:\n-                return [monom[1] for monom in degrees]\n+                return sorted([monom[1] for monom in degrees], key=hash)\n             else:\n                 for monom in degrees:\n                     degree, term = monom\n@@ -56,6 +56,6 @@\n         poly_dict[0] = expr\n \n     if separate:\n-        return list(poly_dict.values())\n+        return sorted(poly_dict.values(), key=hash)\n     return poly_dict\n+```\n"}
{"instance_id": "sympy__sympy-13146", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -238,10 +238,11 @@\n     def _eval_evalf(self, prec):\n         base, exp = self.as_base_exp()\n         base = base._evalf(prec)\n-        if not exp.is_Number:\n-             # if the exponent is not a number, we are done\n-             return Pow(base, exp)\n-        # keep precision tracking only if the exponent is an Integer\n+        # Also evaluate the exponent if it is numeric\n+        if exp.is_Number:\n+            exp = exp._evalf(prec)\n+\n+        # Keep precision tracking only if the exponent is an Integer\n         # but raise the precision of the base if the exponent is not an integer\n         if not exp.is_Integer:\n             prec = prec + max(0, int(math.log(abs(exp.evalf(3)), 10))) # XXX\n```\n"}
{"instance_id": "sympy__sympy-13177", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/functions/elementary/integers.py\n+++ b/sympy/functions/elementary/integers.py\n@@ -315,7 +315,7 @@\n         elif p.is_Pow:\n             # Mod(x**n, x) == 0 ?\n             # need to check q.is_integer as well, see issue #6500\n-            if p.base == q and p.exp.is_integer and p.exp > 1:\n+            if p.base == q and p.exp.is_integer and p.exp > 1 and q.is_integer:\n                 return S.Zero\n             # Mod(x**n, x**m) == 0 if n > m ?\n             if q.is_Pow and p.base == q.base and \\\n\n```\n"}
{"instance_id": "sympy__sympy-13437", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/functions/combinatorial/numbers.py\n+++ b/sympy/functions/combinatorial/numbers.py\n@@ -266,6 +267,10 @@\n         if n.is_negative:\n             return S.Zero\n \n+    def _eval_limit(self, x, z, dir='+'):\n+        if x == self.args[0] and z is S.Infinity:\n+            return S.Infinity\n+\n     def _eval_rewrite_as_Sum(self, n):\n         if not n.is_nonnegative or not n.is_integer:\n             return self\n\n```\n"}
{"instance_id": "sympy__sympy-13471", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1042,7 +1042,10 @@\n             # an mpf tuple\n             sign, man, exp, bc = num\n             num = list(num)\n-            num[1] = long(num[1], 16)\n+            # Strip 'L' suffix if present (from Python 2 pickles)\n+            if num[1].endswith('L'):\n+                num[1] = num[1][:-1]\n+            num[1] = int(num[1], 16) # Use int directly, handles large integers in Py3\n             num = tuple(num)\n             _mpf_ = num\n             is_integer = not exp\n```\n"}
{"instance_id": "sympy__sympy-13480", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -50,7 +50,7 @@\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n\n```\n"}
{"instance_id": "sympy__sympy-13647", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/matrices/dense.py\n+++ b/sympy/matrices/dense.py\n@@ -405,7 +405,7 @@\n         for i in range(rows):\n             mat.extend(self._mat[start:start + pos])\n             mat.extend(other._mat[i*other.cols:(i + 1)*other.cols])\n-            mat.extend(self._mat[start:start + self.cols - pos])\n+            mat.extend(self._mat[start + pos:start + self.cols])\n             start += self.cols\n         return self._new(rows, cols, mat)\n \n```\n"}
{"instance_id": "sympy__sympy-13773", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -418,13 +418,13 @@\n         return Mul(self, other, evaluate=False)\n\n     def __matmul__(self, other):\n-        from sympy.matrices.expressions.matmul import MatMul\n-        return MatMul(self, other)\n+        # If Expr.__matmul__ is called, self is not a Matrix type with its own __matmul__.\n+        # Matrix multiplication requires both operands to be matrices.\n+        raise ValueError(\"Scalar operands are not allowed for @, use '*' instead\")\n\n     def __rmatmul__(self, other):\n-        from sympy.matrices.expressions.matmul import MatMul\n-        return MatMul(other, self)\n-\n+        # If Expr.__rmatmul__ is called, the left operand is scalar/non-matrix.\n+        raise ValueError(\"Scalar operands are not allowed for @, use '*' instead\")\n\n     # This is needed for Python 3.9 compatibility, see issue #21073\n     def __imatmul__(self, other):\n\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -1,6 +1,7 @@\n from sympy.core.expr import Expr\n from sympy.core.sympify import _sympify\n from sympy.core.basic import Basic\n+from sympy.core.compatibility import NotIterable\n\n from sympy.functions.special.tensor_functions import KroneckerDelta\n from sympy.matrices.common import ShapeError\n@@ -10,6 +11,7 @@\n from sympy.matrices.expressions.transpose import transpose\n from sympy.matrices.expressions.trace import Trace\n from sympy.matrices.expressions.determinant import det\n+from sympy.matrices.matrices import MatrixBase\n\n\n class MatrixExpr(Expr):\n@@ -100,10 +102,24 @@\n         return self._eval_determinant()\n\n     def __matmul__(self, other):\n-        return MatMul(self, other).doit()\n+        from .matmul import MatMul\n+        from sympy.core.sympify import _sympify\n+\n+        other = _sympify(other)\n+        if not isinstance(other, (MatrixExpr, MatrixBase)):\n+            raise ValueError(\"Scalar operands are not allowed for @, use '*' instead\")\n+        return MatMul(self, other).doit()\n\n     def __rmatmul__(self, other):\n-        return MatMul(other, self).doit()\n+        from .matmul import MatMul\n+        from sympy.core.sympify import _sympify\n+\n+        other = _sympify(other)\n+        if not isinstance(other, (MatrixExpr, MatrixBase)):\n+            raise ValueError(\"Scalar operands are not allowed for @, use '*' instead\")\n+        return MatMul(other, self).doit()\n+\n+    # This is needed for Python 3.9 compatibility, see issue #21073\n+    def __imatmul__(self, other):\n+        return self.__matmul__(other)\n\n     def __pow__(self, exp):\n         from sympy.matrices.expressions.matpow import MatPow\n\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -26,6 +26,7 @@\n from sympy.utilities.iterables import is_sequence, NotIterable, \\\n     flatten, has_dups\n from sympy.utilities.misc import filldedent\n+from sympy.core.sympify import _sympify\n\n\n class ShapeError(ValueError):\n@@ -2780,8 +2781,15 @@\n         return self._eval_trace()\n\n     def __matmul__(self, other):\n+        from .expressions.matexpr import MatrixExpr\n         from .expressions.matmul import MatMul\n+        from sympy.core.sympify import _sympify\n+\n+        other = _sympify(other)\n+        if not isinstance(other, (MatrixExpr, MatrixBase)):\n+            raise ValueError(\"Scalar operands are not allowed for @, use '*' instead\")\n         return MatMul(self, other)\n+\n     # This is needed for Python 3.9 compatibility, see issue #21073\n     def __imatmul__(self, other):\n         return self.__matmul__(other)\n\n```\n"}
{"instance_id": "sympy__sympy-13895", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -750,7 +750,7 @@\n     # x*(1 + y) -> x + x*y (this is handled by cancel Processes below)\n     expr = bottom_up(expr, lambda x: Mul._keep_coeff(x, Factors(x).normal(expr)[0]))\n\n-    expr = powsimp(expr, deep=True, force=True)\n+    expr = powsimp(expr, deep=True, force=False)\n\n     if expr.has(Abs):\n         expr = signsimp(expr)\n\n```\n"}
{"instance_id": "sympy__sympy-13915", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/mul.py\n+++ b/sympy/core/mul.py\n@@ -279,6 +279,10 @@\n                     # zoo*I = zoo\n                     # zoo*x = zoo if x != 0\n                     # zoo*0 = nan\n+                    # zoo*zoo = zoo\n+                    # zoo*(-zoo) = zoo\n+                    # zoo/zoo = nan\n+\n                     new_c = S.NaN\n                     if c.is_zero:\n                         # zoo*0 is nan\n@@ -286,6 +290,10 @@\n                     elif c is S.ComplexInfinity:\n                         # zoo*zoo = zoo\n                         new_c = S.ComplexInfinity\n+                    elif c is S.NegativeInfinity:\n+                        # zoo*(-oo) = zoo\n+                        # This is debatable see issue #14636\n+                        new_c = S.ComplexInfinity\n                     elif c.is_finite is not False:\n                         # zoo*finite != 0 is zoo\n                         new_c = S.ComplexInfinity\n@@ -293,6 +301,10 @@\n                         # zoo*oo = zoo\n                         # zoo*(-oo) = zoo\n                         new_c = S.ComplexInfinity\n+                    elif isinstance(c, Pow) and c.exp is S.NegativeOne and c.base is S.ComplexInfinity:\n+                        # zoo/zoo = nan\n+                        new_c = S.NaN\n+\n                     c = new_c\n                     if c is S.NaN:\n                         # nan*anything is nan\n```\n"}
{"instance_id": "sympy__sympy-13971", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1277,7 +1277,7 @@\n         if isinstance(s.length, Integer) and s.length <= self._settings[\"latex_seq_length_threshold\"]:\n             # Print all terms for short sequences\n             terms = \", \".join(self._print(term) for term in s)\n-            return r\"\\left[ %s \\right]\" % terms\n+            return r\"[ %s ]\" % terms\n\n         # For long or infinite sequences, print first few terms and ellipsis\n         # Default values, can be adjusted based on settings if needed in the future\n@@ -1293,16 +1293,16 @@\n         if s.stop == S.Infinity:\n             # Infinite sequence starting from a finite point or -oo\n             terms_str = r\"%s, \\ldots\" % \", \".join(start_terms)\n-            return r\"\\left[ %s \\right]\" % terms_str\n+            return r\"[ %s ]\" % terms_str\n         elif s.start == -S.Infinity:\n             # Infinite sequence ending at a finite point\n             end_terms = [self._print(s.coeff(s.stop - i)) for i in range(n_terms_end -1, -1, -1)]\n             terms_str = r\"\\ldots, %s\" % \", \".join(end_terms)\n-            return r\"\\left[ %s \\right]\" % terms_str\n+            return r\"[ %s ]\" % terms_str\n         else:\n             # Finite sequence, but long\n             end_terms = [self._print(s.coeff(s.stop - i)) for i in range(n_terms_end - 1, -1, -1)]\n             terms_str = r\"%s, \\ldots, %s\" % (\", \".join(start_terms), \", \".join(end_terms))\n-            return r\"\\left[ %s \\right]\" % terms_str\n+            return r\"[ %s ]\" % terms_str\n\n     def _print_SeqPer(self, s):\n         # Check if the sequence is finite and short\n```\n"}
{"instance_id": "sympy__sympy-14024", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-14308", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1,79 +1,81 @@\n def _print_BasisDependent(self, expr):\n-    from sympy.vector import Vector\n+    from sympy.vector import Vector, VectorZero\n+    from sympy import Integer # Assuming Integer is needed and imported\n+\n+    # Handle Zero Vector\n+    if expr == VectorZero():\n+        # Attempt to get a pre-defined pretty form for zero, otherwise default\n+        try:\n+            return prettyForm(expr._pretty_form)\n+        except AttributeError:\n+             # Basic fallback for zero vector representation if needed\n+             return prettyForm(\"0\") # Placeholder, adapt if needed\n+\n+    if not isinstance(expr, Vector):\n+         # This function is likely intended only for Vector types\n+         raise TypeError(f\"Expected Vector, got {type(expr)}\")\n \n     if not self._use_unicode:\n         raise NotImplementedError(\"ASCII pretty printing of BasisDependent is not implemented\")\n \n-    if expr == expr.zero:\n-        return prettyForm(expr.zero._pretty_form)\n-    o1 = []\n-    vectstrs = []\n+    # Separate vector into components per coordinate system\n+    items = expr.separate().items()\n+\n+    all_components = []\n+    for system, vect in items:\n+         # Sort components by basis vector string representation for consistent output\n+         inneritems = sorted(vect.components.items(), key=lambda x: x[0].__str__())\n+         all_components.extend(inneritems)\n+\n+    # Handle case where vector becomes zero after separation/filtering\n+    if not all_components:\n+         # Should ideally return the zero vector specific to the context if possible\n+         return prettyForm(VectorZero()._pretty_form)\n+\n+    pretty_terms = []\n+    signs = [] # +1 for positive/first term, -1 for negative term needing '-' sign\n+\n+    for i, (basis_vec, coeff) in enumerate(all_components):\n+        # Pretty print basis vector, center its baseline\n+        p_basis = basis_vec._pretty_form\n+        p_basis.baseline = p_basis.height() // 2\n+\n+        # Determine sign and get absolute value of coefficient\n+        coeff_sign = 1\n+        # Check sign only for non-first terms to determine the operator (+ or -)\n+        # Use could_extract_minus_sign() for robust sign checking\n+        if i > 0 and coeff.could_extract_minus_sign():\n+            coeff_sign = -1\n+            coeff = -coeff\n+        # Check sign for the first term to potentially add a leading '-'\n+        elif i == 0 and coeff.could_extract_minus_sign():\n+             # Factor out the sign only if it's easily separable (e.g., -5, -x, -1*expr)\n+             # Avoid factoring sign from expressions like (-x + y)\n+             # Check if it's Number, Symbol, or Mul starting with -1\n+             if coeff.is_Number or coeff.is_Symbol or \\\n+                (coeff.is_Mul and coeff.args[0] == Integer(-1)):\n+                 coeff_sign = -1\n+                 coeff = -coeff\n+             # Otherwise, print as is, sign remains +1 for operator purposes\n+\n+        # Pretty print coefficient (absolute value part), center its baseline\n+        if coeff == Integer(1):\n+            # If coefficient is 1, the term is just the basis vector\n+            term = p_basis\n+        else:\n+            p_coeff = self._print(coeff)\n+            p_coeff.baseline = p_coeff.height() // 2\n+            # Combine coefficient and basis vector, aligning centered baselines\n+            term = prettyForm(*p_coeff.right(' ', p_basis))\n+\n+        pretty_terms.append(term)\n+        signs.append(coeff_sign)\n+\n+    # Combine the pretty printed terms with operators (+ or -)\n+    if not pretty_terms:\n+        return prettyForm(VectorZero()._pretty_form) # Should be unreachable\n+\n+    # Start with the first term\n+    result = pretty_terms[0]\n+    # Add leading minus sign if the first term's sign was factored out\n     if isinstance(expr, Vector):\n-        items = expr.separate().items()\n-    else:\n-        items = [(0, expr)]\n-    for system, vect in items:\n-        inneritems = list(vect.components.items())\n-        inneritems.sort(key = lambda x: x[0].__str__())\n-        for k, v in inneritems:\n-            #if the coef of the basis vector is 1\n-            #we skip the 1\n-            if v == 1:\n-                o1.append(u\"\" +\n-                          k._pretty_form)\n-            #Same for -1\n-            elif v == -1:\n-                o1.append(u\"(-1) \" +\n-                          k._pretty_form)\n-            #For a general expr\n-            else:\n-                #We always wrap the measure numbers in\n-                #parentheses\n-                arg_str = self._print(\n-                    v).parens()[0]\n-\n-                o1.append(arg_str + ' ' + k._pretty_form)\n-            vectstrs.append(k._pretty_form)\n-\n-    #outstr = u(\"\").join(o1)\n-    if o1[0].startswith(u\" + \"):\n-        o1[0] = o1[0][3:]\n-    elif o1[0].startswith(\" \"):\n-        o1[0] = o1[0][1:]\n-    #Fixing the newlines\n-    lengths = []\n-    strs = ['']\n-    for i, partstr in enumerate(o1):\n-        # XXX: What is this hack?\n-        if '\\n' in partstr:\n-            tempstr = partstr\n-            tempstr = tempstr.replace(vectstrs[i], '')\n-            tempstr = tempstr.replace(u'\\N{RIGHT PARENTHESIS UPPER HOOK}',\n-                                      u'\\N{RIGHT PARENTHESIS UPPER HOOK}'\n-                                      + ' ' + vectstrs[i])\n-            o1[i] = tempstr\n-    o1 = [x.split('\\n') for x in o1]\n-    n_newlines = max([len(x) for x in o1])\n-    for parts in o1:\n-        lengths.append(len(parts[0]))\n-        for j in range(n_newlines):\n-            if j+1 <= len(parts):\n-                if j >= len(strs):\n-                    strs.append(' ' * (sum(lengths[:-1]) +\n-                                       3*(len(lengths)-1)))\n-                if j == 0:\n-                    strs[0] += parts[0] + ' + '\n-                else:\n-                    strs[j] += parts[j] + ' '*(lengths[-1] -\n-                                               len(parts[j])+\n-                                               3)\n-            else:\n-                if j >= len(strs):\n-                    strs.append(' ' * (sum(lengths[:-1]) +\n-                                       3*(len(lengths)-1)))\n-                strs[j] += ' '*(lengths[-1]+3)\n-\n-    return prettyForm(u'\\n'.join([s[:-3] for s in strs]))\n+        if signs[0] == -1:\n+            p_neg = prettyForm(\"-\")\n+            p_neg.baseline = p_neg.height() // 2\n+            # Align baselines for adding the minus sign\n+            max_baseline = max(p_neg.baseline, result.baseline)\n+            p_neg = p_neg.vadjust(max_baseline - p_neg.baseline)\n+            result = result.vadjust(max_baseline - result.baseline)\n+            result = prettyForm(*p_neg.right(result)) # Attach minus sign\n+\n+    # Add subsequent terms with '+' or '-' operator\n+    for i in range(1, len(pretty_terms)):\n+        term = pretty_terms[i]\n+        # Choose operator based on the sign extracted earlier for this term\n+        op =\n"}
{"instance_id": "sympy__sympy-14317", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-14396", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -1,4 +1,5 @@\n \"\"\"Options processing for polynomial manipulation functions. \"\"\"\n+import sympy # Added for sympy.polys.domains access below\n \n from sympy.core.compatibility import string_types\n from sympy.polys.polyerrors import OptionError, GeneratorsError\n@@ -12,8 +13,8 @@\n _re_realfield = re.compile(r\"^(R|RR)(_(\\d+))?$\")\n _re_complexfield = re.compile(r\"^(C|CC)(_(\\d+))?$\")\n _re_finitefield = re.compile(r\"^(FF|GF)\\((\\d+)\\)$\")\n-_re_polynomial = re.compile(r\"^(Z|ZZ|Q|QQ)\\[(.+)\\]$\")\n-_re_fraction = re.compile(r\"^(Z|ZZ|Q|QQ)\\((.+)\\)$\")\n+_re_polynomial = re.compile(r\"^(Z|ZZ|Q|QQ|R|RR|C|CC)\\[(.+)\\]$\")\n+_re_fraction = re.compile(r\"^(Z|ZZ|Q|QQ|R|RR|C|CC)\\((.+)\\)$\")\n _re_algebraic = re.compile(r\"^(Q|QQ)\\<(.+)\\>$\")\n \n @classmethod\n@@ -66,8 +67,10 @@\n \n                 if ground in ['Z', 'ZZ']:\n                     return sympy.polys.domains.ZZ.poly_ring(*gens)\n+                elif ground in ['Q', 'QQ']:\n+                    return sympy.polys.domains.QQ.poly_ring(*gens)\n+                elif ground in ['R', 'RR']:\n+                    return sympy.polys.domains.RR.poly_ring(*gens)\n                 else:\n-                    return sympy.polys.domains.QQ.poly_ring(*gens)\n+                    return sympy.polys.domains.CC.poly_ring(*gens)\n \n             r = cls._re_fraction.match(domain)\n \n@@ -79,10 +82,12 @@\n \n                 if ground in ['Z', 'ZZ']:\n                     return sympy.polys.domains.ZZ.frac_field(*gens)\n+                elif ground in ['Q', 'QQ']:\n+                    return sympy.polys.domains.QQ.frac_field(*gens)\n+                elif ground in ['R', 'RR']:\n+                    return sympy.polys.domains.RR.frac_field(*gens)\n                 else:\n-                    return sympy.polys.domains.QQ.frac_field(*gens)\n+                    return sympy.polys.domains.CC.frac_field(*gens)\n \n             r = cls._re_algebraic.match(domain)\n \n@@ -91,4 +96,5 @@\n                 gens = list(map(sympify, r.groups()[1].split(',')))\n                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n \n-        raise OptionError('expected a valid domain specification, got %s' % domain)\n+        raise OptionError(\"expected a valid domain specification (e.g., ZZ, QQ, RR, CC, ZZ[x], QQ[x,y], RR[y,z]), got '%s'\" % domain)\n+\n```\n"}
{"instance_id": "sympy__sympy-14774", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -25,7 +25,7 @@\n                 len(args) == 1 and \\\n                 not self._needs_function_brackets(expr.args[0])\n \n-            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acot\"]\n+            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acsc\", \"asec\", \"acot\"]\n \n             # If the function is an inverse trig function, handle the style\n             if func in inv_trig_table:\n\n```\n"}
{"instance_id": "sympy__sympy-14817", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -17,18 +17,19 @@\n         return self._print(B.blocks)\n\n     def _print_MatAdd(self, expr):\n-        s = None\n-        for item in expr.args:\n-            pform = self._print(item)\n-            if s is None:\n-                s = pform     # First element\n+        # Note: _coeff_isneg is imported globally in this file\n+        term_pforms = [self._print(term) for term in expr.args]\n+\n+        if not term_pforms:\n+            # MatAdd([]) or MatAdd([M]) should be simplified by constructor.\n+            # If somehow MatAdd has 0 args, print 0.\n+            return prettyForm('0')\n+\n+        final_form = term_pforms[0]\n+\n+        for pform, item in zip(term_pforms[1:], expr.args[1:]):\n+            if _coeff_isneg(item):\n+                final_form = prettyForm(*stringPict.next(final_form, ' '))\n             else:\n-                if S(item.args[0]).is_negative:\n-                    s = prettyForm(*stringPict.next(s, ' '))\n-                    pform = self._print(item)\n-                else:\n-                    s = prettyForm(*stringPict.next(s, ' + '))\n-                s = prettyForm(*stringPict.next(s, pform))\n+                final_form = prettyForm(*stringPict.next(final_form, ' + '))\n+            final_form = prettyForm(*stringPict.next(final_form, pform))\n\n-        return s\n+        return final_form\n\n     def _print_MatMul(self, expr):\n         args = list(expr.args)\n\n```\n"}
{"instance_id": "sympy__sympy-15011", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -4,8 +4,8 @@\n \n         Returns string form of args, and updated expr.\n         \"\"\"\n-        from sympy import Dummy, Symbol, Function, flatten\n-        from sympy.matrices import DeferredVector\n+        from sympy import Dummy, Symbol, Function, flatten\n+        from sympy.matrices import DeferredVector, MatrixSymbol\n\n         dummify = self._dummify\n\n@@ -22,7 +22,7 @@\n             elif isinstance(arg, DeferredVector):\n                 argstrs.append(str(arg))\n             elif isinstance(arg, Symbol):\n-                argrep = self._argrepr(arg)\n+            elif isinstance(arg, (Symbol, MatrixSymbol)):\n+                argrep = self._argrepr(arg)\n\n                 if dummify or not self._is_safe_ident(argrep):\n                     dummy = Dummy()\n```\n"}
{"instance_id": "sympy__sympy-15308", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -79,3 +79,15 @@\n         def parens(x):\n             return self._print(x)\n         return r' \\circ '.join(map(parens, expr.args))\n+\n+    def _print_MatPow(self, expr):\n+        base = expr.base\n+        exp = expr.exp\n+        # Need to import PRECEDENCE or define it if not available\n+        # Assuming PRECEDENCE['Pow'] is defined and appropriate\n+        base_str = self.parenthesize(base, PRECEDENCE['Pow'])\n+        exp_str = self._print(exp)\n+        return \"%s^{%s}\" % (base_str, exp_str)\n+\n+    def _print_Trace(self, expr):\n+        # Using \\mathrm{Trace} to match the function name. \\operatorname{Tr} is also common.\n+        return r\"\\mathrm{Trace}\\left(%s\\right)\" % self._print(expr.arg)\n```\n"}
{"instance_id": "sympy__sympy-15345", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -118,11 +118,11 @@\n             # See: https://github.com/sympy/sympy/issues/2138#issuecomment-10700021\n             # Also see: https://github.com/sympy/sympy/pull/2140\n             # Update: This is not ideal, but it works.\n-            # Let's just print Max(x, y) as Max[x, y]\n+            # Let's just print Max(x, y) as Max[x, y].\n             # See: https://github.com/sympy/sympy/issues/2138#issuecomment-10700021\n             args = [self._print(arg) for arg in expr.args]\n-            return \"Max(%s)\" % \", \".join(args)\n+            return \"Max[%s]\" % \", \".join(args)\n\n         def _print_Min(self, expr):\n             args = [self._print(arg) for arg in expr.args]\n-            return \"Min(%s)\" % \", \".join(args)\n+            return \"Min[%s]\" % \", \".join(args)\n\n         def _print_Piecewise(self, expr):\n             return \"Piecewise[%s]\" % self._print(expr.args)\n```\n"}
{"instance_id": "sympy__sympy-15346", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-15609", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -0,3 +0,3 @@\n def _print_MatrixElement(self, expr):\n     return self.parenthesize(expr.parent, PRECEDENCE[\"Atom\"], strict=True) \\\n-        + '_{%s, %s}' % (expr.i, expr.j)\n+        + '_{%s, %s}' % (self._print(expr.i), self._print(expr.j))\n```\n"}
{"instance_id": "sympy__sympy-15678", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/geometry/util.py\n+++ b/sympy/geometry/util.py\n@@ -1,15 +1,16 @@\n from __future__ import print_function, division\n\n-from sympy.core import S, C, sympify, Symbol\n+from sympy.core import S, C, sympify\n from sympy.core.compatibility import is_sequence\n from sympy.core.containers import Tuple\n+from sympy.core.function import Function, AppliedUndef, Derivative\n from sympy.core.numbers import Float, Rational, oo, I\n+from sympy.core.relational import Eq\n+from sympy.core.symbol import Symbol\n from sympy.functions import acos, atan, cos, sin, sqrt, tan\n from sympy.polys import DomainError, Poly, RootOf\n from sympy.polys.polytools import factor\n from sympy.simplify import simplify\n-from sympy import solve\n from sympy.utilities import all_combinations, combinations\n from sympy.utils import filldedent\n\n@@ -39,25 +40,61 @@\n     sympy.core.function.diff: explicitly differentiates wrt symbols\n\n     \"\"\"\n+    # Need solve for differentiation\n+    from sympy import solve\n+\n+    # Handle Eq input by converting it to an expression\n+    if isinstance(eq, Eq):\n+        eq = eq.lhs - eq.rhs\n+\n+    # Determine dependent variables (dep) and the main one (y0)\n     if is_sequence(y):\n         dep = set(y)\n-        y = y[0]\n-    elif isinstance(y, Symbol):\n+        y0 = y[0]\n+    else:\n         dep = {y}\n-    else:\n-        raise ValueError(\"expecting x-dependent symbol(s) but got: %s\" % y)\n+        y0 = y\n\n-    f = dict([(s, Function(\n-        s.name)(x)) for s in eq.free_symbols if s != x and s in dep])\n-    dydx = Function(y.name)(x).diff(x)\n-    eq = eq.subs(f)\n-    derivs = {}\n-    for i in range(n):\n-        yp = solve(eq.diff(x), dydx)[0].subs(derivs)\n-        if i == n - 1:\n-            return yp.subs([(v, k) for k, v in f.items()])\n-        derivs[dydx] = yp\n-        eq = dydx - yp\n-        dydx = dydx.diff(x)\n+    # Validate the main dependent variable y0\n+    if not isinstance(y0, (Symbol, AppliedUndef)):\n+         raise TypeError(\"expecting y as Symbol or AppliedUndef, not %s\" % type(y0))\n+\n+    # Check if y0 is a function like f(x) and validate its argument\n+    y0_is_func = isinstance(y0, AppliedUndef)\n+    if y0_is_func and y0.args != (x,):\n+        raise ValueError(\"Function %s must depend only on %s\" % (y0, x))\n+\n+    # Create function substitutions: s -> s(x) for symbols in dep\n+    funcs = {}\n+    for s in dep:\n+        if isinstance(s, Symbol):\n+            funcs[s] = Function(s.name)(x)\n+        elif isinstance(s, AppliedUndef):\n+             # If s is f(x), ensure it depends only on x\n+             if s.args != (x,):\n+                 raise ValueError(\"Function %s must depend only on %s\" % (s, x))\n+        else:\n+             raise TypeError(\"Dependent variable must be Symbol or AppliedUndef, got %s\" % type(s))\n+\n+    # Substitute symbols with their function forms in the equation\n+    eq_func = eq.subs(funcs)\n+\n+    # Iteratively compute derivatives\n+    derivs = {} # Stores {Derivative(y(x), x, k): value} or {Derivative(f(x), x, k): value}\n+    current_eq = eq_func\n+    for i in range(1, n + 1):\n+        # Define the derivative of order i we are solving for\n+        if y0_is_func: # y0 is f(x)\n+            dydx_i = Derivative(y0, x, i, evaluate=False)\n+        else: # y0 is Symbol y\n+            # Need the function form y(x) for differentiation.\n+            # Handle case where y0 might not have been in funcs if not a free symbol initially.\n+            y0_func = funcs.get(y0, Function(y0.name)(x))\n+            dydx_i = Derivative(y0_func, x, i, evaluate=False)\n+\n+        # Differentiate the current equation wrt x\n"}
{"instance_id": "sympy__sympy-16106", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -349,6 +349,14 @@\n         x.appendChild(self._print(e.rhs))\n         return x\n \n+    def _print_Indexed(self, expr):\n+        x = self.dom.createElement('apply')\n+        x.appendChild(self.dom.createElement('selector'))\n+        x.appendChild(self._print(expr.base))\n+        for idx in expr.indices:\n+            x.appendChild(self._print(idx))\n+        return x\n+\n     def _print_list(self, seq):\n         \"\"\"MathML reference for the <list> element:\n         http://www.w3.org/TR/MathML2/chapter4.html#contm.list\"\"\"\n```\n"}
{"instance_id": "sympy__sympy-16281", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1618,55 +1618,78 @@\n         return pform\n\n     def _print_Product(self, expr):\n-        func = expr.term\n-        pretty_func = self._print(func)\n-\n-        horizontal_chr = xobj('_', 1)\n-        corner_chr = xobj('_', 1)\n-        vertical_chr = xobj('|', 1)\n+        # Handle trivial case: single term for product\n+        if len(expr.limits) == 1 and expr.limits[0][1] == expr.limits[0][2]:\n+             return self._print(expr.term.subs(expr.limits[0][0], expr.limits[0][1]))\n+\n+        pform = self._print(expr.term)\n+        func_height = pform.height()\n+        func_width = pform.width()\n \n         if self._use_unicode:\n-            # use unicode corners\n-            horizontal_chr = xobj('-', 1)\n+            # use unicode corners U+252C BOX DRAWINGS LIGHT DOWN AND HORIZONTAL\n+            # U+2500 BOX DRAWINGS LIGHT HORIZONTAL\n+            # U+2502 BOX DRAWINGS LIGHT VERTICAL\n+            horizontal_chr = u'\\N{BOX DRAWINGS LIGHT HORIZONTAL}'\n             corner_chr = u'\\N{BOX DRAWINGS LIGHT DOWN AND HORIZONTAL}'\n-\n-        func_height = pretty_func.height()\n-\n-        first = True\n+            vertical_chr = u'\\N{BOX DRAWINGS LIGHT VERTICAL}'\n+        else:\n+            horizontal_chr = '_'\n+            corner_chr = '_'\n+            vertical_chr = '|'\n+\n+        # Process limits to find maximum dimensions\n         max_upper = 0\n-        sign_height = 0\n-\n+        max_lower = 0\n+        max_width = 0\n+        limits = []\n         for lim in expr.limits:\n-            width = (func_height + 2) * 5 // 3 - 2\n-            sign_lines = []\n-            sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n-                sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n-\n-            pretty_sign = stringPict('')\n-            pretty_sign = prettyForm(*pretty_sign.stack(*sign_lines))\n-\n+            # TODO: Handle cases like Product(x, n)\n+            var, low, high = lim\n+            pretty_var = self._print(var)\n+            pretty_low = self._print(low)\n             pretty_upper = self._print(lim[2])\n-            pretty_lower = self._print(Equality(lim[0], lim[1]))\n-\n+\n+            lower = prettyForm(*pretty_var.right('=', pretty_low)) # e.g., n=1\n+            upper = pretty_upper # e.g., oo\n+\n+            max_lower = max(max_lower, lower.height())\n             max_upper = max(max_upper, pretty_upper.height())\n-\n-            if first:\n-                sign_height = pretty_sign.height()\n-\n-            pretty_sign = prettyForm(*pretty_sign.above(pretty_upper))\n-            pretty_sign = prettyForm(*pretty_sign.below(pretty_lower))\n-\n-            if first:\n-                pretty_func.baseline = 0\n-                first = False\n-\n-            height = pretty_sign.height()\n-            padding = stringPict('')\n-            padding = prettyForm(*padding.stack(*[' ']*(height - 1)))\n-            pretty_sign = prettyForm(*pretty_sign.right(padding))\n-\n-            pretty_func = prettyForm(*pretty_sign.right(pretty_func))\n-\n-        pretty_func.baseline = max_upper + sign_height//2\n-        pretty_func.binding = prettyForm.MUL\n-        return pretty_func\n+            max_width = max(max_width, lower.width(), upper.width())\n+            limits.append({'lower': lower, 'upper': upper})\n+\n+        # Determine inner width based on function and limits\n+        inner_width = max(func_width, max_width)\n+\n+        # Build the core product symbol (\u220f) lines\n+        sign_lines = []\n+        if self._use_unicode:\n+            # Unicode: Top bar with extensions\n+            top_bar = horizontal_chr + corner_chr + horizontal_chr * inner_width + corner_chr + horizontal_chr\n+            sign_lines.append(top_bar)\n+            # Unicode: Vertical bars (need padding to match top bar width)\n+            vertical_line = ' ' + vertical_chr + ' ' * inner_width + vertical_chr + ' '\n+            for _ in range(func_height): # Use func_height, removing extra bottom line\n+                sign_lines.append(vertical_line)\n+        else:\n+            # ASCII: Top bar (no extension, but needs padding for alignment)\n+            top_bar = ' ' + corner_chr + horizontal_chr * inner_width + corner_chr + ' '\n+            sign_lines.append(top_bar)\n+            # ASCII: Vertical bars (need padding to match top bar width)\n+            vertical_line = ' ' + vertical_chr + ' ' * inner_width + vertical_chr + ' '\n+            for _ in range(func_height): # Use func_height, removing extra bottom line\n+                sign_lines.append(vertical_line)\n+\n+        pretty_sign_base = stringPict('')\n+        pretty_sign_base = prettyForm(*pretty_sign_base.stack(*sign_lines))\n+        symbol_frame_width = pretty_sign_base.width() # Get actual width after construction\n+\n+        # Stack limits above/below symbol, centered within symbol_frame_width\n+        upper_lines = stringPict('')\n+        lower_lines = stringPict('')\n+        for lim_info in limits:\n+             upper = lim_info['upper']\n+             lower = lim_info['lower']\n+             pad_upper = (symbol_frame_width - upper.width()) // 2\n+             pad_lower = (symbol_frame_width - lower.width()) // 2\n+             upper = prettyForm(*upper.left(' ' * pad_upper))\n+             lower = prettyForm(*lower.left(' ' * pad_lower))\n+             upper_lines = prettyForm(*upper_lines.stack(upper))\n+             lower_lines = prettyForm(*lower_lines.stack(lower))\n+\n+        # Combine symbol and limits\n+        pretty_sym = prettyForm(*pretty_sign_base.above(upper_lines))\n+        pretty_sym = prettyForm(*pretty_sym.below(lower_lines))\n+\n+        # Combine symbol+limits with the function\n+        # Baseline adjustment: Center function vertically relative to the core symbol (vertical bars)\n+        pform.baseline = max_upper + 1 # Old baseline: max_upper + sign_height//2\n+\n+        # Add padding between symbol and function\n+        pad_str = ' ' * 1\n+        padding = stringPict(pad_str)\n+        # Stack padding to match the height of the symbol+limits part\n+        padding = prettyForm(*padding.stack([pad_str] * pretty_sym.height()))\n+\n+        # Combine symbol+limits, padding, and function\n+        pform = prettyForm(*pretty_sym.right(padding, pform))\n+        pform.binding = prettyForm.MUL\n+        return pform\n\n     def _print_Sum(self, expr):\n         # Handle trivial case\n```\n"}
{"instance_id": "sympy__sympy-16503", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1681,7 +1681,6 @@\n             # put the present prettyF to the right\n             prettyF = prettyForm(*prettySign.right(prettyF))\n\n-        prettyF.baseline = max_upper + sign_height//2\n         prettyF.binding = prettyForm.MUL\n         return prettyF\n\n```\n"}
{"instance_id": "sympy__sympy-16792", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/codegen/routines.py\n+++ b/sympy/codegen/routines.py\n@@ -66,6 +66,10 @@\n         output_symbols = set()\n         known_symbols = set()\n\n+        # Add all symbols from argument_sequence to known_symbols\n+        for arg in argument_sequence:\n+            known_symbols.add(arg.name if isinstance(arg, (InputArgument, OutputArgument, InOutArgument)) else arg)\n+\n         # Create Argument instances\n         for arg in argument_sequence:\n             if isinstance(arg, OutputArgument):\n\n```\n"}
{"instance_id": "sympy__sympy-16988", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1,5 +1,7 @@\n+from sympy.core.singleton import S\n from sympy.sets.fancysets import Range\n from sympy.utilities.iterables import sift, ordered\n+from sympy.core.compatibility import as_int\n \n \n def simplify_intersection(args):\n@@ -14,6 +16,10 @@\n     if not args:\n         return S.UniversalSet\n \n+    # Remove duplicates before any processing\n+    # Use set for uniqueness, then ordered for canonical representation\n+    args = tuple(ordered(set(args)))\n+\n     for arg in args:\n         if not isinstance(arg, Set):\n             raise TypeError(\"Input args to Union must be Sets\")\n@@ -50,7 +56,7 @@\n \n     # ===== Pair-wise Rules =====\n     # Here we depend on rules built into the constituent sets\n-    args = set(args)\n+    args = set(args) # Use a set for efficient manipulation in the loop\n     new_args = True\n     while new_args:\n         for s in args:\n```\n"}
{"instance_id": "sympy__sympy-17022", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/printing/lambdarepr.py\n+++ b/sympy/printing/lambdarepr.py\n@@ -8,6 +8,7 @@\n from sympy.sets.sets import Set, Interval, FiniteSet, Union\n from sympy.matrices.expressions.matexpr import MatrixSymbol\n from sympy.matrices.expressions.blockmatrix import BlockMatrix\n+from sympy.matrices.expressions.special import Identity\n from sympy.tensor.array import NDimArray, DenseNDimArray, SparseNDimArray\n from sympy.utilities.decorator import doctest_depends_on\n from sympy.utilities.exceptions import sympy_deprecation_warning\n@@ -101,6 +102,25 @@\n         # Piecewise function\n         return self._print_Piecewise(expr)\n \n+    def _print_Identity(self, expr):\n+        module_aliases = self.settings.get('module_aliases', {})\n+\n+        # Prefer numpy, then scipy\n+        eye_alias = None\n+        if 'numpy' in module_aliases:\n+            eye_alias = module_aliases['numpy']\n+        elif 'scipy' in module_aliases:\n+            eye_alias = module_aliases['scipy']\n+        # Add other potential modules here if needed (e.g., cupy, jax?)\n+\n+        if eye_alias:\n+            n_str = self._print(expr.shape[0])\n+            return \"{}.eye({})\".format(eye_alias, n_str)\n+        else:\n+            # No known module provides 'eye'\n+            raise TypeError(\n+                \"lambdify cannot process Identity unless a suitable numerical \"\n+                \"module (e.g., numpy or scipy) providing 'eye' is specified.\")\n \n     def _print_MatrixBase(self, expr):\n         # Workaround for https://github.com/numpy/numpy/issues/2741\n\n```\n"}
{"instance_id": "sympy__sympy-17139", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,7 +501,7 @@ def _TR56(rv, func, func_, rule, max=False, pow=False):\n         if not isinstance(rv, Pow) or rv.base.func != func:\n             return rv\n         n, x = rv.exp, rv.base.args[0]\n-        if (rv.exp < 0) == True:\n+        if rv.exp.is_real and rv.exp.is_negative:\n             if not pow:\n                 return rv\n             n = -n\n\n```\n"}
{"instance_id": "sympy__sympy-17630", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -94,14 +94,23 @@\n         if (self.blockshape[1] != other.blockshape[0] or\n                 self.colblocksizes != other.rowblocksizes):\n             raise ShapeError(\"Block shapes incompatible for multiplication\")\n-\n+        \n+        # Avoid circular imports\n+        from sympy.matrices.expressions.matadd import MatAdd\n+        from sympy.matrices.expressions.zeromatrix import ZeroMatrix\n+        from sympy import S\n+        \n         C = Matrix(self.blockshape[0], other.blockshape[1], lambda i, j: S.Zero)\n         for i in range(self.blockshape[0]):\n             for j in range(other.blockshape[1]):\n+                block_sum = S.Zero\n                 for k in range(self.blockshape[1]):\n-                    C[i, j] = C[i, j] + self.blocks[i, k]*other.blocks[k, j]\n+                    term = self.blocks[i, k] * other.blocks[k, j]\n+                    block_sum = MatAdd(block_sum, term).doit() # Ensure simplification\n+                \n+                # If the block sum simplifies to S.Zero, replace with ZeroMatrix\n+                if block_sum == S.Zero:\n+                    C[i, j] = ZeroMatrix(self.rowblocksizes[i], other.colblocksizes[j])\n+                else:\n+                    C[i, j] = block_sum\n \n         return BlockMatrix(C)\n-\n-    def _blockadd(self, other):\n-        if not isinstance(other, BlockMatrix):\n\n```\n"}
{"instance_id": "sympy__sympy-17655", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -92,6 +92,11 @@\n         factor = sympify(factor)\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n+\n+    def __rmul__(self, factor):\n+        \"\"\"Multiply point's coordinates by a factor.\"\"\"\n+        # This is the same as __mul__(factor)\n+        return self.__mul__(factor)\n \n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n\n```\n"}
{"instance_id": "sympy__sympy-18057", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -121,7 +121,10 @@\n         # N.B. If this method returns None, the result of the comparison\n         # is determined by the Python interpreter as usual.\n         try:\n-            other = sympify(other)\n+            # We want to compare Expr to other objects.\n+            # If other is not sympifiable it is not equal to self.\n+            # If other is sympifiable, then we may be able to make a\n+            # determination. We force sympify(strict=True) to prevent\n+            # ``Symbol('x') == 'x'`` from returning True.\n+            other = sympify(other, strict=True)\n         except SympifyError:\n             # Cannot sympify other? Then it is structurally unequal.\n             return False\n\n```\n"}
{"instance_id": "sympy__sympy-18087", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -500,11 +500,6 @@\n     # identities based on sin**2 + cos**2 = 1\n     # XXX these are not quite right for complex arguments\n     matchers_identity = [\n-        # pattern, result, function, wild\n-        # e.g. sqrt(1 - b**2) -> cos(c) where b = sin(c)\n-        (sqrt(1 - b**2), cos(c), sin(c), b),\n-        (sqrt(1 + b**2), cosh(c), sinh(c), b),\n-        (sqrt(b**2 - 1), sinh(c), cosh(c), b),\n     ]\n \n     # now expand the patterns for all functions defined in funcs\n```\n"}
{"instance_id": "sympy__sympy-18189", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -1,5 +1,6 @@\n from collections.abc import Iterable\n \n+from sympy.utilities.misc import filldedent\n from sympy.core import Add, Mul, Pow, Symbol, symbols, sympify, Integer, Rational\n from sympy.core.compatibility import is_sequence\n from sympy.core.exprtools import factor_terms\n@@ -17,10 +18,13 @@\n                  raise TypeError(\n                      'syms should be given as a sequence, e.g. a list')\n              syms = [i for i in syms if i in var]\n-             if syms != var:\n-                 dict_sym_index = dict(zip(syms, range(len(syms))))\n-                 return {tuple([t[dict_sym_index[i]] for i in var])\n-                             for t in diophantine(eq, param)}\n+             # If syms is given, use it to order the results.\n+             # Solve with the default variable order first.\n+             if set(syms) != set(var):\n+                 # Ensure all variables are present, raise error if not.\n+                 raise ValueError(filldedent(f\"syms {syms} must contain all variables {var}\"))\n+             if list(syms) != var: # Check if the order is different\n+                 var_map = dict(zip(var, range(len(var)))) # Map default-ordered vars to indices\n+                 solutions_default_order = diophantine(eq, param, permute=permute) # Solve with default order, pass permute\n+                 return {tuple(t[var_map[s]] for s in syms) for t in solutions_default_order} # Reorder results\n          n, d = eq.as_numer_denom()\n          if n.is_number:\n              return set()\n\n```\n"}
{"instance_id": "sympy__sympy-18199", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/ntheory/residue_ntheory.py\n+++ b/sympy/ntheory/residue_ntheory.py\n@@ -24,6 +24,11 @@\n     \"\"\"\n     from sympy.core.numbers import igcdex\n     a, n, p = as_int(a), as_int(n), as_int(p)\n+    a %= p\n+    if a == 0:\n+        if all_roots:\n+            return [0]\n+        return 0\n     if n == 2:\n         return sqrt_mod(a, p, all_roots)\n     # see Hackman \"Elementary Number Theory\" (2009), page 76\n\n```\n"}
{"instance_id": "sympy__sympy-18532", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -119,12 +119,13 @@\n     def atoms(self, *types):\n         \"\"\"Returns the atoms that form the current object.\n \n-        By default, only objects that are truly atomic and can't\n-        be divided into smaller pieces are returned: symbols, numbers,\n-        and number symbols like I and pi. It is possible to request\n-        atoms of any type, however, as demonstrated below.\n+        By default, only expressions that have no args are returned (i.e.\n+        those for which ``expr.args`` is empty): symbols, numbers,\n+        and number symbols like I and pi. This corresponds to the\n+        mathematical definition of an atom in an expression. It is\n+        possible to request atoms of any type, however, as demonstrated\n+        below.\n \n         Examples\n         ========\n@@ -188,10 +189,11 @@\n         if types:\n             types = tuple(\n                 [t if isinstance(t, type) else type(t) for t in types])\n+            check = lambda expr: isinstance(expr, types)\n         else:\n-            types = (Atom,)\n+            # Definition of Atom is based on args\n+            check = lambda expr: not expr.args\n         result = set()\n         for expr in preorder_traversal(self):\n-            if isinstance(expr, types):\n+            if check(expr):\n                 result.add(expr)\n         return result\n```\n"}
{"instance_id": "sympy__sympy-18621", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -240,10 +240,19 @@\n         col_block_idx = self.col_block_indices[j]\n         # Extract element from relevant block\n         block = self.blocks[row_block_idx, col_block_idx]\n+\n         # Offset into the block\n         row_offset = self.row_block_offset(i)\n         col_offset = self.col_block_offset(j)\n-        return block._entry(row_offset, col_offset)\n+\n+        from sympy.matrices.matrices import MatrixBase\n+        from sympy import S\n+\n+        if isinstance(block, MatrixBase):\n+            return block[row_offset, col_offset]\n+        elif isinstance(block, MatrixExpr):\n+            return block._entry(row_offset, col_offset)\n+        else: # Scalar block\n+            return block if row_offset == 0 and col_offset == 0 else S.Zero\n\n     def _eval_transpose(self):\n         # Flip all blocks\n```\n"}
{"instance_id": "sympy__sympy-18698", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-18835", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -21,10 +21,16 @@\n 19     [[1], [2, 1]]\n 20     \"\"\"\n 21     try:\n+        # Store initial length if seq is a list to detect modification\n+        _initial_len = None\n+        _is_list = isinstance(seq, list)\n+        if _is_list:\n+            _initial_len = len(seq)\n+\n 22         seen = set()\n 23         result = result or []\n 24         for i, s in enumerate(seq):\n+            # Check for modification if it was initially a list\n+            if _is_list and len(seq) != _initial_len:\n+                raise RuntimeError(\"list changed size during iteration\")\n 25             if not (s in seen or seen.add(s)):\n 26                 yield s\n 27     except TypeError:\n\n```\n"}
{"instance_id": "sympy__sympy-19007", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -1,8 +1,10 @@\n+from itertools import accumulate\n+\n from sympy.core.basic import Basic\n from sympy.core.numbers import Integer\n from sympy.core.sympify import sympify\n-from sympy.matrices.expressions.matexpr import MatrixExpr\n-from sympy.matrices.expressions.special import ZeroMatrix, Identity\n+from sympy.matrices.expressions.matexpr import MatrixExpr, MatrixElement\n+from sympy.matrices.expressions.special import ZeroMatrix # Identity not used here directly\n from sympy.utilities.misc import filldedent\n from sympy import Symbol # Required for check below\n\n\n@@ -76,6 +78,43 @@\n     @property\n     def colblocksizes(self):\n         return [self.blocks[0, i].cols for i in range(self.blockshape[1])]\n+\n+    def _entry(self, i, j, **kwargs):\n+        # Return symbolic element if indices are not integers\n+        i, j = sympify(i), sympify(j)\n+        if not (i.is_Integer and j.is_Integer):\n+            # TODO: Add symbolic bounds checking?\n+            #       Raise error if i, j are outside symbolic bounds?\n+            return MatrixElement(self, i, j)\n+\n+        # Indices are integers, find the block and element\n+        i_int, j_int = int(i), int(j)\n+        rows, cols = self.shape\n+        # Raise IndexError if index is outside symbolic bounds:\n+        if not (0 <= i < rows and 0 <= j < cols):\n+             raise IndexError(\"Index out of bounds: (%s, %s) for matrix of shape %s\" % (i, j, self.shape))\n+\n+        # Find the block containing (i, j)\n+        row_block_indices = [0] + list(accumulate(self.rowblocksizes))\n+        col_block_indices = [0] + list(accumulate(self.colblocksizes))\n+\n+        block_i, block_j = -1, -1\n+        rel_i, rel_j = -1, -1\n+\n+        for k in range(len(self.rowblocksizes)):\n+            if row_block_indices[k] <= i_int < row_block_indices[k+1]:\n+                block_i = k\n+                rel_i = i_int - row_block_indices[k]\n+                break\n+\n+        for k in range(len(self.colblocksizes)):\n+            if col_block_indices[k] <= j_int < col_block_indices[k+1]:\n+                block_j = k\n+                rel_j = j_int - col_block_indices[k]\n+                break\n+\n+        # Return the element from the specific block by calling its _entry method\n+        return self.blocks[block_i, block_j]._entry(rel_i, rel_j, **kwargs)\n\n\n class BlockDiagMatrix(BlockMatrix):\n\n```\n"}
{"instance_id": "sympy__sympy-19254", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -23,19 +23,19 @@\n\n\n def dup_zz_mignotte_bound(f, K):\n-    \"\"\"Mignotte bound for univariate polynomials in `K[x]`. \"\"\"\n-    a = dup_max_norm(f, K)\n+    \"\"\"Knuth-Cohen bound for univariate polynomials in `K[x]`. \"\"\"\n     b = abs(dup_LC(f, K))\n-    n = dup_degree(f)\n-\n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    # The Knuth-Cohen bound is ||f||_2 * |lc(f)|\n+    # where ||f||_2 is the L2 norm (Euclidean norm) of the coefficient vector.\n+    # See: D. E. Knuth, The Art of Computer Programming, Vol. 2, Seminumerical\n+    # Algorithms, 3rd ed., Addison-Wesley, 1998, Section 4.6.2, Exercise 20.\n+    return dup_l2_norm(f, K) * b\n\n\n def dmp_zz_mignotte_bound(f, u, K):\n-    \"\"\"Mignotte bound for multivariate polynomials in `K[X]`. \"\"\"\n-    a = dmp_max_norm(f, u, K)\n+    \"\"\"Knuth-Cohen style bound for multivariate polynomials in `K[X]`. \"\"\"\n     b = abs(dmp_ground_LC(f, u, K))\n-    n = sum(dmp_degree_list(f, u))\n-\n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    # Adapt Knuth-Cohen bound for multivariate case using L2 norm.\n+    # TODO: Verify if this is the standard multivariate adaptation.\n+    return dmp_l2_norm(f, u, K) * b\n\n\n def dup_zz_hensel_step(m, f, g, h, s, t, K):\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -7,9 +7,10 @@\n     fc = f[-1]\n     A = dup_max_norm(f, K)\n     b = dup_LC(f, K)\n-    B = int(abs(K.sqrt(K(n + 1))*2**n*A*b))\n+    # Replace Mignotte bound B with Knuth-Cohen bound: B = ||f||_2 * |lc(f)|\n+    l2_norm = dup_l2_norm(f, K)\n+    B = int(abs(l2_norm * b))\n     C = int((n + 1)**(2*n)*A**(2*n - 1))\n     gamma = int(_ceil(2*_log(C, 2)))\n     bound = int(2*gamma*_log(gamma))\n     a = []\n\n```\n"}
{"instance_id": "sympy__sympy-19487", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/functions/elementary/complexes.py\n+++ b/sympy/functions/elementary/complexes.py\n@@ -91,6 +91,10 @@\n             return self.args[0] / Abs(self.args[0])\n         return self\n\n+    def _eval_rewrite_as_Abs(self, arg, **kwargs):\n+        \"\"\"Rewrite sign(x) as x/Abs(x).\"\"\"\n+        return arg / Abs(arg)\n+\n     @classmethod\n     def eval(cls, arg):\n         # handle what we can\n\n```\n"}
{"instance_id": "sympy__sympy-20049", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/physics/vector/point.py\n+++ b/sympy/physics/vector/point.py\n@@ -1,4 +1,5 @@\n from sympy.physics.vector.vector import Vector, _check_vector\n+from sympy.physics.vector.vector import VectorTypeError\n from sympy.physics.vector.frame import ReferenceFrame, _check_frame\n from sympy import sympify\n from sympy.core.basic import Basic\n@@ -447,18 +448,62 @@\n         return self.vel(outframe)\n\n     def vel(self, frame):\n-        \"\"\"The velocity Vector of this Point in the ReferenceFrame.\n-\n+        \"\"\"Returns the velocity vector of this point in the specified frame.\n+\n+        If the velocity of this point has been defined explicitly in the\n+        reference frame, that velocity is returned. If not, and the point's\n+        position has been defined relative to another point whose velocity in\n+        the frame is known, the velocity is calculated using the relationship:\n+\n+        ^N v^P = ^N v^O + d/dt(^N r^OP)\n+\n+        where P is this point, O is the other point, N is the frame, and\n+        ^N r^OP is the position vector from O to P expressed in the N frame.\n+        The calculation is performed recursively down the chain of points\n+        until a point with a known velocity in the frame is found. The time\n+        derivative is taken with respect to the specified frame N.\n+\n+        If the velocity has not been defined explicitly and the point has no\n+        defined position relative to another point (i.e., it is a root point\n+        in the position hierarchy), it is assumed to have zero velocity in the\n+        specified frame.\n+\n+        Parameters\n+        ----------\n         Parameters\n         ==========\n \n         frame : ReferenceFrame\n             The frame in which the returned velocity vector will be defined in\n \n+        Returns\n+        -------\n+        Vector\n+            The velocity vector of this point in the specified frame.\n+\n+        Raises\n+        ------\n+        ValueError\n+            If the velocity cannot be determined (e.g., the velocity of a\n+            parent point in the position hierarchy is not defined in the\n+            frame, or differentiation fails).\n+        VectorTypeError\n+            If the frame argument is not a ReferenceFrame.\n+\n+        Examples\n+        --------\n         Examples\n         ========\n \n         >>> from sympy.physics.vector import Point, ReferenceFrame\n+        >>> from sympy.physics.vector import dynamicsymbols, Vector\n         >>> N = ReferenceFrame('N')\n         >>> p1 = Point('p1')\n         >>> p1.set_vel(N, 10 * N.x)\n@@ -466,13 +511,49 @@\n         >>> p1.vel(N)\n         10*N.x\n \n-        \"\"\"\n-\n+        >>> # Velocity calculation example\n+        >>> q = dynamicsymbols('q')\n+        >>> A = ReferenceFrame('A')\n+        >>> P = Point('P') # P's velocity in A is implicitly zero\n+        >>> Q = Point('Q')\n+        >>> Q.set_pos(P, q * A.x)\n+        >>> Q.vel(A) # Calculates P.vel(A) + d/dt(q*A.x) in A\n+        q'*A.x\n+        >>> O = Point('O')\n+        >>> O.set_vel(A, 5 * A.y) # O's velocity in A is explicitly set\n+        >>> R = Point('R')\n+        >>> R.set_pos(O, q * A.y)\n+        >>> R.vel(A) # Calculates O.vel(A) + d/dt(q*A.y) in A\n+        q'*A.y + 5*A.y\n+\n+        \"\"\"\n         _check_frame(frame)\n+        # Check cache\n         if not (frame in self._vel_dict):\n-            raise ValueError('Velocity of point ' + self.name + ' has not been'\n-                             ' defined in ReferenceFrame ' + frame.name)\n+            # If not cached, attempt to calculate based on position definition\n+            parent_point = None\n+            relative_pos_vec = None\n+            if self._pos_dict:\n+                parent_point, relative_pos_vec = list(self._pos_dict.items())[0]\n+\n+            if parent_point is not None:\n+                try:\n+                    parent_vel = parent_point.vel(frame) # Recursive call\n+                    relative_vel = relative_pos_vec.dt(frame)\n+                    calculated_vel = parent_vel + relative_vel\n+                    # Cache the calculated velocity\n+                    self._vel_dict[frame] = calculated_vel\n+                except RecursionError:\n+                    raise ValueError('Recursive position definition detected for point {}'.format(self.name))\n+                except Exception as e:\n+                    # Propagate ValueError from parent, otherwise wrap other errors\n+                    if isinstance(e, ValueError):\n+                        raise e\n+                    else:\n+                        raise ValueError('Velocity of point {} could not be calculated in ReferenceFrame {}: {}'.format(self.name, frame.name, e)) from e\n+            else:\n+                # No parent point, assume zero velocity if not set. Cache it.\n+                self._vel_dict[frame] = Vector(0)\n+\n         return self._vel_dict[frame]\n\n     def acc(self, frame):\n```\n"}
{"instance_id": "sympy__sympy-20154", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -41,20 +41,13 @@\n     {1: 1, 5: 1}\n     {2: 1, 4: 1}\n     {3: 2}\n-\n-    Note that the _same_ dictionary object is returned each time.\n-    This is for speed:  generating each partition goes quickly,\n-    taking constant time, independent of n.\n-\n-    >>> [p for p in partitions(6, k=2)]\n-    [{1: 6}, {1: 6}, {1: 6}, {1: 6}]\n-\n-    If you want to build a list of the returned dictionaries then\n-    make a copy of them:\n-\n-    >>> [p.copy() for p in partitions(6, k=2)]  # doctest: +SKIP\n+\n+    >>> [p for p in partitions(6, k=2)] # doctest: +SKIP\n     [{2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n-    >>> [(M, p.copy()) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n-    [(3, {2: 3}), (4, {1: 2, 2: 2}), (5, {1: 4, 2: 1}), (6, {1: 6})]\n+\n+    Using ``size=True`` provides the number of parts (M) along with the\n+    partition (P):\n+\n+    >>> [(M, p) for M, p in partitions(6, k=2, size=True)] # doctest: +SKIP\n+    [(3, {2: 3}), (4, {1: 2, 2: 2}), (5, {1: 4, 2: 1}), (6, {1: 6})]\n \n     References\n     ==========\n@@ -118,9 +111,9 @@\n                 p[1] = n\n                 M = n\n                 if size:\n-                    yield M, p\n+                    yield M, p.copy()\n                 else:\n-                    yield p\n+                    yield p.copy()\n                 del p[1]\n             return\n \n@@ -140,9 +133,9 @@\n             if M <= m:  # Check maximum number of parts constraint\n                 if n_rem == 0:\n                     if size:\n-                        yield M, p\n+                        yield M, p.copy()\n                     else:\n-                        yield p\n+                        yield p.copy()\n                 else:\n                     yield from _partitions(n_rem, min(k, n_rem))\n \n\n```\n"}
{"instance_id": "sympy__sympy-20212", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -508,7 +508,7 @@\n         if expt.is_negative:\n             if expt.is_infinite: # exponent is -oo\n                 # See issue 6102 - discussion is needed over this point\n-                return S.Zero\n+                return S.ComplexInfinity\n             else: # exponent is finite negative\n                 return S.ComplexInfinity\n         if expt.is_infinite: # exponent is complex infinity (zoo)\n```\n"}
{"instance_id": "sympy__sympy-20322", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-20442", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-20590", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -35,6 +35,8 @@\n     \"\"\"\n     __metaclass__ = BasicMeta\n\n+    __slots__ = ()\n+\n     # To be overridden by Basic subclasses\n     def __new__(cls, *args, **kwargs):\n         # args = map(_sympify, args) # XXX this is slow\n```\n"}
{"instance_id": "sympy__sympy-20639", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-21055", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/functions/elementary/complexes.py\n+++ b/sympy/functions/elementary/complexes.py\n@@ -1,5 +1,4 @@\n from __future__ import print_function, division\n-\n from sympy.core.add import Add\n from sympy.core.expr import Expr\n from sympy.core.function import Function, Derivative, ArgumentIndexError, AppliedUndef\n@@ -73,6 +72,16 @@\n         return (x * Derivative(y, t, evaluate=True) - y *\n                     Derivative(x, t, evaluate=True)) / (x**2 + y**2)\n \n+    def _eval_refine(self, assumptions):\n+        \"\"\"\n+        Simplify arg using assumptions.\n+        \"\"\"\n+        from sympy.assumptions import ask, Q\n+        if ask(Q.positive(self.args[0]), assumptions):\n+            return S.Zero\n+        if ask(Q.negative(self.args[0]), assumptions):\n+            return S.Pi\n+\n     def _eval_rewrite_as_atan2(self, arg, **kwargs):\n         x, y = self.args[0].as_real_imag()\n         return atan2(y, x)\n```\n"}
{"instance_id": "sympy__sympy-21171", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1000,8 +1000,10 @@\n         return r\"\\operatorname{Ci}{\\left(%s\\right)}\" % self._print(expr.args[0])\n\n     def _print_SingularityFunction(self, expr, exp=None):\n+        # The argument 'exp' is assigned implicitly when printing Pow(function, exp).\n         x, a, n = expr.args\n         tex = r\"\\left\\langle %s \\right\\rangle^{%s}\" % (self._print(x - a),\n                                                      self._print(n))\n+        if exp is not None:\n+            tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n\n     def _print_Si(self, expr):\n```\n"}
{"instance_id": "sympy__sympy-21379", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-21612", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/parsing/latex/_parse_latex_antlr.py\n+++ b/sympy/parsing/latex/_parse_latex_antlr.py\n@@ -38,7 +38,7 @@\n     expr_top = convert_expr(frac.upper)\n     expr_bot = convert_expr(frac.lower)\n     inverse_denom = sympy.Pow(expr_bot, -1, evaluate=False)\n-    if expr_top == 1:\n+    if expr_top == sympy.S.One:\n         return inverse_denom\n     else:\n         return sympy.Mul(expr_top, inverse_denom, evaluate=False)\n```\n"}
{"instance_id": "sympy__sympy-21614", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -36,6 +36,8 @@\n from sympy.utilities.iterables import iterable, is_sequence, NotIterable, ordered\n from sympy.utilities.misc import filldedent, func_name\n from sympy.utilities.exceptions import SymPyDeprecationWarning\n+from sympy.matrices.common import MatrixKind\n+from sympy.tensor.array.ndim_array import ArrayKind\n\n\n class PoleError(Exception):\n@@ -461,6 +463,20 @@\n         # consistency checks handled in __new__\n         return expr._eval_derivative_n_times(v, n)\n\n+    @property\n+    @cacheit\n+    def kind(self):\n+        \"\"\"\n+        Return the kind of the derivative expression.\n+\n+        Explanation\n+        ===========\n+        The kind is inferred from the expression being differentiated.\n+        Differentiation preserves the kind (Matrix, Array, Number). See\n+        :ref:`low-level-kind-system` for more details.\n+        \"\"\"\n+        return self.expr.kind\n+\n     @property\n     def expr(self):\n         \"\"\"Return the expression being differentiated.\"\"\"\n\n```\n"}
{"instance_id": "sympy__sympy-21627", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-21847", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -113,7 +113,7 @@\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(powers.values()) >= min_degree:\n                     monomials_list_comm.append(Mul(*item))\n             yield from set(monomials_list_comm)\n         else:\n@@ -126,7 +126,7 @@\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(powers.values()) >= min_degree:\n                     monomials_list_non_comm.append(Mul(*item))\n             yield from set(monomials_list_non_comm)\n     else:\n```\n"}
{"instance_id": "sympy__sympy-22005", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/solvers/polysys.py\n+++ b/sympy/solvers/polysys.py\n@@ -105,7 +105,7 @@\n \n         univariate = list(filter(_is_univariate, basis))\n \n-        if len(univariate) == 1:\n+        if len(univariate) == 1 and len(gens) == 1:\n             f = univariate.pop()\n         else:\n             raise NotImplementedError(filldedent('''\n```\n"}
{"instance_id": "sympy__sympy-22714", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "\n"}
{"instance_id": "sympy__sympy-22840", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/simplify/cse_main.py\n+++ b/sympy/simplify/cse_main.py\n@@ -17,7 +17,8 @@\n     Substitutions containing any Symbol from ``ignore`` will be ignored.\n     \"\"\"\n     from sympy.matrices.expressions import MatrixExpr, MatrixSymbol, MatMul, MatAdd\n-    from sympy.polys.rootoftools import RootOf\n+    from sympy.matrices.expressions.matexpr import MatrixElement\n+    from sympy.polys.rootoftools import RootOf\n \n     if opt_subs is None:\n         opt_subs = dict()\n@@ -36,11 +37,14 @@\n         if isinstance(expr, RootOf):\n             return\n \n-        if isinstance(expr, Basic) and (expr.is_Atom or expr.is_Order):\n-            if expr.is_Symbol:\n-                excluded_symbols.add(expr)\n+        # Don't treat MatrixSymbol, MatrixElement, other Atoms, or Order as CSE candidates\n+        # We also don't want to collect non-Symbol atoms in excluded_symbols\n+        if isinstance(expr, (MatrixSymbol, MatrixElement)):\n             return\n+        # Handle remaining Atoms and Order\n+        if isinstance(expr, Basic) and (expr.is_Atom or expr.is_Order):\n+            if expr.is_Symbol:\n+                excluded_symbols.add(expr)\n+            return\n \n         if iterable(expr):\n             args = expr\n```\n"}
{"instance_id": "sympy__sympy-23117", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -116,6 +116,10 @@\n             if not hasattr(pointer, \"__iter__\") or isinstance(pointer, (str, bytes)):\n                 return [pointer], ()\n\n+            # Handle empty iterables:\n+            if not pointer:\n+                return [], (0,)\n+\n             elems, shapes = zip(*[f(i) for i in pointer])\n             # Check if all shapes are equal, return the shape of the first element:\n             if len(set(shapes)) != 1:\n\n```\n"}
{"instance_id": "sympy__sympy-23191", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/physics/vector/vector.py\n+++ b/sympy/physics/vector/vector.py\n@@ -1,5 +1,6 @@\n from sympy.core.basic import Basic\n from sympy.core.sympify import sympify\n+from sympy.core.add import Add\n from sympy.core.operations import SympifyError\n from sympy.core.symbol import Symbol\n from sympy.functions import sqrt\n@@ -12,40 +13,58 @@\n     def _pretty(self, printer):\n         \"\"\"Pretty Printing method. \"\"\"\n         from sympy.printing.pretty.stringpict import prettyForm\n+\n         e = self\n \n         class Fake:\n-\n             def render(self, *args, **kwargs):\n                 ar = e.args  # just to shorten things\n                 if len(ar) == 0:\n                     return str(0)\n                 pforms = []  # output list, to be concatenated to a string\n                 for i, v in enumerate(ar):\n-                    for j in 0, 1, 2:\n-                        # if the coef of the basis vector is 1, we skip the 1\n-                        if ar[i][0][j] == 1:\n-                            pform = printer._print(ar[i][1].pretty_vecs[j])\n-                        # if the coef of the basis vector is -1, we skip the 1\n-                        elif ar[i][0][j] == -1:\n-                            pform = printer._print(ar[i][1].pretty_vecs[j])\n-                            pform = prettyForm(*pform.left(\" - \"))\n+                    for j in range(3):\n+                        coeff = ar[i][0][j]\n+                        if coeff == 0:\n+                            continue\n+\n+                        # Get pretty form of vector component\n+                        pform_vec = printer._print(ar[i][1].pretty_vecs[j])\n+\n+                        if coeff == 1:\n+                            # Coefficient is 1, just use the vector form\n+                            pform = pform_vec\n+                        elif coeff == -1:\n+                            # Coefficient is -1, prepend a minus sign, aligned vertically\n+                            pform_minus = prettyForm(\"-\")\n+                            h_m = pform_minus.height()\n+                            h_v = pform_vec.height()\n+\n+                            # Pad the minus sign vertically if the vector form is taller\n+                            if h_v > h_m:\n+                                delta_h = h_v - h_m\n+                                pad_above = delta_h // 2\n+                                pad_below = delta_h - pad_above\n+                                pform_minus = prettyForm(*pform_minus.above('\\n'*pad_above))\n+                                pform_minus = prettyForm(*pform_minus.below('\\n'*pad_below))\n+\n+                            pform = prettyForm(*pform_minus.right(pform_vec))\n                             bin = prettyForm.NEG\n-                            pform = prettyForm(binding=bin, *pform)\n-                        elif ar[i][0][j] != 0:\n-                            # If the basis vector coeff is not 1 or -1,\n-                            # we might wrap it in parentheses, for readability.\n-                            pform = printer._print(ar[i][0][j])\n+                            pform = prettyForm(binding=bin, *pform) # Mark as negative term for addition\n+                        else:\n+                            # General coefficient, print it next to the vector form\n+                            pform_coeff = printer._print(coeff)\n+                            # Handle Add parentheses for coefficients\n+                            if isinstance(coeff, Add):\n+                                tmp = pform_coeff.parens()\n+                                pform_coeff = prettyForm(tmp[0], tmp[1])\n \n-                            if isinstance(ar[i][0][j], Add):\n-                                tmp = pform.parens()\n-                                pform = prettyForm(tmp[0], tmp[1])\n+                            # Pad the shorter form (coeff or vec) vertically to match the taller one's height, centered.\n+                            h_c = pform_coeff.height()\n+                            h_v = pform_vec.height()\n \n-                            pform = prettyForm(*pform.right(\n-                                \" \", ar[i][1].pretty_vecs[j]))\n-                        else:\n-                            continue\n+                            if h_c > h_v:\n+                                delta_h = h_c - h_v\n+                                pad_above = delta_h // 2\n+                                pad_below = delta_h - pad_above\n+                                pform_vec = prettyForm(*pform_vec.above('\\n'*pad_above))\n+                                pform_vec = prettyForm(*pform_vec.below('\\n'*pad_below))\n+                            elif h_v > h_c:\n+                                delta_h = h_v - h_c\n+                                pad_above = delta_h // 2\n+                                pad_below = delta_h - pad_above\n+                                pform_coeff = prettyForm(*pform_coeff.above('\\n'*pad_above))\n+                                pform_coeff = prettyForm(*pform_coeff.below('\\n'*pad_below))\n+\n+                            # Combine the (potentially padded) coefficient and vector forms\n+                            pform = prettyForm(*pform_coeff.right(\" \", pform_vec))\n+\n                         pforms.append(pform)\n \n                 pform = prettyForm.__add__(*pforms)\n```\n"}
{"instance_id": "sympy__sympy-23262", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -769,10 +769,16 @@\n ###############################################################################\n\n def _recursive_to_string(converter, expr):\n-    if isinstance(expr, (list, tuple)):\n-        return type(expr).__name__ + '(' + ', '.join(\n-            _recursive_to_string(converter, e) for e in expr) + ')'\n+    # Handle iterables recursively\n+    if isinstance(expr, tuple):\n+        if not expr:\n+            return '()'\n+        elif len(expr) == 1:\n+            # Need trailing comma for single element tuple\n+            return '(%s,)' % _recursive_to_string(converter, expr[0])\n+        else:\n+            return '(%s)' % ', '.join(\n+                _recursive_to_string(converter, e) for e in expr)\n+    elif isinstance(expr, list):\n+        return '[%s]' % ', '.join(\n+            _recursive_to_string(converter, e) for e in expr)\n     elif isinstance(expr, dict):\n         keys = [_recursive_to_string(converter, k) for k in expr.keys()]\n         values = [_recursive_to_string(converter, v) for v in expr.values()]\n```\n"}
{"instance_id": "sympy__sympy-24066", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -3,7 +3,7 @@\n from sympy.core.compatibility import ordered\n from sympy.core.containers import Tuple\n from sympy.core.expr import Expr\n-from sympy.core.function import Function, Derivative\n+from sympy.core.function import Function, Derivative, AppliedUndef\n from sympy.core.mul import Mul\n from sympy.core.power import Pow\n from sympy.core.singleton import S\n@@ -40,11 +40,15 @@\n                  dim /= idim**count\n              return factor, dim\n          elif isinstance(expr, Function):\n+             # By default, functions requires dimensionless arguments\n+             # and returns dimensionless results.\n+             # TODO: Add exceptions for functions that operate on units.\n              fds = [self._collect_factor_and_dimension(\n                  arg) for arg in expr.args]\n-             return (expr.func(*(f[0] for f in fds)),\n-                     *(d[1] for d in fds))\n+             for i, (factor, dim) in enumerate(fds):\n+                 if not self.get_dimension_system().is_dimensionless(dim):\n+                     raise ValueError(\n+                         'Dimension of \"{}\" is {}, '\n+                         'but it should be dimensionless'.format(\n+                             expr.args[i], dim))\n+             return expr.func(*(f[0] for f in fds)), Dimension(1)\n          elif isinstance(expr, Dimension):\n              return S.One, expr\n          else:\n\n```\n"}
{"instance_id": "sympy__sympy-24102", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -481,7 +481,7 @@\n                         return self.global_dict[name]\n                     return _sympify(name)\n                 # Add other cases if needed, e.g., for specific Mathematica constructs parsed as strings\n-            except (SyntaxError, TypeError, ValueError):\n+            except (SyntaxError, TypeError, ValueError, NameError):\n                  # If ast.parse fails or name lookup fails, treat as raw symbol\n                  return _sympify(l)\n             # Fallback if ast.parse succeeds but doesn't match handled types\n+            return _sympify(l)\n```\n"}
{"instance_id": "sympy__sympy-24152", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```patch\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -168,11 +168,13 @@\n             if isinstance(args[i], Add):\n                 for aa in args[i].args:\n                     tp = TensorProduct(*args[:i] + (aa,) + args[i + 1:])\n-                    if isinstance(tp, TensorProduct):\n-                        add_args.append(tp._eval_expand_tensorproduct(**hints))\n-                    else:\n-                        add_args.append(tp)\n+                    # Handle the case where TensorProduct constructor pulls out scalars\n+                    c_part, nc_part = tp.args_cnc()\n+                    if len(nc_part) == 1 and isinstance(nc_part[0], TensorProduct):\n+                        # Recursively expand the TensorProduct part\n+                        nc_part = (nc_part[0]._eval_expand_tensorproduct(**hints),)\n+                    # Recombine scalar and non-scalar parts\n+                    add_args.append(Mul(*c_part) * Mul(*nc_part))\n                 # For now, only expand one Add instance.\n                 break\n         else:\n\n```\n"}
{"instance_id": "sympy__sympy-24213", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -23,7 +23,7 @@\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n\n```\n"}
{"instance_id": "sympy__sympy-24909", "model_name_or_path": "swebench-lite_ast-chunking_BGE-base_gemini-2.5-pro_generations_swebench-lite", "model_patch": "```diff\n--- a/sympy/physics/units/prefixes.py\n+++ b/sympy/physics/units/prefixes.py\n@@ -67,20 +67,27 @@\n             return \"Prefix(%r, %r, %r, %r)\" % (\n                 str(self.name), str(self.abbrev), self._exponent, self.base)\n\n-    def __mul__(self, other):\n-        from sympy.physics.units import Quantity\n-        if not isinstance(other, (Quantity, Prefix)):\n-            return super().__mul__(other)\n-\n-        fact = self.scale_factor * other.scale_factor\n-\n-        if fact == 1:\n-            return 1\n-        elif isinstance(other, Prefix):\n-            # simplify prefix\n-            for p in PREFIXES:\n-                if PREFIXES[p].scale_factor == fact:\n-                    return PREFIXES[p]\n-            return fact\n-\n-        return self.scale_factor * other\n+    def __mul__(self, other):\n+        from sympy.physics.units import Quantity\n+        if not isinstance(other, (Quantity, Prefix)):\n+            # Multiply prefix's scale factor by the other object (number, symbol, etc.)\n+            return self.scale_factor * other\n+\n+        # Handle Prefix * Quantity\n+        if isinstance(other, Quantity):\n+            # Delegate to Quantity's __rmul__ which is designed to handle Prefix * Quantity\n+            # and produce a Quantity object with the prefix correctly applied.\n+            # This ensures milli * W returns the milli-watt Quantity.\n+            return other.__rmul__(self)\n+\n+        # Handle Prefix * Prefix (other must be a Prefix here)\n+        fact = self.scale_factor * other.scale_factor\n+\n+        if fact == 1:\n+            # Use Integer(1) for consistency with SymPy types\n+            from sympy.core.numbers import Integer\n+            return Integer(1)\n+\n+        # Try to find a standard prefix for the combined factor\n+        for p_obj in PREFIXES.values():\n+            if p_obj.scale_factor == fact:\n+                return p_obj\n+        # Return the numerical factor if no standard prefix matches\n+        return fact\n```\n"}
